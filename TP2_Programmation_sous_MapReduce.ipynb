{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bessel7/data-analyst/blob/main/TP2_Programmation_sous_MapReduce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GxUGus3U-R6"
      },
      "source": [
        "## Introduction à la programmation distribuée sous <i>MapReduce</i>\n",
        "L'objet principal de ce notebook est de maîtriser la programmation de traitement distribué sous <b>MapReduce</b>. \n",
        "Pour rappel, sous Hadoop, il ne revient pas au programmeur applicatif de mettre en œuvre les mécanismes de réplication, ni de gérer la traçabilité des grains et leur réaffectation. Ces tâches sont de la responsabilité du framework. \n",
        "\n",
        "Le programmeur applicatif a néanmoins le rôle de reformuler les algorithmes qu'il souhaite mettre en œuvre sur la plateforme distribuée suivant le mécanisme d’exécution <i>MapReduce</i>, un mécanisme d’exécution très populaire, présent dans plusieurs frameworks distribués.\n",
        "\n",
        "<i>MapReduce</i> décompose l’ensemble des opérations à réaliser en deux types de tâches <b>élémentaires</b> et <b>uniformes</b>, les <i>Map</i> et les <i>Reduce</i>. Chaque donnée passe d'abord par une tâche <i>Map</i> qui la transforme et éventuellement par une seconde tâche <i>Reduce</i>. \n",
        "\n",
        "Aucun ordre d'exécution particulier n'est attendu entre différentes tâches <i>Map</i> ou entre différentes tâches <i>Reduce</i>. Une ou plusieurs tâches <i>Map</i> et/ou <i>Reduce</i> peuvent être facilement assignées à chaque nœud de calcul. Un nœud de calcul peut correspondre à un ordinateur individuel ou à un cœur d'une unité centrale multi-cœur. Dans ce dernier cas, la mémoire vive et le stockage de masse de l’ordinateur sont partagés entre les cœurs.\n",
        "\n",
        "Le fonctionnement général de MapReduce est constitué des étapes suivantes:\n",
        "<ol>\n",
        "<li>L'ensemble de données à traiter est découpé en fragments (<i>chunks</i>).</li>\n",
        "<li>Chaque tâche <i>Map</i> est assignée à un nœud de calcul qui reçoit un ou plusieurs fragments que la tâche <i>Map</i> transforme en une séquence de paires \\[clé, valeur].</li>\n",
        "<li>Chaque tâche <i>Reduce</i> est associée à une ou plusieurs clés et est assignée à un nœud de calcul.</li>\n",
        "<li>Les paires (clé, valeur) produites par les <i>Map</i> sont groupées par clés et stockées sur les nœuds de calcul qui exécuteront les tâches <i>Reduce</i> respectives (étape shuffle).</li>\n",
        "<li>Chaque tâche <i>Reduce</i> combine, pour chaque clé qui lui est associée, les valeurs des paires [clé, valeur] avec cette clé ; les résultats sont stockés et constituent le résultat du traitement.</li>\n",
        "</ol>\n",
        "\n",
        "Le programmeur écrit les fonctions <i>Map</i> et <i>Reduce</i>, le framework se charge du reste comme illustré ci-dessous dans le décompte distribué de la fréquence de chaque mot d'un corpus.\n",
        "<!-- img width=\"70%\" src=\"https://res.cloudinary.com/talend/image/upload/q_auto,w_923,h_486/resources/seo-articles/seo-what-is-mapreduce_gj9ehi.webp\" -->\n",
        "\n",
        "<img width=\"70%\" src=\"https://www.nayaa.fr/bigdata/mr-execution-ex.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW7oVPy2wD_r"
      },
      "source": [
        "##Installation du Java Development Kit (JDK) \n",
        "Hadoop est écrit en Java et nécessite donc l'installation d'exécution de Java."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z7VzgdtcHT7"
      },
      "source": [
        "Installation du JDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG2QZ2-puh60"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHs729CucFMv"
      },
      "source": [
        "Création de la variable d'environnement <JAVA_HOME> pour situer l'emplacement d'installationde Java "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SJ7l69avQP0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zATmQRKXv6y5"
      },
      "source": [
        "# Installation du framework Hadoop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2GpL7zccB-E"
      },
      "source": [
        "Téléchargement depuis les archives de la fondation Apache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIzgKOjjvVZn",
        "outputId": "5b795fad-30be-43a3-c449-d21fc56132ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-17 14:00:19--  https://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz\n",
            "Resolving archive.apache.org (archive.apache.org)... 138.201.131.134, 2a01:4f8:172:2ec5::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|138.201.131.134|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 500749234 (478M) [application/x-gzip]\n",
            "Saving to: ‘hadoop-3.3.0.tar.gz.1’\n",
            "\n",
            "hadoop-3.3.0.tar.gz 100%[===================>] 477.55M  27.1MB/s    in 18s     \n",
            "\n",
            "2023-01-17 14:00:38 (26.0 MB/s) - ‘hadoop-3.3.0.tar.gz.1’ saved [500749234/500749234]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3tokPwWb_TU"
      },
      "source": [
        "Extraction de l'archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qsxg2nVvcql",
        "outputId": "c5ec1b8a-07cc-4702-aa74-f7d1b49f97c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mLe flux de sortie a été tronqué et ne contient que les 5000 dernières lignes.\u001b[0m\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FSDataOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/TrashPolicyDefault.Emptier.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/HarFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/PathExistsException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/XAttrSetFlag.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/BatchedRemoteIterator.BatchedEntries.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ParentNotDirectoryException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/Options.CreateOpts.CreateParent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/PathIsNotDirectoryException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/PathHandle.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/crypto/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/crypto/CryptoFSDataInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/crypto/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/crypto/class-use/CryptoFSDataInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/crypto/class-use/CryptoFSDataOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/crypto/CryptoFSDataOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/crypto/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/crypto/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/crypto/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/crypto/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/AbstractFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FsConstants.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ftp/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ftp/FTPException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ftp/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ftp/class-use/FTPException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ftp/class-use/FTPFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ftp/FTPFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ftp/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ftp/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ftp/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ftp/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/UnsupportedMultipartUploaderException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FileSystemMultipartUploader.Factory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/BlockLocation.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/permission/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/permission/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/permission/class-use/AclStatus.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/permission/class-use/AclEntry.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/permission/class-use/AclEntryType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/permission/class-use/FsCreateModes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/permission/class-use/AclEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/permission/class-use/FsPermission.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/permission/class-use/AclStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/permission/class-use/FsAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/permission/class-use/AclEntryScope.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/Trash.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/HarFs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FilterFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FSProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/BatchListingOperations.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/Options.Rename.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/class-use/PathData.PathType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/class-use/TouchCommands.Touchz.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/class-use/CommandFormat.DuplicatedOptionException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/class-use/CommandFormat.NotEnoughArgumentsException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/class-use/TouchCommands.Touch.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/class-use/CommandFormat.UnknownOptionException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/class-use/CommandFormat.IllegalNumberOfArgumentsException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/class-use/PathData.FileTypeRequirement.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/class-use/CommandFormat.TooManyArgumentsException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/class-use/CommandFormat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/FindOptions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/Result.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/FilterExpression.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/class-use/FindOptions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/class-use/Result.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/class-use/FilterExpression.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/class-use/Expression.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/class-use/BaseExpression.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/Expression.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/BaseExpression.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/shell/find/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/RawLocalFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FSDataInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/Options.CreateOpts.ChecksumParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/StreamCapabilities.StreamCapability.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/DelegationTokenRenewer.Renewable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FsShell.Help.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/PathNotFoundException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ByteBufferReadable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/Options.ChecksumCombineMode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/CanUnbuffer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FileContext.Util.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/LocatedFileStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FsShellPermissions.Chown.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FSProtos.FsPermissionProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/StreamCapabilitiesPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/UnsupportedFileSystemException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/BatchedRemoteIterator.BatchedListEntries.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/impl/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/impl/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/impl/class-use/OpenFileParameters.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/impl/class-use/FunctionsRaisingIOE.BiFunctionRaisingIOE.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/impl/class-use/FunctionsRaisingIOE.CallableRaisingIOE.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/impl/class-use/AbstractFSBuilderImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/impl/class-use/FunctionsRaisingIOE.FunctionRaisingIOE.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/impl/class-use/FutureDataInputStreamBuilderImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/impl/class-use/FsLinkResolution.FsLinkResolutionFunction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ReadOption.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/GlobalStorageStatistics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/Options.CreateOpts.BufferSize.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FSProtos.FileStatusProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FSProtos.FsPermissionProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FSProtos.LocalFileSystemPathHandleProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/DUHelper.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/StorageType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/Options.HandleOpt.Data.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/CommonConfigurationKeysPublic.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/GetSpaceUsed.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FileSystem.Statistics.StatisticsData.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/GetSpaceUsed.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/DelegationTokenRenewer.RenewAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FileContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FileAlreadyExistsException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FSProtos.FsPermissionProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ByteBufferPositionedReadable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ChecksumFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/ViewFileSystem.MountPoint.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/ViewFs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/ViewFs.MountPoint.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/class-use/ViewFileSystem.MountPoint.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/class-use/ViewFs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/class-use/ViewFs.MountPoint.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/class-use/ViewFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/class-use/NotInMountpointException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/class-use/Constants.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/class-use/ConfigUtil.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/class-use/ViewFileSystemUtil.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/ViewFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/NotInMountpointException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/Constants.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/ConfigUtil.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/ViewFileSystemUtil.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/viewfs/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FSBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/QuotaUsage.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/ContentSummary.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FsServerDefaults.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/PartialListing.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/Options.CreateOpts.Perms.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FileSystem.Statistics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/fs/FsShellPermissions.Chgrp.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/IOUtils.NullOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/IOUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/VIntWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/CompressedWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/LongWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/EnumSetWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/RawComparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/BytesWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/VLongWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SequenceFile.Sorter.RawKeyValueIterator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SetFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SetFile.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/coder/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/coder/util/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/coder/util/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/coder/util/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/coder/util/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/coder/util/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/coder/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/coder/class-use/DummyErasureDecoder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/coder/class-use/DummyErasureEncoder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/class-use/ErasureCodeConstants.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/class-use/ErasureCodeNative.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/class-use/ECSchema.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/grouper/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/grouper/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/grouper/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/grouper/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/grouper/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/codec/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/codec/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/codec/class-use/DummyErasureCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/ErasureCodeConstants.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/ErasureCodeNative.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/ECSchema.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/erasurecode/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/NullWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/ShortWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/GenericWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SequenceFile.ValueBytes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/MapFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SequenceFile.Sorter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/ByteBufferPool.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/WritableFactories.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/FloatWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/NullWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/WritableComparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/ByteWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/ElasticByteBufferPool.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/Writable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/MapFile.Reader.Option.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SecureIOUtils.AlreadyExistsException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/IOUtils.NullOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/IOUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/VIntWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/CompressedWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/LongWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/EnumSetWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/RawComparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/BytesWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/VLongWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SequenceFile.Sorter.RawKeyValueIterator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SetFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SetFile.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/NullWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/ShortWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/GenericWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SequenceFile.ValueBytes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/MapFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SequenceFile.Sorter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/ByteBufferPool.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/WritableFactories.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/FloatWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/NullWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/WritableComparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/ByteWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/ElasticByteBufferPool.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/Writable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/MapFile.Reader.Option.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SecureIOUtils.AlreadyExistsException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/ArrayFile.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/MultipleIOException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/MapWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/BinaryComparable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/WritableUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SequenceFile.CompressionType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/MD5Hash.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/WritableComparable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/TwoDArrayWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/ByteWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/Stringifier.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/MD5Hash.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/DoubleWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SetFile.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/WritableFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/AbstractMapWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SequenceFile.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/Closeable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SequenceFile.Writer.Option.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/IntWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/UTF8.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/ArrayPrimitiveWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/BloomMapFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/MapFile.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/ReadaheadPool.ReadaheadRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/ArrayFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/FloatWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/Text.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/ShortWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/MapFile.Writer.Option.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/ArrayWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/DataInputByteBuffer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SequenceFile.Metadata.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/VersionedWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/ObjectWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/MapFile.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SequenceFile.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SortedMapWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SecureIOUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/MultipleIOException.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/IntWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/LongWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/BooleanWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SequenceFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/LongWritable.DecreasingComparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/VersionMismatchException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/DataOutputOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/MapFile.Merger.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SequenceFile.Reader.Option.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/SequenceFile.Sorter.SegmentDescriptor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/BloomMapFile.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/ArrayFile.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/Text.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/BooleanWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/DoubleWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/DefaultStringifier.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/BloomMapFile.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/class-use/BytesWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/ArrayFile.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/MultipleIOException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/MapWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/nativeio/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/nativeio/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/nativeio/class-use/NativeIOException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/nativeio/class-use/Errno.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/nativeio/class-use/NativeIO.POSIX.PmemMappedRegion.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/nativeio/class-use/NativeIO.POSIX.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/nativeio/class-use/NativeIO.POSIX.NoMlockCacheManipulator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/nativeio/class-use/NativeIO.POSIX.SupportState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/nativeio/class-use/NativeIO.POSIX.Pmem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/nativeio/class-use/NativeIO.POSIX.CacheManipulator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/nativeio/class-use/NativeIO.POSIX.Stat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/nativeio/class-use/NativeIO.Windows.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/nativeio/class-use/NativeIO.Windows.AccessRight.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/BinaryComparable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/WritableUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SequenceFile.CompressionType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/MD5Hash.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/WritableComparable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/TwoDArrayWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/ByteWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/Stringifier.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/MD5Hash.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/DoubleWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SetFile.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/WritableFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/AbstractMapWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SequenceFile.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/Closeable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SequenceFile.Writer.Option.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/IntWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/UTF8.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/Utils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/RawComparable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/Compression.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/MetaBlockDoesNotExist.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/Compression.Algorithm.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/Utils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/RawComparable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/Compression.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/MetaBlockDoesNotExist.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/Compression.Algorithm.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/Utils.Version.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/SimpleBufferedOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/TFile.Reader.Scanner.Entry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/TFile.Reader.Scanner.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/BoundedRangeFileInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/TFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/TFile.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/MetaBlockAlreadyExists.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/class-use/TFile.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/Utils.Version.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/SimpleBufferedOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/TFile.Reader.Scanner.Entry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/TFile.Reader.Scanner.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/BoundedRangeFileInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/TFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/TFile.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/MetaBlockAlreadyExists.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/file/tfile/TFile.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/ArrayPrimitiveWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/BloomMapFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/JavaSerialization.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/WritableSerialization.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/class-use/JavaSerialization.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/class-use/WritableSerialization.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/class-use/JavaSerializationComparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/AvroSpecificSerialization.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/AvroReflectSerializable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/class-use/AvroSpecificSerialization.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/class-use/AvroReflectSerializable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/class-use/AvroReflectSerialization.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/class-use/AvroSerialization.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/AvroReflectSerialization.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/AvroSerialization.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/avro/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/JavaSerializationComparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/serializer/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/CompressionCodecFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/CodecPool.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/CompressionCodec.Util.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/CompressionOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/SnappyCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/BlockDecompressorStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/bzip2/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/bzip2/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/bzip2/class-use/BZip2DummyCompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/bzip2/class-use/Bzip2Factory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/bzip2/class-use/Bzip2Decompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/bzip2/class-use/CBZip2InputStream.STATE.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/bzip2/class-use/BZip2DummyDecompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/bzip2/class-use/CBZip2InputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/bzip2/class-use/CBZip2OutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/bzip2/class-use/BZip2Constants.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/bzip2/class-use/Bzip2Compressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/CodecConstants.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/CompressionInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/SplittableCompressionCodec.READ_MODE.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/BZip2Codec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/SplittableCompressionCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/BlockCompressorStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/CompressionCodecFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/CodecPool.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/CompressionCodec.Util.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/CompressionOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/SnappyCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/BlockDecompressorStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/CodecConstants.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/CompressionInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/SplittableCompressionCodec.READ_MODE.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/BZip2Codec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/SplittableCompressionCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/BlockCompressorStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/SplitCompressionInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/DoNotPool.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/CompressionCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/DirectDecompressionCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/Lz4Codec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/Compressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/DirectDecompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/GzipCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/Decompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/DefaultCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/GzipCodec.GzipOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/ZStandardCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/DeflateCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/CompressorStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/PassthroughCodec.PassthroughDecompressorStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/PassthroughCodec.StubDecompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/DecompressorStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/class-use/PassthroughCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/lz4/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/lz4/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/lz4/class-use/Lz4Decompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/lz4/class-use/Lz4Compressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/SplitCompressionInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/DoNotPool.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zstd/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zstd/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zstd/class-use/ZStandardCompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zstd/class-use/ZStandardDecompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zstd/class-use/ZStandardDecompressor.ZStandardDirectDecompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/CompressionCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/DirectDecompressionCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/Lz4Codec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/Compressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/DirectDecompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/GzipCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zlib/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zlib/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zlib/class-use/BuiltInGzipDecompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zlib/class-use/ZlibDecompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zlib/class-use/BuiltInZlibDeflater.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zlib/class-use/ZlibDecompressor.CompressionHeader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zlib/class-use/ZlibCompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zlib/class-use/ZlibCompressor.CompressionStrategy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zlib/class-use/ZlibCompressor.CompressionLevel.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zlib/class-use/ZlibDecompressor.ZlibDirectDecompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zlib/class-use/ZlibCompressor.CompressionHeader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zlib/class-use/ZlibFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/zlib/class-use/BuiltInZlibInflater.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/Decompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/DefaultCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/GzipCodec.GzipOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/ZStandardCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/DeflateCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/CompressorStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/PassthroughCodec.PassthroughDecompressorStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/PassthroughCodec.StubDecompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/DecompressorStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/snappy/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/snappy/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/snappy/class-use/SnappyCompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/snappy/class-use/SnappyDecompressor.SnappyDirectDecompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/snappy/class-use/SnappyDecompressor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/compress/PassthroughCodec.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/MapFile.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/ReadaheadPool.ReadaheadRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/ArrayFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/FloatWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/Text.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/ShortWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/MapFile.Writer.Option.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/ArrayWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/DataInputByteBuffer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SequenceFile.Metadata.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/VersionedWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/ObjectWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/MapFile.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SequenceFile.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SortedMapWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SecureIOUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/MultipleIOException.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/IntWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/LongWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/BooleanWritable.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SequenceFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/LongWritable.DecreasingComparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/VersionMismatchException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/DataOutputOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/MapFile.Merger.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/Idempotent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/MultiException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/RetryUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/RetryPolicies.MultipleLinearRandomRetry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/FailoverProxyProvider.ProxyInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/DefaultFailoverProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/RetryPolicies.MultipleLinearRandomRetry.Pair.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/RetryPolicy.RetryAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/AtMostOnce.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/RetryProxy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/FailoverProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/RetryPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/RetryPolicy.RetryAction.RetryDecision.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/retry/class-use/RetryPolicies.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SequenceFile.Reader.Option.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/SequenceFile.Sorter.SegmentDescriptor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/BloomMapFile.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/ArrayFile.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/Text.Comparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/BooleanWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/DoubleWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/DefaultStringifier.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/BloomMapFile.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/io/BytesWritable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/UnsupportedCodecException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/class-use/UnsupportedCodecException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/KeyShell.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/KeyProviderDelegationTokenExtension.DelegationTokenExtension.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/KeyProviderFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/KeyProviderExtension.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/KeyProviderDelegationTokenExtension.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/CachingKeyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/KeyProvider.KeyVersion.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/UserProvider.Factory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/KeyShell.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/KeyProviderDelegationTokenExtension.DelegationTokenExtension.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/KeyProviderFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/KeyProviderExtension.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/KeyProviderDelegationTokenExtension.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/CachingKeyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/KeyProvider.KeyVersion.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/UserProvider.Factory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/KeyProviderCryptoExtension.EncryptedKeyVersion.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/KeyProviderExtension.Extension.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/KeyProviderCryptoExtension.CryptoExtension.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/JavaKeyStoreProvider.KeyMetadata.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/KeyProvider.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/KeyProvider.Metadata.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/KeyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/class-use/JavaKeyStoreProvider.Factory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/KeyProviderCryptoExtension.EncryptedKeyVersion.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/KeyProviderExtension.Extension.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/KeyProviderCryptoExtension.CryptoExtension.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/JavaKeyStoreProvider.KeyMetadata.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/KeyProvider.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/KeyProvider.Metadata.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/KMSClientProvider.KMSTokenRenewer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/KMSClientProvider.KMSMetadata.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/KMSClientProvider.KMSKeyVersion.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/KMSClientProvider.KMSEncryptedKeyVersion.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/class-use/KMSClientProvider.KMSTokenRenewer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/class-use/KMSClientProvider.KMSMetadata.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/class-use/KMSClientProvider.KMSKeyVersion.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/class-use/KMSClientProvider.KMSEncryptedKeyVersion.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/class-use/ValueQueue.SyncGenerationPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/class-use/KMSDelegationToken.KMSDelegationTokenIdentifier.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/class-use/LoadBalancingKMSClientProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/class-use/KMSClientProvider.Factory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/class-use/ValueQueue.QueueRefiller.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/ValueQueue.SyncGenerationPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/KMSDelegationToken.KMSDelegationTokenIdentifier.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/LoadBalancingKMSClientProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/KMSClientProvider.Factory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/ValueQueue.QueueRefiller.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/kms/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/KeyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/key/JavaKeyStoreProvider.Factory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/random/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/random/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/random/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/random/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/random/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/crypto/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/HadoopIllegalArgumentException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/IrqHandler.Interrupted.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/LaunchableService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/HadoopUncaughtExceptionHandler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/IrqHandler.InterruptData.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/LauncherExitCodes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/AbstractLaunchableService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/class-use/IrqHandler.Interrupted.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/class-use/LaunchableService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/class-use/HadoopUncaughtExceptionHandler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/class-use/IrqHandler.InterruptData.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/class-use/LauncherExitCodes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/class-use/AbstractLaunchableService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/class-use/ServiceLauncher.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/class-use/ServiceLaunchException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/class-use/ServiceLauncher.MinimalGenericOptionsParser.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/class-use/LauncherArguments.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/class-use/InterruptEscalator.ServiceForcedShutdown.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/ServiceLauncher.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/ServiceLaunchException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/ServiceLauncher.MinimalGenericOptionsParser.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/LauncherArguments.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/InterruptEscalator.ServiceForcedShutdown.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/launcher/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/LoggingStateChangeListener.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/CompositeService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/AbstractService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/ServiceStateChangeListener.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/ServiceOperations.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/ServiceStateException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/class-use/LoggingStateChangeListener.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/class-use/CompositeService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/class-use/AbstractService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/class-use/ServiceStateChangeListener.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/class-use/ServiceOperations.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/class-use/ServiceStateException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/class-use/Service.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/class-use/CompositeService.CompositeServiceShutdownHook.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/class-use/LifecycleEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/class-use/Service.STATE.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/class-use/ServiceOperations.ServiceListeners.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/class-use/ServiceStateModel.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/Service.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/CompositeService.CompositeServiceShutdownHook.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/LifecycleEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/Service.STATE.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/ServiceOperations.ServiceListeners.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/ServiceStateModel.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/service/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/ConfigRedactor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/Configuration.DeprecationDelta.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/ConfigRedactor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/Configuration.DeprecationDelta.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/ReconfigurableBase.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/StorageUnit.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/Configurable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/Configuration.IntegerRanges.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/ReconfigurationUtil.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/Configured.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/Reconfigurable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/ConfServlet.BadFormatException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/Configuration.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/ReconfigurationException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/ReconfigurationServlet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/ReconfigurationUtil.PropertyChange.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/class-use/StorageSize.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/ReconfigurableBase.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/StorageUnit.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/Configurable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/Configuration.IntegerRanges.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/ReconfigurationUtil.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/Configured.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/Reconfigurable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/ConfServlet.BadFormatException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/Configuration.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/ReconfigurationException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/ReconfigurationServlet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/ReconfigurationUtil.PropertyChange.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/StorageSize.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/conf/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.TraceAdminService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.SpanReceiverListInfo.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.AddSpanReceiverRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.AddSpanReceiverResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.RemoveSpanReceiverResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.ListSpanReceiversResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.TraceAdminService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.SpanReceiverListInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.TraceAdminService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.ListSpanReceiversRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/SpanReceiverInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.TraceAdminService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.SpanReceiverListInfo.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.AddSpanReceiverRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.AddSpanReceiverResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.RemoveSpanReceiverResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.ListSpanReceiversResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.TraceAdminService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.SpanReceiverListInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.TraceAdminService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.ListSpanReceiversRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/SpanReceiverInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.SpanReceiverListInfoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/SpanReceiverInfoBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.AddSpanReceiverRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.RemoveSpanReceiverRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.ListSpanReceiversRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminProtocol.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.TraceAdminService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.ConfigPair.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.ConfigPair.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.RemoveSpanReceiverRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.AddSpanReceiverResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.AddSpanReceiverRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.RemoveSpanReceiverResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.RemoveSpanReceiverResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.ListSpanReceiversRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.AddSpanReceiverResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.ConfigPairOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.ListSpanReceiversResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.ListSpanReceiversResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminProtocolPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/class-use/TraceAdminPB.RemoveSpanReceiverRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.SpanReceiverListInfoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/SpanReceiverInfoBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.AddSpanReceiverRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.RemoveSpanReceiverRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.ListSpanReceiversRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminProtocol.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.TraceAdminService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.ConfigPair.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.ConfigPair.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.RemoveSpanReceiverRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.AddSpanReceiverResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.AddSpanReceiverRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.RemoveSpanReceiverResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.RemoveSpanReceiverResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.ListSpanReceiversRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.AddSpanReceiverResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.ConfigPairOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.ListSpanReceiversResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.ListSpanReceiversResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminProtocolPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/tracing/TraceAdminPB.RemoveSpanReceiverRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.GenericRefreshProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/RefreshCallQueueProtocolProtos.RefreshCallQueueProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.GenericRefreshRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.GenericRefreshResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.GenericRefreshProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/RefreshCallQueueProtocolProtos.RefreshCallQueueProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.GenericRefreshResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.GenericRefreshProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.GenericRefreshRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/RefreshCallQueueProtocolProtos.RefreshCallQueueProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/RefreshCallQueueProtocolProtos.RefreshCallQueueRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.GenericRefreshResponseCollectionProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/RefreshCallQueueProtocolProtos.RefreshCallQueueResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/RefreshCallQueueProtocolProtos.RefreshCallQueueResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.GenericRefreshProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/RefreshCallQueueProtocolProtos.RefreshCallQueueProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.GenericRefreshRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.GenericRefreshResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.GenericRefreshProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/RefreshCallQueueProtocolProtos.RefreshCallQueueProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.GenericRefreshResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.GenericRefreshProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.GenericRefreshRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/RefreshCallQueueProtocolProtos.RefreshCallQueueProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/RefreshCallQueueProtocolProtos.RefreshCallQueueRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.GenericRefreshResponseCollectionProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/RefreshCallQueueProtocolProtos.RefreshCallQueueResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/RefreshCallQueueProtocolProtos.RefreshCallQueueResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.GenericRefreshResponseCollectionProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/RefreshCallQueueProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/RefreshCallQueueProtocolProtos.RefreshCallQueueRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.GenericRefreshProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/RefreshCallQueueProtocolProtos.RefreshCallQueueResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.GenericRefreshResponseCollectionProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.GenericRefreshResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/RefreshCallQueueProtocolProtos.RefreshCallQueueProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/RefreshCallQueueProtocolProtos.RefreshCallQueueRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/class-use/GenericRefreshProtocolProtos.GenericRefreshRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.GenericRefreshResponseCollectionProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/RefreshCallQueueProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/RefreshCallQueueProtocolProtos.RefreshCallQueueRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.GenericRefreshProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/RefreshCallQueueProtocolProtos.RefreshCallQueueResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.GenericRefreshResponseCollectionProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.GenericRefreshResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/RefreshCallQueueProtocolProtos.RefreshCallQueueProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/RefreshCallQueueProtocolProtos.RefreshCallQueueRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/GenericRefreshProtocolProtos.GenericRefreshRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/proto/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ProtocolInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ProtobufRpcEngine2.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RpcMultiplexer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ExternalCall.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RefreshResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/WeightedTimeCostProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/Client.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/Server.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/DecayRpcScheduler.MetricsProxy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/DefaultRpcScheduler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RetryCache.CacheEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RPC.RpcKind.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/StandbyException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RpcClientException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/DecayRpcScheduler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RPC.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/Server.Call.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RemoteException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/WeightedRoundRobinMultiplexer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ProtocolMetaInfoServerSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RpcScheduler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RpcEngine.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/UnexpectedServerException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ProtocolMetaInfoPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ProcessingDetails.Timing.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/FairCallQueue.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/DecayRpcScheduler.DecayTask.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ProtobufRpcEngineCallback2.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/DecayRpcSchedulerMXBean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/IpcException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ProtobufRpcEngine.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/UserIdentityProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RpcNoSuchProtocolException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ProxyCombiner.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RpcClientUtil.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/WritableRpcEngine.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/CallQueueManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RpcInvocationHandler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RefreshHandler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/CallerContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/Server.Connection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RetryCache.CacheEntryWithPayload.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ProtocolSignature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ProtobufRpcEngine2.Server.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RpcWritable.Buffer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/DefaultCostProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/WritableRpcEngine.Server.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RpcServerException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RetriableException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/FairCallQueueMXBean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ProtobufRpcEngineCallback.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RefreshRegistry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ProtocolProxy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/ProtobufRpcEngine.Server.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RpcNoSuchMethodException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/CostProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/AsyncCallLimitExceededException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RPC.VersionMismatch.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RpcException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/RPC.Server.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/VersionedProtocol.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/class-use/CallerContext.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/class-use/GenericRefreshProtocolClientSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/class-use/GenericRefreshProtocolServerSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/class-use/RefreshCallQueueProtocolClientSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/class-use/RefreshCallQueueProtocolServerSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/GenericRefreshProtocolClientSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/GenericRefreshProtocolServerSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/RefreshCallQueueProtocolClientSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/RefreshCallQueueProtocolServerSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protocolPB/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcSaslProto.SaslAuthOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/IpcConnectionContextProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/IpcConnectionContextProtos.IpcConnectionContextProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.ProtocolSignatureProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.ProtocolVersionProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RPCCallerContextProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcResponseHeaderProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcSaslProto.SaslAuth.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RPCTraceInfoProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcRequestHeaderProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.GetProtocolVersionsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.GetProtocolSignatureRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.GetProtocolVersionsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.GetProtocolVersionsResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.GetProtocolSignatureResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.ProtocolVersionProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtobufRpcEngineProtos.RequestHeaderProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcSaslProto.SaslAuth.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcRequestHeaderProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcResponseHeaderProto.RpcErrorCodeProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.GetProtocolSignatureRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.GetProtocolSignatureResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/IpcConnectionContextProtos.UserInformationProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtobufRpcEngineProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtobufRpcEngine2Protos.RequestHeaderProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.GetProtocolSignatureResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RPCTraceInfoProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcSaslProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtobufRpcEngine2Protos.RequestHeaderProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.ProtocolInfoService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcSaslProto.SaslAuthOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/IpcConnectionContextProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/IpcConnectionContextProtos.IpcConnectionContextProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.ProtocolSignatureProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.ProtocolVersionProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RPCCallerContextProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcResponseHeaderProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcSaslProto.SaslAuth.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RPCTraceInfoProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcRequestHeaderProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.GetProtocolVersionsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.GetProtocolSignatureRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.GetProtocolVersionsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.GetProtocolVersionsResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.GetProtocolSignatureResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.ProtocolVersionProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtobufRpcEngineProtos.RequestHeaderProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcSaslProto.SaslAuth.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcRequestHeaderProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcResponseHeaderProto.RpcErrorCodeProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.GetProtocolSignatureRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.GetProtocolSignatureResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/IpcConnectionContextProtos.UserInformationProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtobufRpcEngineProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtobufRpcEngine2Protos.RequestHeaderProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.GetProtocolSignatureResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RPCTraceInfoProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcSaslProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtobufRpcEngine2Protos.RequestHeaderProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.ProtocolInfoService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcSaslProto.SaslState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcResponseHeaderProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcRequestHeaderProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.ProtocolSignatureProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcRequestHeaderProto.OperationProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/IpcConnectionContextProtos.UserInformationProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/IpcConnectionContextProtos.IpcConnectionContextProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.ProtocolInfoService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcResponseHeaderProto.RpcStatusProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtobufRpcEngine2Protos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcSaslProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtobufRpcEngineProtos.RequestHeaderProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.ProtocolSignatureProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcSaslProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RPCCallerContextProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtobufRpcEngineProtos.RequestHeaderProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcResponseHeaderProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.ProtocolInfoService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.GetProtocolVersionsResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RpcKindProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RPCTraceInfoProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/IpcConnectionContextProtos.IpcConnectionContextProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/IpcConnectionContextProtos.UserInformationProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.GetProtocolVersionsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtobufRpcEngine2Protos.RequestHeaderProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/RpcHeaderProtos.RPCCallerContextProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.GetProtocolVersionsResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.ProtocolVersionProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.ProtocolInfoService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/class-use/ProtocolInfoProtos.GetProtocolSignatureRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcSaslProto.SaslState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcResponseHeaderProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcRequestHeaderProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.ProtocolSignatureProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcRequestHeaderProto.OperationProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/IpcConnectionContextProtos.UserInformationProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/IpcConnectionContextProtos.IpcConnectionContextProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.ProtocolInfoService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcResponseHeaderProto.RpcStatusProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtobufRpcEngine2Protos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcSaslProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtobufRpcEngineProtos.RequestHeaderProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.ProtocolSignatureProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcSaslProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RPCCallerContextProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtobufRpcEngineProtos.RequestHeaderProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcResponseHeaderProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.ProtocolInfoService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.GetProtocolVersionsResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RpcKindProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RPCTraceInfoProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/IpcConnectionContextProtos.IpcConnectionContextProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/IpcConnectionContextProtos.UserInformationProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.GetProtocolVersionsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtobufRpcEngine2Protos.RequestHeaderProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/RpcHeaderProtos.RPCCallerContextProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.GetProtocolVersionsResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.ProtocolVersionProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.ProtocolInfoService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/ProtocolInfoProtos.GetProtocolSignatureRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ipc/protobuf/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/FailoverFailedException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/HAServiceProtocolHelper.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToStandbyResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.GetServiceStatusRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToStandbyResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.CedeActiveRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.GracefulFailoverResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToObserverRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToActiveResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.GetServiceStatusResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.MonitorHealthResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToActiveRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.HAStateChangeRequestInfoProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.HAServiceStateProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToActiveRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.HAStateChangeRequestInfoProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.GetServiceStatusResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToObserverResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToObserverResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.HAStateChangeRequestInfoProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.GracefulFailoverRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.ZKFCProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToStandbyResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.GetServiceStatusRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToStandbyResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.CedeActiveRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.GracefulFailoverResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToObserverRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToActiveResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.GetServiceStatusResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.MonitorHealthResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToActiveRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.HAStateChangeRequestInfoProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.HAServiceStateProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToActiveRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.HAStateChangeRequestInfoProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.GetServiceStatusResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToObserverResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToObserverResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.HAStateChangeRequestInfoProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.GracefulFailoverRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.ZKFCProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.CedeActiveResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToStandbyRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.ZKFCProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.MonitorHealthRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.HAServiceProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToObserverRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.ZKFCProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToActiveRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.GetServiceStatusRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.CedeActiveResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToStandbyRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.GracefulFailoverRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.MonitorHealthRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.CedeActiveResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.ZKFCProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.GetServiceStatusRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.HAServiceProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToObserverRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.MonitorHealthRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToStandbyRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.HAServiceProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.GracefulFailoverRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToActiveResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToObserverResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.CedeActiveRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.HARequestSource.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.HAServiceProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.GracefulFailoverResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.CedeActiveRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.MonitorHealthResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.GracefulFailoverResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.GetServiceStatusResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToStandbyResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.TransitionToActiveResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/ZKFCProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/class-use/HAServiceProtocolProtos.MonitorHealthResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.CedeActiveResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToStandbyRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.ZKFCProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.MonitorHealthRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.HAServiceProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToObserverRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.ZKFCProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToActiveRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.GetServiceStatusRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.CedeActiveResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToStandbyRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.GracefulFailoverRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.MonitorHealthRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.CedeActiveResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.ZKFCProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.GetServiceStatusRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.HAServiceProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToObserverRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.MonitorHealthRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToStandbyRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.HAServiceProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.GracefulFailoverRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToActiveResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToObserverResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.CedeActiveRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.HARequestSource.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.HAServiceProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.GracefulFailoverResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.CedeActiveRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.MonitorHealthResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.GracefulFailoverResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.GetServiceStatusResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToStandbyResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.TransitionToActiveResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/ZKFCProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/proto/HAServiceProtocolProtos.MonitorHealthResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/FenceMethod.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/ActiveStandbyElector.ActiveNotFoundException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/ShellCommandFencer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/PowerShellFencer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/FailoverFailedException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/HAServiceProtocolHelper.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/FenceMethod.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/ActiveStandbyElector.ActiveNotFoundException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/ShellCommandFencer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/PowerShellFencer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/ActiveStandbyElector.ActiveStandbyElectorCallback.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/HAServiceProtocol.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/HAAdmin.UsageInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/HAServiceProtocol.HAServiceState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/ServiceFailedException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/HealthCheckFailedException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/HAServiceTarget.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/BadFencingConfigurationException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/HAServiceProtocol.RequestSource.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/SshFenceByTcpPort.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/class-use/HAServiceProtocol.StateChangeRequestInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/protocolPB/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/protocolPB/ZKFCProtocolClientSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/protocolPB/HAServiceProtocolPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/protocolPB/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/protocolPB/class-use/ZKFCProtocolClientSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/protocolPB/class-use/HAServiceProtocolPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/protocolPB/class-use/ZKFCProtocolPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/protocolPB/ZKFCProtocolPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/protocolPB/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/protocolPB/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/protocolPB/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/protocolPB/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/ActiveStandbyElector.ActiveStandbyElectorCallback.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/HAServiceProtocol.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/HAAdmin.UsageInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/HAServiceProtocol.HAServiceState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/ServiceFailedException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/HealthCheckFailedException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/HAServiceTarget.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/BadFencingConfigurationException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/HAServiceProtocol.RequestSource.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/SshFenceByTcpPort.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/ha/HAServiceProtocol.StateChangeRequestInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsSystem.AbstractCallback.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsJsonBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsRecordBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsSource.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/filter/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/filter/GlobFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/filter/RegexFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/filter/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/filter/class-use/GlobFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/filter/class-use/RegexFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/filter/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/filter/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/filter/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/filter/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/MBeans.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/SampleStat.MinMax.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/QuantileEstimator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/MetricsCache.Record.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/MetricsCache.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/class-use/MBeans.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/class-use/SampleStat.MinMax.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/class-use/QuantileEstimator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/class-use/MetricsCache.Record.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/class-use/MetricsCache.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/class-use/Servers.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/Servers.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/util/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsRecord.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsSystem.AbstractCallback.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsJsonBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsRecordBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsSource.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsRecord.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/AbstractMetric.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsCollector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsTag.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricStringBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsPlugin.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsSystem.Callback.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsSystemMXBean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsVisitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/class-use/MetricsSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/AbstractMetric.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsCollector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsTag.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricStringBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsPlugin.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/source/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/source/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/source/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/source/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/source/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsSystem.Callback.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsSystemMXBean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsVisitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/RollingFileSystemSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/GraphiteSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/StatsDSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/class-use/RollingFileSystemSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/class-use/GraphiteSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/class-use/StatsDSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/class-use/StatsDSink.StatsD.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/class-use/GraphiteSink.Graphite.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/class-use/PrometheusMetricsSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/class-use/FileSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/StatsDSink.StatsD.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/GraphiteSink.Graphite.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/GangliaSink30.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/AbstractGangliaSink.GangliaConfType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/class-use/GangliaSink30.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/class-use/AbstractGangliaSink.GangliaConfType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/class-use/AbstractGangliaSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/class-use/AbstractGangliaSink.GangliaSlope.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/class-use/GangliaSink31.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/AbstractGangliaSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/AbstractGangliaSink.GangliaSlope.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/ganglia/GangliaSink31.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/PrometheusMetricsSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/FileSink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/sink/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/annotation/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/annotation/Metric.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/annotation/Metrics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/annotation/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/annotation/class-use/Metric.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/annotation/class-use/Metrics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/annotation/class-use/Metric.Type.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/annotation/Metric.Type.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/annotation/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/annotation/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/annotation/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/annotation/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableGaugeInt.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableRollingAverages.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableRatesWithAggregation.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableCounterInt.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MetricsRegistry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/Interns.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableGaugeInt.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableRollingAverages.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableRatesWithAggregation.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableCounterInt.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MetricsRegistry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/Interns.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableRates.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableCounter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableGaugeLong.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableStat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableRate.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableQuantiles.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableGauge.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/DefaultMetricsSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableGaugeFloat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableCounterLong.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/class-use/MutableMetric.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableRates.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableCounter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableGaugeLong.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableStat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableRate.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableQuantiles.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableGauge.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/DefaultMetricsSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableGaugeFloat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableCounterLong.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/lib/MutableMetric.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/metrics2/MetricsSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/org/apache/hadoop/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/overview-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/overview-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/allclasses-noframe.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/build/source/hadoop-common-project/hadoop-common/target/api/package-list\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/DeprecatedProperties.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/core-default.xml\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/GroupsMapping.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/UnixShellAPI.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/CommandsManual.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/CredentialProviderAPI.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/DownstreamDev.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/RackAwareness.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-common/AdminCompatibilityGuide.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/expanded.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/banner.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/icon_warning_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/collapsed.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/logo_apache.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/newwindow.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/h5.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/apache-maven-project-2.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/external.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/h3.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/icon_success_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/maven-logo-2.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/logo_maven.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/breadcrumbs.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/logos/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/logos/build-by-maven-white.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/logos/maven-feather.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/logos/build-by-maven-black.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/icon_info_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/bg.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/images/icon_error_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/project-reports.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-native-client/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/expanded.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/banner.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/icon_warning_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/collapsed.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/logo_apache.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/newwindow.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/h5.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/apache-maven-project-2.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/external.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/h3.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/icon_success_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/maven-logo-2.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/logo_maven.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/breadcrumbs.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/logos/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/logos/build-by-maven-white.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/logos/maven-feather.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/logos/build-by-maven-black.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/icon_info_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/bg.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/images/icon_error_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/project-reports.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/serialized-form.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/index.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/stylesheet.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/index-all.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/constant-values.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/overview-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/help-doc.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/deprecated-list.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/allclasses-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/script.js\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/DFSUtilClient.CorruptedBlocks.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/ReplicaAccessorBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/UnknownCipherSuiteException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.DiffStats.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/AddErasureCodingPolicyResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/DatanodeInfo.AdminStates.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/SnapshotAccessControlException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/DatanodeInfo.DatanodeInfoBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.Bean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/ZoneReencryptionStatus.State.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.DiffType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/RollingUpgradeInfo.Bean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/EncryptionZone.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/ZoneReencryptionStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/CorruptFileBlocks.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/BlockType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.DiffReportListingEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/SnapshottableDirectoryStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/CachePoolEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/ECBlockGroupStats.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/CachePoolInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/class-use/TrustedChannelResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/class-use/ReplaceDatanodeOnFailure.Policy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/class-use/BlockPinningException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/class-use/PipelineAck.ECN.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/TrustedChannelResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/ReplaceDatanodeOnFailure.Policy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/BlockPinningException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/PipelineAck.ECN.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/DatanodeAdminProperties.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/SnapshotDiffReport.DiffStats.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/AddErasureCodingPolicyResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/DatanodeInfo.AdminStates.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/SnapshotAccessControlException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/DatanodeInfo.DatanodeInfoBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/SnapshottableDirectoryStatus.Bean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/ZoneReencryptionStatus.State.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/SnapshotDiffReport.DiffType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/RollingUpgradeInfo.Bean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/EncryptionZone.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/ZoneReencryptionStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/CorruptFileBlocks.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/BlockType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/SnapshotDiffReportListing.DiffReportListingEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/SnapshottableDirectoryStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/CachePoolEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/ECBlockGroupStats.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/CachePoolInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/DatanodeAdminProperties.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/HdfsConstants.SafeModeAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/CachePoolStats.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/CacheDirectiveInfo.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/HdfsConstants.UpgradeAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/CacheDirectiveEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/HdfsConstants.StoragePolicySatisfierMode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/HdfsNamedFileStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/CachePoolStats.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/SnapshotDiffReportListing.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/HdfsFileStatus.Flags.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/CacheDirectiveInfo.Expiration.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/CacheDirectiveInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/ReplicatedBlockStats.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/SnapshotDiffReport.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/HdfsConstants.ReencryptAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/OpenFilesIterator.OpenFilesType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/HdfsConstants.DatanodeReportType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/ZoneReencryptionStatus.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/HdfsConstants.RollingUpgradeAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/SnapshotDiffReport.DiffReportEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/CacheDirectiveStats.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/class-use/CacheDirectiveStats.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/HdfsConstants.SafeModeAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/CachePoolStats.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/CacheDirectiveInfo.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/HdfsConstants.UpgradeAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/CacheDirectiveEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/HdfsConstants.StoragePolicySatisfierMode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/HdfsNamedFileStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/CachePoolStats.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/SnapshotDiffReportListing.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/HdfsFileStatus.Flags.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/CacheDirectiveInfo.Expiration.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/CacheDirectiveInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/ReplicatedBlockStats.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/HdfsConstants.ReencryptAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/OpenFilesIterator.OpenFilesType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/HdfsConstants.DatanodeReportType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/ZoneReencryptionStatus.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/HdfsConstants.RollingUpgradeAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/SnapshotDiffReport.DiffReportEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/CacheDirectiveStats.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocol/CacheDirectiveStats.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/net/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/net/BasicInetPeer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/net/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/net/class-use/BasicInetPeer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/net/class-use/NioInetPeer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/net/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/net/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/net/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/net/NioInetPeer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/net/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/CannotObtainBlockLengthException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/DeadNodeDetector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/DFSMultipartUploaderFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/StripedBlockUtil.StripingChunk.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/StripedBlockUtil.VerticalRange.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/LongBitFormat.Enum.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/StripedBlockUtil.BlockReadStats.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/StripedBlockUtil.StripingCell.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/StripedBlockUtil.AlignedStripe.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/class-use/StripedBlockUtil.StripingChunk.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/class-use/StripedBlockUtil.VerticalRange.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/class-use/LongBitFormat.Enum.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/class-use/StripedBlockUtil.BlockReadStats.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/class-use/StripedBlockUtil.StripingCell.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/class-use/StripedBlockUtil.AlignedStripe.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/class-use/StripedBlockUtil.ChunkByteBuffer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/class-use/LongBitFormat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/class-use/StripedBlockUtil.StripeRange.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/class-use/ByteArrayManager.Conf.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/class-use/IOUtilsClient.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/class-use/StripedBlockUtil.StripingChunkReadResult.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/StripedBlockUtil.ChunkByteBuffer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/LongBitFormat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/StripedBlockUtil.StripeRange.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/ByteArrayManager.Conf.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/IOUtilsClient.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/StripedBlockUtil.StripingChunkReadResult.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/util/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/DFSOpsCountStatistics.OpType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/ReplicaAccessor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/InMemoryAliasMapFailoverProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/ClientHAProxyFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/WrappedFailoverProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/class-use/InMemoryAliasMapFailoverProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/class-use/ClientHAProxyFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/class-use/WrappedFailoverProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/class-use/ConfiguredFailoverProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/class-use/AbstractNNFailoverProxyProvider.NNProxyInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/class-use/AbstractNNFailoverProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/class-use/IPFailoverProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/class-use/RequestHedgingProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/ConfiguredFailoverProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/AbstractNNFailoverProxyProvider.NNProxyInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/AbstractNNFailoverProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/IPFailoverProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/RequestHedgingProxyProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/ha/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/namenode/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/ReplicaNotFoundException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/DiskBalancerWorkStatus.DiskBalancerWorkEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ReplicaNotFoundException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/DiskBalancerWorkStatus.DiskBalancerWorkEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/CachingStrategy.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/CachingStrategy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/DiskBalancerWorkStatus.Result.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/CorruptMetaHeaderException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/CachingStrategy.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/CachingStrategy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/DiskBalancerWorkStatus.Result.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/CorruptMetaHeaderException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/datanode/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/protocol/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/SlowDiskReports.DiskOp.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/DatanodeStorage.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/DatanodeStorageReport.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/StorageReport.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/DataNodeUsageReport.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/DatanodeStorage.State.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm.SlotId.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/DfsClientShm.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/DomainSocketFactory.PathInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitReplicaInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/ShortCircuitShm.SlotId.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/DfsClientShm.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/DomainSocketFactory.PathInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/ShortCircuitReplicaInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/ShortCircuitShm.ShmId.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/ShortCircuitCache.ShortCircuitReplicaCreator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/DomainSocketFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/DomainSocketFactory.PathState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/DfsClientShmManager.PerDatanodeVisitorInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/ShortCircuitShm.Slot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/DfsClientShmManager.Visitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/ShortCircuitShm.SlotIterator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/ShortCircuitCache.CacheVisitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/class-use/ShortCircuitShm.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm.ShmId.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.ShortCircuitReplicaCreator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/DomainSocketFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/DomainSocketFactory.PathState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.PerDatanodeVisitorInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm.Slot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/DfsClientShmManager.Visitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm.SlotIterator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitCache.CacheVisitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/shortcircuit/ShortCircuitShm.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/DFSUtilClient.CorruptedBlocks.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/ReplicaAccessorBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/UnknownCipherSuiteException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/CannotObtainBlockLengthException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/DeadNodeDetector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/DFSMultipartUploaderFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/DFSOpsCountStatistics.OpType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/ReplicaAccessor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/NameNodeProxiesClient.ProxyAndInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/UnknownCryptoProtocolVersionException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/ReadStatistics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/DistributedFileSystem.HdfsDataOutputStreamBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/DFSClient.DFSDataInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/DFSOpsCountStatistics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/class-use/DFSInotifyEventInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/NameNodeProxiesClient.ProxyAndInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocolPB/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocolPB/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocolPB/class-use/PBHelperClient.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocolPB/class-use/ReconfigurationProtocolUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocolPB/class-use/ReconfigurationProtocolPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocolPB/PBHelperClient.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocolPB/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocolPB/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocolPB/ReconfigurationProtocolUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocolPB/ReconfigurationProtocolPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocolPB/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/protocolPB/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/block/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/block/BlockTokenIdentifier.AccessMode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/block/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/block/class-use/BlockTokenIdentifier.AccessMode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/block/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/block/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/block/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/block/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/delegation/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/delegation/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/delegation/class-use/DelegationTokenIdentifier.WebHdfsDelegationTokenIdentifier.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/delegation/class-use/DelegationTokenIdentifier.SWebHdfsDelegationTokenIdentifier.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.WebHdfsDelegationTokenIdentifier.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/delegation/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenIdentifier.SWebHdfsDelegationTokenIdentifier.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/delegation/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/delegation/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/security/token/delegation/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.UnlinkEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.EventType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.CreateEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/EventBatch.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.TruncateEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.UnlinkEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.EventType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.CreateEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/EventBatch.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.TruncateEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.AppendEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.MetadataUpdateEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.RenameEvent.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.CreateEvent.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.MetadataUpdateEvent.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.AppendEvent.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.CloseEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.UnlinkEvent.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.CreateEvent.INodeType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.RenameEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/MissingEventsException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/class-use/Event.MetadataUpdateEvent.MetadataType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.AppendEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.MetadataUpdateEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.RenameEvent.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.CreateEvent.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.MetadataUpdateEvent.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.AppendEvent.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.CloseEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.UnlinkEvent.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.CreateEvent.INodeType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.RenameEvent.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/MissingEventsException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/Event.MetadataUpdateEvent.MetadataType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/inotify/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/UnknownCryptoProtocolVersionException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/ReadStatistics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.Retry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.HttpClient.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsDataOutputStream.SyncFlag.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.DeprecatedKeys.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.StripedRead.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.Write.ByteArrayManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.Failover.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.Retry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.HttpClient.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsDataOutputStream.SyncFlag.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.DeprecatedKeys.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.StripedRead.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.Write.ByteArrayManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.Failover.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/DfsPathCapabilities.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsDataInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.Read.ShortCircuit.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.Mmap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.Write.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.BlockWrite.ReplaceDatanodeOnFailure.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.Read.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/BlockReportOptions.Factory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/BlockReportOptions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.ShortCircuit.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsDataOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.BlockWrite.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsAdmin.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/CreateEncryptionZoneFlag.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/class-use/HdfsClientConfigKeys.HedgedRead.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/DfsPathCapabilities.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsDataInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.Read.ShortCircuit.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.Mmap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.Write.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.BlockWrite.ReplaceDatanodeOnFailure.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.Read.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/BlockReportOptions.Factory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/BlockReportOptions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.ShortCircuit.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/metrics/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/metrics/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/metrics/class-use/BlockReaderIoProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/BlockReaderFactory.FailureInjector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/class-use/BlockReaderFactory.FailureInjector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/class-use/DfsClientConf.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/class-use/DfsClientConf.ShortCircuitConf.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/class-use/SnapshotDiffReportGenerator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/class-use/BlockReaderFactory.BlockReaderPeer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/DfsClientConf.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/DfsClientConf.ShortCircuitConf.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/SnapshotDiffReportGenerator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/BlockReaderFactory.BlockReaderPeer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/impl/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsDataOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.BlockWrite.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsAdmin.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/CreateEncryptionZoneFlag.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/HdfsClientConfigKeys.HedgedRead.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/client/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/DistributedFileSystem.HdfsDataOutputStreamBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.WebHdfsInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/OAuth2ConnectionConfigurator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/AccessTokenProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/class-use/OAuth2ConnectionConfigurator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/class-use/AccessTokenProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/class-use/OAuth2Constants.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/class-use/ConfRefreshTokenBasedAccessTokenProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/class-use/AccessTokenTimer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/class-use/ConfCredentialBasedAccessTokenProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/class-use/CredentialBasedAccessTokenProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/OAuth2Constants.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/ConfRefreshTokenBasedAccessTokenProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/AccessTokenTimer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/ConfCredentialBasedAccessTokenProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/CredentialBasedAccessTokenProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/oauth2/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/class-use/WebHdfsFileSystem.WebHdfsInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/class-use/WebHdfsFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/class-use/KerberosUgiAuthenticator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/class-use/WebHdfsFileSystem.ReadRunner.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/class-use/ByteRangeInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/class-use/SWebHdfsFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/class-use/JsonUtilClient.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/class-use/SSLConnectionConfigurator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/class-use/ByteRangeInputStream.URLOpener.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/KerberosUgiAuthenticator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/WebHdfsFileSystem.ReadRunner.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/ByteRangeInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/SWebHdfsFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/JsonUtilClient.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/SSLConnectionConfigurator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/OverwriteParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/StorageSpaceQuotaParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/FsActionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/OldSnapshotNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/ECPolicyParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/SnapshotNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/DestinationParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/HttpOpParam.TemporaryRedirectOp.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/OffsetParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/AccessTimeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/NameSpaceQuotaParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/BufferSizeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/RecursiveParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/PermissionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/Param.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/UserParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/PostOpParam.Op.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/OverwriteParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/StorageSpaceQuotaParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/FsActionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/OldSnapshotNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/ECPolicyParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/SnapshotNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/DestinationParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/HttpOpParam.TemporaryRedirectOp.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/OffsetParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/AccessTimeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/NameSpaceQuotaParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/BufferSizeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/RecursiveParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/PermissionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/Param.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/UserParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/PostOpParam.Op.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/XAttrNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/ConcatSourcesParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/HttpOpParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/GetOpParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/CreateParentParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/ExcludeDatanodesParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/StorageTypeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/DeleteOpParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/StartAfterParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/OwnerParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/CreateFlagParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/TokenArgumentParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/NoRedirectParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/PutOpParam.Op.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/RenameOptionSetParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/LengthParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/HttpOpParam.Op.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/XAttrEncodingParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/ModificationTimeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/GetOpParam.Op.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/ReplicationParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/HttpOpParam.Type.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/AclPermissionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/RenewerParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/NewLengthParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/DoAsParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/XAttrSetFlagParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/StoragePolicyParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/UnmaskedPermissionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/PostOpParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/DelegationParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/XAttrValueParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/DeleteOpParam.Op.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/BlockSizeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/PutOpParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/class-use/GroupParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/XAttrNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/ConcatSourcesParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/HttpOpParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/GetOpParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/CreateParentParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/ExcludeDatanodesParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/StorageTypeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/DeleteOpParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/StartAfterParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/OwnerParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/CreateFlagParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/TokenArgumentParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/NoRedirectParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/PutOpParam.Op.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/RenameOptionSetParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/LengthParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/HttpOpParam.Op.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/XAttrEncodingParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/ModificationTimeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/GetOpParam.Op.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/ReplicationParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/HttpOpParam.Type.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/AclPermissionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/RenewerParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/NewLengthParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/DoAsParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/XAttrSetFlagParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/StoragePolicyParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/UnmaskedPermissionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/PostOpParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/DelegationParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/XAttrValueParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/DeleteOpParam.Op.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/BlockSizeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/PutOpParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/GroupParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/resources/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/ByteRangeInputStream.URLOpener.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/web/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/DFSClient.DFSDataInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/DFSOpsCountStatistics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/DFSInotifyEventInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/hdfs/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/XAttr.NameSpace.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/class-use/XAttr.NameSpace.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/class-use/WebHdfs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/class-use/XAttr.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/class-use/SWebHdfs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/class-use/CacheFlag.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/WebHdfs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/XAttr.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/SWebHdfs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/CacheFlag.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/org/apache/hadoop/fs/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/overview-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/overview-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/allclasses-noframe.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/build/source/hadoop-hdfs-project/hadoop-hdfs-client/target/api/package-list\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-client/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/WebHDFS.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/ObserverNameNode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/CentralizedCacheManagement.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/user_comments_for_Apache_Hadoop_HDFS_3.2.1_to_Apache_Hadoop_HDFS_3.3.0.xml\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/missingSinces.txt\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/alldiffs_index_removals.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/fields_index_removals.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/packages_index_removals.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/fields_index_changes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/pkg_org.apache.hadoop.hdfs.server.namenode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/jdiff_topleftframe.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/methods_index_changes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/packages_index_additions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/fields_index_all.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/classes_index_additions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/packages_index_changes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/classes_index_all.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/changes-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/jdiff_statistics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/constructors_index_removals.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/methods_index_all.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/alldiffs_index_additions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/pkg_org.apache.hadoop.hdfs.server.aliasmap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/constructors_index_additions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/jdiff_help.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/org.apache.hadoop.hdfs.server.aliasmap.InMemoryAliasMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/constructors_index_all.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/alldiffs_index_changes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/alldiffs_index_all.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/methods_index_additions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/classes_index_changes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/classes_index_removals.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/methods_index_removals.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/constructors_index_changes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/packages_index_all.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/changes/fields_index_additions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/Apache_Hadoop_HDFS_3.3.0.xml\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/jdiff/xml/stylesheet-jdiff.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/ViewFs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HdfsPermissionsGuide.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/configuration.xsl\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/MemoryStorage.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HdfsQuotaAdminGuide.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HdfsProvidedStorage.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/federation.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/viewfs_TypicalMountTable.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/expanded.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/banner.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/icon_warning_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/hdfsproxy-forward.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/collapsed.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/federation-background.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/logo_apache.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/newwindow.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/h5.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/hdfsproxy-server.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/apache-maven-project-2.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/external.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/h3.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/hdfsdatanodes.odg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/caching.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/icon_success_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.odg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/maven-logo-2.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/logo_maven.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/breadcrumbs.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/LazyPersistWrites.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/logos/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/logos/build-by-maven-white.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/logos/maven-feather.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/logos/build-by-maven-black.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/hdfsdatanodes.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/icon_info_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/bg.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/hdfsdatanodes.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/icon_error_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/hdfsproxy-overview.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/images/hdfs-logo.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/ExtendedAttributes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HdfsImageViewer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HdfsUpgradeDomain.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/Federation.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/project-reports.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HdfsUserGuide.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HdfsEditsViewer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HdfsDataNodeAdminGuide.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HdfsMultihoming.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/ArchivalStorage.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HdfsNfsGateway.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/serialized-form.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/index.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/stylesheet.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/index-all.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/constant-values.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/overview-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/help-doc.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/deprecated-list.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/allclasses-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/script.js\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/LayoutVersion.Feature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/class-use/BlackListBasedTrustedChannelResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/class-use/WhitelistBasedTrustedChannelResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/BlackListBasedTrustedChannelResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/WhitelistBasedTrustedChannelResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/datatransfer/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/class-use/LayoutVersion.Feature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/class-use/FSLimitException.PathComponentTooLongException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/class-use/SnapshotInfo.Bean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/class-use/BlockListAsLongs.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/class-use/LayoutVersion.FeatureInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/class-use/FSLimitException.MaxDirectoryItemsExceededException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/class-use/LayoutVersion.LayoutFeature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/class-use/SnapshotException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/FSLimitException.PathComponentTooLongException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/SnapshotInfo.Bean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/BlockListAsLongs.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/LayoutVersion.FeatureInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/FSLimitException.MaxDirectoryItemsExceededException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/LayoutVersion.LayoutFeature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/SnapshotException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocol/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/net/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/net/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/net/class-use/DFSTopologyNodeImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/net/class-use/DFSNetworkTopology.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/net/DFSTopologyNodeImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/net/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/net/DFSNetworkTopology.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/net/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/net/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/net/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/WebHdfsDtFetcher.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/DFSUtil.ServiceComparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/AtomicFileOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/FoldedTreeSet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/XMLUtils.Stanza.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/ConstEnumCounters.ConstEnumException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/Diff.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/ConstEnumCounters.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/EnumCounters.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/AtomicFileOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/FoldedTreeSet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/XMLUtils.Stanza.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/ConstEnumCounters.ConstEnumException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/Diff.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/ConstEnumCounters.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/EnumCounters.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/ReadOnlyList.Util.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/RwLock.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/LightWeightHashSet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/XMLUtils.UnmanglingError.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/MD5FileUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/DataTransferThrottler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/ReferenceCountMap.ReferenceCounter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/LightWeightLinkedSet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/Holder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/Diff.Container.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/Diff.UndoInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/Diff.Element.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/EnumDoubles.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/XMLUtils.InvalidXmlException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/class-use/Diff.Processor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/ReadOnlyList.Util.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/RwLock.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/LightWeightHashSet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/XMLUtils.UnmanglingError.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/MD5FileUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/DataTransferThrottler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/ReferenceCountMap.ReferenceCounter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/LightWeightLinkedSet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/Holder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/Diff.Container.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/Diff.UndoInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/Diff.Element.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/EnumDoubles.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/XMLUtils.InvalidXmlException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/Diff.Processor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/util/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/mover/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/mover/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/mover/class-use/Mover.Cli.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/mover/Mover.Cli.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/mover/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/mover/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/mover/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/mover/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SecretManagerSection.DelegationKey.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/metrics/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/metrics/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/metrics/class-use/NameNodeMetrics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/metrics/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/metrics/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/metrics/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/metrics/NameNodeMetrics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/metrics/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeReferenceSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.FilesUnderConstructionSection.FileUnderConstructionEntry.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/NameNode.NameNodeHAContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeReference.WithCount.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SecretManagerSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/JournalManager.CorruptionException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.INodeSymlink.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.QuotaByStorageTypeFeatureProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.FileSummary.Section.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeReference.DstReference.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeDirectorySection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotSection.Snapshot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.NameSystemSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/startupprogress/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/startupprogress/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/startupprogress/class-use/StartupProgress.Counter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.DirectoryDiffOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/metrics/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/metrics/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/metrics/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/metrics/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/metrics/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/window/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/window/RollingWindowManager.User.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/window/RollingWindowManager.TopWindow.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/window/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/window/class-use/RollingWindowManager.User.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/window/class-use/RollingWindowManager.TopWindow.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/window/class-use/RollingWindowManager.Op.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/window/RollingWindowManager.Op.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/window/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/window/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/window/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/window/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/top/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.XAttrCompactProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.NameSystemSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ContentCounts.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.QuotaByStorageTypeFeatureProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/sps/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/sps/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/sps/class-use/StoragePolicySatisfyManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/sps/class-use/StoragePolicySatisfier.DatanodeMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/sps/class-use/BlockStorageMovementNeeded.DirPendingWorkInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/sps/class-use/BlockStorageMovementAttemptedItems.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/sps/class-use/StoragePolicySatisfier.DatanodeWithStorage.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.Loader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.FileSummary.Section.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.DirectoryDiff.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.FileUnderConstructionFeature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotSection.SnapshotOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INode.BlocksMapUpdateInfo.UpdatedReplicationInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SecretManagerSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeReferenceSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.Loader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.QuotaByStorageTypeFeatureProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INode.Feature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/NNStorage.NameNodeFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.INodeDirectory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSTreeTraverser.TraverseInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.CacheManagerSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/QuotaCounts.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.INodeFileOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.DiffEntry.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/NNStorageRetentionManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.StringTableSection.Entry.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.CreatedListEntryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/DirectoryWithQuotaFeature.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.ErasureCodingSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.FilesUnderConstructionSection.FileUnderConstructionEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSEditLogLoader.PositionTrackingInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/NameNode.OperationCategory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.CreatedListEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/TransferFsImage.TransferResult.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.FilesUnderConstructionSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.CacheManagerSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSPermissionChecker.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.FileSummary.SectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/AuditLogger.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/DefaultINodeAttributesProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeAttributes.SnapshotCopy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.FileDiffOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeDirectorySection.DirEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeReferenceSection.INodeReference.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SecretManagerSection.DelegationKey.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeReferenceSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.FilesUnderConstructionSection.FileUnderConstructionEntry.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/NameNode.NameNodeHAContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeReference.WithCount.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SecretManagerSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/JournalManager.CorruptionException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.INodeSymlink.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.QuotaByStorageTypeFeatureProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.FileSummary.Section.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeReference.DstReference.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeDirectorySection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotSection.Snapshot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.NameSystemSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.DirectoryDiffOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.XAttrCompactProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.NameSystemSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/ContentCounts.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.QuotaByStorageTypeFeatureProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSImageFormatPBINode.Loader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.FileSummary.Section.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSEditLogOp.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.DirectoryDiff.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.FileUnderConstructionFeature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotSection.SnapshotOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INode.BlocksMapUpdateInfo.UpdatedReplicationInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SecretManagerSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeReferenceSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSImageFormatProtobuf.Loader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.QuotaByStorageTypeFeatureProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INode.Feature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/NNStorage.NameNodeFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.INodeDirectory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSTreeTraverser.TraverseInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.CacheManagerSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/QuotaCounts.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.INodeFileOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.DiffEntry.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/NNStorageRetentionManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.StringTableSection.Entry.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.CreatedListEntryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/DirectoryWithQuotaFeature.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.ErasureCodingSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.FilesUnderConstructionSection.FileUnderConstructionEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSEditLogLoader.PositionTrackingInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/NameNode.OperationCategory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.CreatedListEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/TransferFsImage.TransferResult.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.FilesUnderConstructionSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.CacheManagerSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSPermissionChecker.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.FileSummary.SectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/AuditLogger.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/DefaultINodeAttributesProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeAttributes.SnapshotCopy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.FileDiffOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeDirectorySection.DirEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeReferenceSection.INodeReference.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/CachePool.DirectiveList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodesInPath.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.XAttrCompactProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeDirectorySection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.FileUnderConstructionFeature.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.StringTableSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeDirectorySection.DirEntry.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeDirectory.SnapshotAndINode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.StringTableSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SecretManagerSection.PersistToken.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.INode.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SecretManagerSection.DelegationKey.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeReferenceSection.INodeReference.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/ContentCounts.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/Quota.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.FilesUnderConstructionSection.FileUnderConstructionEntryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/DirectoryWithQuotaFeature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSImageFormatProtobuf.SaverContext.DeduplicationMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/QuotaCounts.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/AclEntryStatusFormat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSEditLogOp.OpInstanceCache.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.INodeFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.AclFeatureProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/NNUpgradeUtil.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSImageFormatProtobuf.SectionName.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/MetaRecoveryContext.RequestStopException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.INodeSymlink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.DiffEntry.Type.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSDirectory.DirOp.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.XAttrFeatureProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.ErasureCodingSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.NameSystemSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/NameNodeLayoutVersion.Feature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/SerialNumberManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.FileSummary.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.INodeDirectoryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.StringTableSection.EntryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.CreatedListEntry.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/HdfsAuditLogger.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSImageFormat.Loader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/QuotaByStorageTypeEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSImageFormatProtobuf.LoaderContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/CacheManager.PersistState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.StringTableSection.Entry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.FileUnderConstructionFeatureOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.FilesUnderConstructionSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeDirectory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeReference.WithName.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.DirectoryDiff.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/Content.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.XAttrFeatureProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SecretManagerSection.PersistToken.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INode.BlocksMapUpdateInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeAttributeProvider.AuthorizationContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.FileSummaryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSDirAttrOp.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.INodeFile.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSImageFormatProtobuf.SaverContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SecretManagerSection.DelegationKeyOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SecretManagerSection.PersistTokenOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.XAttrCompactProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.FilesUnderConstructionSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.FileDiff.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/EncryptionZoneManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.DiffEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeDirectoryAttributes.CopyWithQuota.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotSection.Snapshot.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeFileAttributes.SnapshotCopy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.ErasureCodingSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeAttributeProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeDirectorySectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.INode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSImageFormatPBINode.Saver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeDirectoryAttributes.SnapshotCopy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.DiffEntryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.AclFeatureProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.StringTableSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/SerialNumberManager.StringTable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.INodeDirectory.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.INodeOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/IsNameNodeActiveServlet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/EncryptionFaultInjector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.CacheManagerSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSImageFormatProtobuf.Saver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INode.ReclaimContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/QuotaByStorageTypeEntry.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/DefaultAuditLogger.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeReference.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.INodeSymlinkOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeReferenceSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/CheckpointFaultInjector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/XAttrFormat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.QuotaByStorageTypeEntryProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/StoragePolicySummary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/NNStorage.NameNodeDirType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeReferenceSection.INodeReferenceOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.XAttrFeatureProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SecretManagerSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeAttributeProvider.AccessControlEnforcer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FSEditLogOp.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeDirectorySection.DirEntryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/DfsServlet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.AclFeatureProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.INode.Type.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.QuotaByStorageTypeEntryProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INodeAttributeProvider.AuthorizationContext.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/Quota.Counts.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/INode.QuotaDelta.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.FileSummary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.INodeSection.QuotaByStorageTypeEntryProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/class-use/FsImageProto.SnapshotDiffSection.FileDiff.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/CachePool.DirectiveList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodesInPath.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.XAttrCompactProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeDirectorySection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.FileUnderConstructionFeature.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.StringTableSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeDirectorySection.DirEntry.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.SnapshotAndINode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.StringTableSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SecretManagerSection.PersistToken.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.INode.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SecretManagerSection.DelegationKey.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeReferenceSection.INodeReference.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ContentCounts.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/Quota.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.FilesUnderConstructionSection.FileUnderConstructionEntryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/DirectoryWithQuotaFeature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.SaverContext.DeduplicationMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/QuotaCounts.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/AclEntryStatusFormat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.OpInstanceCache.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.INodeFile.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.AclFeatureProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/NNUpgradeUtil.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.SectionName.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/MetaRecoveryContext.RequestStopException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.INodeSymlink.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.DiffEntry.Type.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSDirectory.DirOp.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.XAttrFeatureProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.ErasureCodingSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.NameSystemSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/NameNodeLayoutVersion.Feature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/SerialNumberManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.FileSummary.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.INodeDirectoryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.StringTableSection.EntryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.CreatedListEntry.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/HdfsAuditLogger.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSImageFormat.Loader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/QuotaByStorageTypeEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.LoaderContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/CacheManager.PersistState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.StringTableSection.Entry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.FileUnderConstructionFeatureOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.FilesUnderConstructionSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeDirectory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeReference.WithName.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.DirectoryDiff.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/Content.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.XAttrFeatureProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SecretManagerSection.PersistToken.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INode.BlocksMapUpdateInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeAttributeProvider.AuthorizationContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/web/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/web/resources/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/web/resources/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/web/resources/class-use/NamenodeWebHdfsMethods.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/web/resources/NamenodeWebHdfsMethods.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/web/resources/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/web/resources/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/web/resources/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/web/resources/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.FileSummaryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSDirAttrOp.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.INodeFile.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.SaverContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SecretManagerSection.DelegationKeyOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SecretManagerSection.PersistTokenOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.XAttrCompactProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.FilesUnderConstructionSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.FileDiff.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/EncryptionZoneManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.DiffEntry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeDirectoryAttributes.CopyWithQuota.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotSection.Snapshot.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeFileAttributes.SnapshotCopy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.ErasureCodingSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeAttributeProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeDirectorySectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.INode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSImageFormatPBINode.Saver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeDirectoryAttributes.SnapshotCopy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.DiffEntryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.AclFeatureProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.StringTableSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/SerialNumberManager.StringTable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.INodeDirectory.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.INodeOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/IsNameNodeActiveServlet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/EncryptionFaultInjector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.CacheManagerSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSImageFormatProtobuf.Saver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INode.ReclaimContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/QuotaByStorageTypeEntry.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/DefaultAuditLogger.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeReference.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.INodeSymlinkOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeReferenceSection.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/CheckpointFaultInjector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/XAttrFormat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.QuotaByStorageTypeEntryProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/StoragePolicySummary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/NNStorage.NameNodeDirType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeReferenceSection.INodeReferenceOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/RemoteNameNodeInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/HAZKInfoProtos.ActiveNodeInfoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/HAZKInfoProtos.ActiveNodeInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/HAZKInfoProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/class-use/HAZKInfoProtos.ActiveNodeInfoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/class-use/HAZKInfoProtos.ActiveNodeInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/class-use/HAZKInfoProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/class-use/HAZKInfoProtos.ActiveNodeInfo.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/HAZKInfoProtos.ActiveNodeInfo.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/proto/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/class-use/RemoteNameNodeInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/class-use/NameNodeHAProxyFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/NameNodeHAProxyFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/ha/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.XAttrFeatureProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSectionOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SecretManagerSection.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeAttributeProvider.AccessControlEnforcer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeDirectorySection.DirEntryOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/DfsServlet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/DirectoryWithSnapshotFeature.DirectoryDiffList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/DiffListBySkipList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotStatsMXBean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/DirectoryWithSnapshotFeature.DirectoryDiff.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotFSImageFormat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/DirectoryDiffListFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/DirectoryWithSnapshotFeature.DirectoryDiffList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/DiffListBySkipList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/SnapshotStatsMXBean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/DirectoryWithSnapshotFeature.DirectoryDiff.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/SnapshotFSImageFormat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/DirectoryDiffListFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/Snapshot.Root.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/FileDiff.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/SnapshotFSImageFormat.ReferenceMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/FSImageFormatPBSnapshot.Loader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/DiffListByArrayList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/FSImageFormatPBSnapshot.Saver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/SnapshotManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/DiffList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/class-use/FileDiffList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/Snapshot.Root.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/FileDiff.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotFSImageFormat.ReferenceMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/FSImageFormatPBSnapshot.Loader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/DiffListByArrayList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/FSImageFormatPBSnapshot.Saver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/SnapshotManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/DiffList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/FileDiffList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/snapshot/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.AclFeatureProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.INode.Type.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.QuotaByStorageTypeEntryProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INodeAttributeProvider.AuthorizationContext.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/Quota.Counts.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/INode.QuotaDelta.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.FileSummary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.INodeSection.QuotaByStorageTypeEntryProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotDiffSection.FileDiff.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/BlockRecoveryWorker.RecoveryTaskStriped.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/metrics/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/metrics/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/metrics/class-use/DataNodeMetricHelper.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/metrics/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/metrics/DataNodeMetricHelper.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/metrics/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/metrics/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/metrics/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/DiskFileCorruptException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ReplicaAlreadyExistsException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ErrorReportAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.BlockPoolReport.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/FSCachingGetSpaceUsed.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ReplicaWaitingToBeRecovered.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ReplicaBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/VolumeScanner.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.DiskBalancerMover.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/UnexpectedReplicaStateException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/checker/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/checker/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/checker/class-use/DatasetVolumeChecker.Callback.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/checker/class-use/AbstractFuture.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/checker/class-use/DatasetVolumeChecker.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/StorageLocation.CheckContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ReplicaInPipeline.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/BlockRecoveryWorker.RecoveryTaskStriped.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/DiskFileCorruptException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ReplicaAlreadyExistsException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ErrorReportAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/DirectoryScanner.BlockPoolReport.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/FSCachingGetSpaceUsed.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ReplicaWaitingToBeRecovered.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ReplicaBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/VolumeScanner.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/DiskBalancer.DiskBalancerMover.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/UnexpectedReplicaStateException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/StorageLocation.CheckContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/SecureDataNodeStarter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ReplicaInPipeline.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ChunkChecksum.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ShortCircuitRegistry.NewShmInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/FileIoProvider.OPERATION.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/DataNodeLayoutVersion.Feature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/FinalizedReplica.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/LocalReplica.ReplicaDirInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/BPServiceActorActionException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/LocalReplicaInPipeline.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ShortCircuitRegistry.Visitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ShortCircuitRegistry.RegisteredShm.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ReplicaBeingWritten.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ShortCircuitRegistry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/SecureDataNodeStarter.SecureResources.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/DirectoryScanner.ScanInfoVolumeReport.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/DiskBalancer.VolumePair.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/BPServiceActorAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ReportBadBlockAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/LocalReplica.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ReplicaUnderRecovery.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/ReplicaHandler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/DiskBalancer.BlockMover.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/class-use/DirectoryScanner.ReportCompiler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ChunkChecksum.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ShortCircuitRegistry.NewShmInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/FileIoProvider.OPERATION.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/DataNodeLayoutVersion.Feature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/FinalizedReplica.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/LocalReplica.ReplicaDirInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/BPServiceActorActionException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/LocalReplicaInPipeline.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ShortCircuitRegistry.Visitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/FsDatasetSpi.Factory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/FsVolumeSpi.VolumeCheckContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/FsVolumeSpi.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/FsDatasetSpi.FsVolumeReferences.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/class-use/FsDatasetSpi.Factory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/class-use/FsVolumeSpi.VolumeCheckContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/class-use/FsVolumeSpi.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/class-use/FsDatasetSpi.FsVolumeReferences.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/class-use/AvailableSpaceVolumeChoosingPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/class-use/FsVolumeSpi.BlockIterator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/class-use/FsVolumeReference.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/class-use/LengthInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/class-use/ReplicaInputStreams.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/class-use/RoundRobinVolumeChoosingPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/class-use/ReplicaOutputStreams.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/class-use/FsVolumeSpi.ScanInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/AvailableSpaceVolumeChoosingPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/FsVolumeSpi.BlockIterator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/FsVolumeReference.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/LengthInputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/ReplicaInputStreams.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/RoundRobinVolumeChoosingPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/ReplicaOutputStreams.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ReservedSpaceCalculator.ReservedSpaceCalculatorAggressive.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ReservedSpaceCalculator.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ReservedSpaceCalculator.ReservedSpaceCalculatorConservative.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ReservedSpaceCalculator.ReservedSpaceCalculatorAbsolute.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/class-use/ReservedSpaceCalculator.ReservedSpaceCalculatorAggressive.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/class-use/ReservedSpaceCalculator.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/class-use/ReservedSpaceCalculator.ReservedSpaceCalculatorConservative.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/class-use/ReservedSpaceCalculator.ReservedSpaceCalculatorAbsolute.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/class-use/AddBlockPoolException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/class-use/ReservedSpaceCalculator.ReservedSpaceCalculatorPercentage.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/class-use/FsDatasetFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/class-use/ReservedSpaceCalculator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/class-use/FsVolumeImplBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/class-use/FsVolumeImpl.BlockDirFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/AddBlockPoolException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ReservedSpaceCalculator.ReservedSpaceCalculatorPercentage.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsDatasetFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/ReservedSpaceCalculator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeImplBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/FsVolumeImpl.BlockDirFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/FsVolumeSpi.ScanInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/fsdataset/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ShortCircuitRegistry.RegisteredShm.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ReplicaBeingWritten.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ShortCircuitRegistry.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/SecureDataNodeStarter.SecureResources.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.ScanInfoVolumeReport.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/DataNodeUGIProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/class-use/DataNodeUGIProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/class-use/WebHdfsHandler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/WebHdfsHandler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/class-use/DatanodeHttpServer.MapBasedFilterConfig.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/class-use/DatanodeHttpServer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/DatanodeHttpServer.MapBasedFilterConfig.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/DatanodeHttpServer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/web/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.VolumePair.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/BPServiceActorAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ReportBadBlockAction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/LocalReplica.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ReplicaUnderRecovery.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/ReplicaHandler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/DiskBalancer.BlockMover.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/datanode/DirectoryScanner.ReportCompiler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/RemoteEditLog.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/BlocksStorageMoveAttemptFinished.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/BlocksWithLocations.StripedBlockWithLocations.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/BalancerBandwidthCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/BlockStorageMovementCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/RemoteEditLogManifest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/VolumeFailureSummary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/NamespaceInfo.Capability.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/ReceivedDeletedBlockInfo.BlockStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/StorageReceivedDeletedBlocks.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/ReceivedDeletedBlockInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/FencedException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/StorageBlockReport.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/BlockStorageMovementCommand.BlockMovingInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/protocol/class-use/BlockRecoveryCommand.RecoveringStripedBlock.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/HdfsServerConstants.BlockUCState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/TokenVerifier.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/FileRegion.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/HdfsServerConstants.NamenodeRole.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/MetricsLoggerTask.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/HdfsServerConstants.BlockUCState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/TokenVerifier.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/FileRegion.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/HdfsServerConstants.NamenodeRole.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/MetricsLoggerTask.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/HostRestrictingAuthorizationFilter.HttpInteraction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/HdfsServerConstants.ReplicaState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/BlockAlias.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/HdfsServerConstants.StartupOption.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/HostRestrictingAuthorizationFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/HdfsServerConstants.NodeType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/HdfsServerConstants.RollingUpgradeStartupOption.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/class-use/Storage.StorageState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/HostRestrictingAuthorizationFilter.HttpInteraction.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/HdfsServerConstants.ReplicaState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/BlockAlias.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/HdfsServerConstants.StartupOption.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/HostRestrictingAuthorizationFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/HdfsServerConstants.NodeType.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/HdfsServerConstants.RollingUpgradeStartupOption.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/BlockAliasMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/BlockAliasMap.Reader.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/class-use/BlockAliasMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/class-use/BlockAliasMap.Reader.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/class-use/BlockAliasMap.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/class-use/BlockAliasMap.ImmutableIterator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/class-use/BlockAliasMap.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/class-use/BlockAliasMap.Writer.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/BlockAliasMap.Reader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/BlockAliasMap.ImmutableIterator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/LevelDBFileRegionAliasMap.LevelDBWriter.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/LevelDBFileRegionAliasMap.LevelDBOptions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/TextFileRegionAliasMap.WriterOptions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/TextFileRegionAliasMap.ReaderOptions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/LevelDBFileRegionAliasMap.LevelDBReader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/LevelDBFileRegionAliasMap.LevelDBWriter.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/LevelDBFileRegionAliasMap.LevelDBOptions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/TextFileRegionAliasMap.WriterOptions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/TextFileRegionAliasMap.ReaderOptions.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/LevelDBFileRegionAliasMap.LevelDBReader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/LevelDBFileRegionAliasMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/LevelDBFileRegionAliasMap.LevelDBWriter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/TextFileRegionAliasMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/TextFileRegionAliasMap.TextWriter.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/LevelDBFileRegionAliasMap.LevelDBReader.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/TextFileRegionAliasMap.TextReader.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/TextFileRegionAliasMap.TextReader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/class-use/TextFileRegionAliasMap.TextWriter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/LevelDBFileRegionAliasMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/LevelDBFileRegionAliasMap.LevelDBWriter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/TextFileRegionAliasMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/TextFileRegionAliasMap.TextWriter.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/LevelDBFileRegionAliasMap.LevelDBReader.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/TextFileRegionAliasMap.TextReader.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/TextFileRegionAliasMap.TextReader.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/TextFileRegionAliasMap.TextWriter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/BlockAliasMap.Writer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/BlockAliasMap.Writer.Options.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/blockaliasmap/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/Storage.StorageState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/common/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/DiskBalancerCluster.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/DiskBalancerDataNode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/DiskBalancerVolume.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/class-use/DiskBalancerCluster.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/class-use/DiskBalancerDataNode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/class-use/DiskBalancerVolume.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/class-use/DiskBalancerVolumeSet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/DiskBalancerVolumeSet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/datamodel/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/HelpCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/ExecuteCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/PlanCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/Command.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/QueryCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/class-use/HelpCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/class-use/ExecuteCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/class-use/PlanCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/class-use/Command.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/class-use/QueryCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/class-use/ReportCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/class-use/CancelCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/ReportCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/CancelCommand.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/command/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/class-use/DiskBalancerException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/class-use/DiskBalancerException.Result.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/MoveStep.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/class-use/MoveStep.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/class-use/GreedyPlanner.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/class-use/PlannerFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/class-use/NodePlan.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/class-use/Planner.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/class-use/Step.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/GreedyPlanner.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/PlannerFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/NodePlan.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/Planner.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/Step.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/planner/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/connectors/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/connectors/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/connectors/class-use/ClusterConnector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/connectors/class-use/JsonNodeConnector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/connectors/class-use/ConnectorFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/connectors/ClusterConnector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/connectors/JsonNodeConnector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/connectors/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/connectors/ConnectorFactory.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/connectors/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/connectors/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/connectors/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/DiskBalancerException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/diskbalancer/DiskBalancerException.Result.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/Dispatcher.DBlockStriped.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/Dispatcher.DDatanode.StorageGroup.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/MovedBlocks.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/class-use/Dispatcher.DBlockStriped.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/class-use/Dispatcher.DDatanode.StorageGroup.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/class-use/MovedBlocks.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/class-use/Dispatcher.StorageGroupMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/class-use/Dispatcher.Source.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/class-use/Dispatcher.DBlock.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/class-use/Matcher.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/class-use/Dispatcher.PendingMove.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/class-use/MovedBlocks.Locations.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/class-use/ExitStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/class-use/Dispatcher.DDatanode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/Dispatcher.StorageGroupMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/Dispatcher.Source.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/Dispatcher.DBlock.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/Matcher.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/Dispatcher.PendingMove.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/MovedBlocks.Locations.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/ExitStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/Dispatcher.DDatanode.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/balancer/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/aliasmap/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/aliasmap/InMemoryAliasMap.CheckedFunction2.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/aliasmap/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/aliasmap/class-use/InMemoryAliasMap.CheckedFunction2.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/aliasmap/class-use/InMemoryAliasMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/aliasmap/class-use/InMemoryAliasMapProtocol.IterationResult.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/aliasmap/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/aliasmap/InMemoryAliasMap.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/aliasmap/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/aliasmap/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/aliasmap/InMemoryAliasMapProtocol.IterationResult.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/aliasmap/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminBackoffMonitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/BlockIdManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeStorageInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/NumberReplicas.StoredReplicaState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminDefaultMonitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/BlockStatsMXBean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/UnresolvedTopologyException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementStatusDefault.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.CachedBlocksList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.LeavingServiceStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminMonitorInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/BlockInfoStriped.StorageAndBlockIndex.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/HostFileManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/DatanodeAdminBackoffMonitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/BlockIdManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/DatanodeStorageInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/NumberReplicas.StoredReplicaState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/DatanodeAdminDefaultMonitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/BlockStatsMXBean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/UnresolvedTopologyException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/BlockPlacementStatusDefault.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/DatanodeDescriptor.CachedBlocksList.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/DatanodeDescriptor.LeavingServiceStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/DatanodeAdminMonitorInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/BlockInfoStriped.StorageAndBlockIndex.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/HostFileManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/DatanodeDescriptor.CachedBlocksList.Type.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/ProvidedStorageMap.ProvidedDescriptor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/SlowDiskTracker.DiskLatency.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/BlockManagerFaultInjector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/AvailableSpaceBlockPlacementPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/BlockUnderConstructionFeature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/CombinedHostFileManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/BlockStoragePolicySuite.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/DatanodeAdminMonitorBase.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/HostSet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/DatanodeStatistics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/CorruptReplicasMap.Reason.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/BlockPlacementPolicyWithNodeGroup.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/NumberReplicas.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/class-use/SlowPeerTracker.ReportForJson.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeDescriptor.CachedBlocksList.Type.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/ProvidedStorageMap.ProvidedDescriptor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/SlowDiskTracker.DiskLatency.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/BlockManagerFaultInjector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/AvailableSpaceBlockPlacementPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/BlockUnderConstructionFeature.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/CombinedHostFileManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/BlockStoragePolicySuite.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeAdminMonitorBase.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/HostSet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/DatanodeStatistics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/CorruptReplicasMap.Reason.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/BlockPlacementPolicyWithNodeGroup.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/NumberReplicas.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/SlowPeerTracker.ReportForJson.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/server/blockmanagement/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/DFSUtil.ConfiguredNNAddress.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/class-use/WebHdfsDtFetcher.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/class-use/DFSUtil.ServiceComparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/class-use/DFSUtil.ConfiguredNNAddress.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/class-use/SWebHdfsDtFetcher.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/class-use/HdfsDtFetcher.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/ReconfigurationProtocolServerSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/NamenodeProtocolServerSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/class-use/ReconfigurationProtocolServerSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/class-use/NamenodeProtocolServerSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/class-use/DatanodeProtocolServerSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/class-use/ReconfigurationProtocolServerSideUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/class-use/PBHelper.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/DatanodeProtocolServerSideTranslatorPB.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/ReconfigurationProtocolServerSideUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/PBHelper.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/protocolPB/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/block/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/block/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/block/class-use/BlockPoolTokenSecretManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/block/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/block/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/block/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/block/BlockPoolTokenSecretManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/block/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/delegation/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/delegation/DelegationTokenSecretManager.SecretManagerState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/delegation/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/delegation/class-use/DelegationTokenSecretManager.SecretManagerState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/delegation/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/delegation/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/delegation/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/security/token/delegation/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineEditsViewer/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineEditsViewer/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineEditsViewer/class-use/OfflineEditsViewer.Flags.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineEditsViewer/class-use/TeeOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineEditsViewer/OfflineEditsViewer.Flags.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineEditsViewer/TeeOutputStream.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineEditsViewer/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineEditsViewer/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineEditsViewer/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineEditsViewer/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/DiskBalancerCLI.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/class-use/DiskBalancerCLI.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/class-use/DFSHAAdmin.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/class-use/AdminHelper.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/class-use/GetConf.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/class-use/StoragePolicyAdmin.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/DFSHAAdmin.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/AdminHelper.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/GetConf.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageDelimitedTextWriter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/IgnoreSnapshotException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/class-use/PBImageDelimitedTextWriter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/class-use/IgnoreSnapshotException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/class-use/WebImageViewer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/class-use/PBImageCorruptionDetector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/class-use/XmlImageVisitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/class-use/PBImageCorruption.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/WebImageViewer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageCorruptionDetector.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/XmlImageVisitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageCorruption.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/offlineImageViewer/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/StoragePolicyAdmin.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/snapshot/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/snapshot/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/snapshot/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/snapshot/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/snapshot/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/tools/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/SWebHdfsDtFetcher.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/AuthFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/AuthFilterInitializer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/ParamFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/class-use/AuthFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/class-use/AuthFilterInitializer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/class-use/ParamFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/class-use/JsonUtil.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/JsonUtil.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/TokenServiceParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/ExceptionHandler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/TokenKindParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/class-use/TokenServiceParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/class-use/ExceptionHandler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/class-use/TokenKindParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/class-use/UserProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/class-use/UriFsPathParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/class-use/NamenodeAddressParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/UserProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/UriFsPathParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/NamenodeAddressParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/resources/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/web/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoRollbackRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.AcceptRecoveryRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.JournalRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.QJournalProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.FormatRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.JournalIdProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.FinalizeLogSegmentRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PersistedRecoveryPaxosData.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.NewEpochRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.FormatRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.CanRollBackResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.JournalIdProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.StartLogSegmentResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.StartLogSegmentResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournalCTimeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DiscardSegmentsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.FormatRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.HeartbeatResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoUpgradeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PrepareRecoveryRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.RequestInfoProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetEditLogManifestRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PurgeLogsResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoPreUpgradeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.SegmentStateProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.HeartbeatRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoPreUpgradeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetEditLogManifestResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoUpgradeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.QJournalProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.SegmentStateProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournalStateRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.JournalResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PurgeLogsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoPreUpgradeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.NewEpochResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.FormatResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.AcceptRecoveryResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoFinalizeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.FinalizeLogSegmentRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoFinalizeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.QJournalProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.JournalResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DiscardSegmentsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoFinalizeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournalStateRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PurgeLogsResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.StartLogSegmentRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PrepareRecoveryResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoPreUpgradeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.AcceptRecoveryResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.IsFormattedRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.CanRollBackResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetEditLogManifestResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.StartLogSegmentRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.AcceptRecoveryRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoRollbackRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.JournalRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.HeartbeatResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournalStateResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.IsFormattedRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.FormatResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.RequestInfoProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournalCTimeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.FinalizeLogSegmentResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoRollbackRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.AcceptRecoveryRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.JournalRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.QJournalProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.FormatRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.JournalIdProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.FinalizeLogSegmentRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PersistedRecoveryPaxosData.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.NewEpochRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.FormatRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.CanRollBackResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.JournalIdProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.StartLogSegmentResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.StartLogSegmentResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournalCTimeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DiscardSegmentsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.FormatRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.HeartbeatResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoUpgradeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PrepareRecoveryRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.RequestInfoProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetEditLogManifestRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PurgeLogsResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoPreUpgradeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.SegmentStateProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.HeartbeatRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoPreUpgradeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetEditLogManifestResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoUpgradeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.QJournalProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.SegmentStateProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournalStateRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.JournalResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PurgeLogsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoPreUpgradeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.NewEpochResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.FormatResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.AcceptRecoveryResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoFinalizeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.FinalizeLogSegmentRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoFinalizeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.QJournalProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.JournalResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DiscardSegmentsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoFinalizeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournalStateRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PurgeLogsResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.StartLogSegmentRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PrepareRecoveryResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoPreUpgradeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.AcceptRecoveryResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.IsFormattedRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.CanRollBackResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetEditLogManifestResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.StartLogSegmentRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.AcceptRecoveryRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoRollbackRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.JournalRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.HeartbeatResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournalStateResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.IsFormattedRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.FormatResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.RequestInfoProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournalCTimeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.FinalizeLogSegmentResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PrepareRecoveryResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.StartLogSegmentResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PurgeLogsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PurgeLogsResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.IsFormattedRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.IsFormattedResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournalStateResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournaledEditsResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournaledEditsResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournalStateResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoRollbackResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/InterQJournalProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.HeartbeatRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DiscardSegmentsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.SegmentStateProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoUpgradeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PrepareRecoveryResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.StartLogSegmentRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/InterQJournalProtocolProtos.InterQJournalProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetEditLogManifestResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PrepareRecoveryRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoFinalizeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.HeartbeatResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournaledEditsResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoRollbackRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetEditLogManifestRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.CanRollBackResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/InterQJournalProtocolProtos.InterQJournalProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournaledEditsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.NewEpochRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DiscardSegmentsResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoUpgradeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PersistedRecoveryPaxosDataOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.FinalizeLogSegmentResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournalCTimeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.FinalizeLogSegmentResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.FormatResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.RequestInfoProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DiscardSegmentsResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.AcceptRecoveryRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.HeartbeatRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.JournalRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.NewEpochResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.AcceptRecoveryResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournaledEditsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournaledEditsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DiscardSegmentsResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournalCTimeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.FinalizeLogSegmentRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoUpgradeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetEditLogManifestRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoPreUpgradeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.JournalResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.NewEpochRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/InterQJournalProtocolProtos.InterQJournalProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoRollbackResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.IsFormattedResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.CanRollBackRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.IsFormattedResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoFinalizeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoRollbackResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PersistedRecoveryPaxosData.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoFinalizeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournalCTimeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/InterQJournalProtocolProtos.InterQJournalProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PrepareRecoveryRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoPreUpgradeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.NewEpochResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.CanRollBackRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.PurgeLogsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.CanRollBackRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournalCTimeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.QJournalProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.GetJournalStateRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.JournalIdProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/class-use/QJournalProtocolProtos.DoUpgradeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PrepareRecoveryResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.StartLogSegmentResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PurgeLogsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PurgeLogsResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.IsFormattedRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.IsFormattedResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournalStateResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournaledEditsResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournaledEditsResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournalStateResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoRollbackResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/InterQJournalProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.HeartbeatRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DiscardSegmentsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.SegmentStateProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoUpgradeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PrepareRecoveryResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.StartLogSegmentRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/InterQJournalProtocolProtos.InterQJournalProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetEditLogManifestResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PrepareRecoveryRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoFinalizeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.HeartbeatResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournaledEditsResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoRollbackRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetEditLogManifestRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.CanRollBackResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/InterQJournalProtocolProtos.InterQJournalProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournaledEditsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.NewEpochRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DiscardSegmentsResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoUpgradeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PersistedRecoveryPaxosDataOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.FinalizeLogSegmentResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournalCTimeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.FinalizeLogSegmentResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.FormatResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.RequestInfoProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DiscardSegmentsResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.AcceptRecoveryRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.HeartbeatRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.JournalRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.NewEpochResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.AcceptRecoveryResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournaledEditsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournaledEditsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DiscardSegmentsResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournalCTimeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.FinalizeLogSegmentRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoUpgradeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetEditLogManifestRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoPreUpgradeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.JournalResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.NewEpochRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/InterQJournalProtocolProtos.InterQJournalProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoRollbackResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.IsFormattedResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.CanRollBackRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.IsFormattedResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoFinalizeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoRollbackResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PersistedRecoveryPaxosData.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoFinalizeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournalCTimeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/InterQJournalProtocolProtos.InterQJournalProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PrepareRecoveryRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoPreUpgradeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.NewEpochResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.CanRollBackRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.PurgeLogsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.CanRollBackRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournalCTimeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.QJournalProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournalStateRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.JournalIdProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.DoUpgradeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/server/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/server/JournalNodeMXBean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/server/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/server/class-use/JournalNodeMXBean.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/server/class-use/Journal.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/server/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/server/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/server/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/server/Journal.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/server/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocolPB/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocolPB/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocolPB/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocolPB/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/protocolPB/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/client/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/client/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/client/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/client/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/qjournal/client/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/HdfsDtFetcher.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/org/apache/hadoop/hdfs/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/overview-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/overview-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/allclasses-noframe.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/build/source/hadoop-hdfs-project/hadoop-hdfs/target/api/package-list\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HdfsRollingUpgrade.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HdfsSnapshots.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/SLGUserGuide.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/LibHdfs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/TransparentEncryption.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/HDFSDiskbalancer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/expanded.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/banner.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/icon_warning_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/collapsed.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/logo_apache.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/newwindow.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/h5.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/apache-maven-project-2.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/external.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/h3.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/icon_success_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/maven-logo-2.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/logo_maven.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/breadcrumbs.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/logos/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/logos/build-by-maven-white.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/logos/maven-feather.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/logos/build-by-maven-black.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/icon_info_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/bg.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/images/icon_error_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/HDFSRouterFederation.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/hdfs-rbf-default.xml\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/configuration.xsl\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/routerfederation.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/expanded.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/banner.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/icon_warning_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/collapsed.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/logo_apache.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/newwindow.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/h5.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/apache-maven-project-2.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/external.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/h3.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/icon_success_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/maven-logo-2.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/logo_maven.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/breadcrumbs.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/logos/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/logos/build-by-maven-white.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/logos/maven-feather.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/logos/build-by-maven-black.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/icon_info_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/bg.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/images/icon_error_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/project-reports.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/serialized-form.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/index.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/stylesheet.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/index-all.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/constant-values.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/overview-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/help-doc.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/deprecated-list.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/allclasses-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/script.js\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/RouterProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/class-use/RouterProtocolProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/class-use/RouterProtocolProtos.RouterAdminProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/class-use/RouterProtocolProtos.RouterAdminProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/class-use/RouterProtocolProtos.RouterAdminProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/class-use/RouterProtocolProtos.RouterAdminProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/RouterProtocolProtos.RouterAdminProtocolService.Interface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/RouterProtocolProtos.RouterAdminProtocolService.Stub.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/RouterProtocolProtos.RouterAdminProtocolService.BlockingInterface.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/RouterProtocolProtos.RouterAdminProtocolService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocol/proto/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterHttpServer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterStateManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterQuotaUsage.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterQuotaUpdateService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterCacheAdmin.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterQuotaManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/MountTableRefresherService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/ConnectionContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RemoteResult.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterStoragePolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/PeriodicService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/ConnectionNullException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/MountTableRefresherThread.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RemoteLocationContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/Quota.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/FederationUtil.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterNamenodeProtocol.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/NoNamenodesAvailableException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/NameserviceManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterClientProtocol.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/IsRouterActiveServlet.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterWebHdfsMethods.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RemoteMethod.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterAdminServer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterPermissionChecker.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/SubClusterTimeoutException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/DFSRouter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterRpcClient.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterServiceState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterHeartbeatService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/NamenodeHeartbeatService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RemoteParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/ErasureCoding.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterMetricsService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterRpcMonitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/ConnectionManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterUserProtocol.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterSnapshot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterSafemodeService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterMetrics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterQuotaUsage.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/class-use/RouterRpcServer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/security/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/security/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/security/class-use/RouterSecurityManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/security/token/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/security/token/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/router/security/token/class-use/ZKDelegationTokenSecretManagerImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/metrics/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/metrics/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/metrics/class-use/NamenodeBeanMetrics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/metrics/class-use/FederationRPCPerformanceMonitor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/metrics/class-use/NullStateStoreMetrics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/metrics/class-use/RBFMetrics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/metrics/class-use/StateStoreMetrics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/metrics/class-use/FederationRPCMetrics.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetNamespaceInfoResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/LeaveSafeModeRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetNamenodeRegistrationsRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/EnableNameserviceResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/UpdateNamenodeRegistrationRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/RefreshSuperUserGroupsConfigurationResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/EnableNameserviceRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetDestinationResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/RemoveMountTableEntryRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetRouterRegistrationsRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/RefreshSuperUserGroupsConfigurationRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetMountTableEntriesRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/DisableNameserviceRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetDestinationRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetSafeModeResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/RemoveMountTableEntryResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/RefreshMountTableEntriesRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/EnterSafeModeRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/UpdateMountTableEntryResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/LeaveSafeModeResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetSafeModeRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/UpdateMountTableEntryRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/NamenodeHeartbeatResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/RouterHeartbeatRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetRouterRegistrationsResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/RefreshMountTableEntriesResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetNamenodeRegistrationsResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetRouterRegistrationRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetMountTableEntriesResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetDisabledNameservicesResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/DisableNameserviceResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/NamenodeHeartbeatRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/EnterSafeModeResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetDisabledNameservicesRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/UpdateNamenodeRegistrationResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/AddMountTableEntryResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/RouterHeartbeatResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/AddMountTableEntryRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetNamespaceInfoRequest.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/class-use/GetRouterRegistrationResponse.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetNamenodeRegistrationsRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetDestinationRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetDisabledNameservicesRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/LeaveSafeModeResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/EnableNameserviceResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/EnterSafeModeResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetNamespaceInfoResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/FederationProtocolPBTranslator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetRouterRegistrationResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/RouterHeartbeatResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetRouterRegistrationsRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/UpdateNamenodeRegistrationRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/NamenodeHeartbeatResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetDisabledNameservicesResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/RefreshSuperUserGroupsConfigurationRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/RefreshMountTableEntriesResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetSafeModeRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/NamenodeHeartbeatRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/RouterHeartbeatRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/UpdateNamenodeRegistrationResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetNamenodeRegistrationsResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/DisableNameserviceResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetSafeModeResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetMountTableEntriesResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/RefreshSuperUserGroupsConfigurationResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/EnableNameserviceRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/AddMountTableEntryResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetRouterRegistrationRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/EnterSafeModeRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/RefreshMountTableEntriesRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/UpdateMountTableEntryResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetRouterRegistrationsResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/DisableNameserviceRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/RemoveMountTableEntryRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetMountTableEntriesRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/RemoveMountTableEntryResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/AddMountTableEntryRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/UpdateMountTableEntryRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetDestinationResponsePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/GetNamespaceInfoRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/protocol/impl/pb/class-use/LeaveSafeModeRequestPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/class-use/CachedRecordStore.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/class-use/StateStoreConnectionMonitorService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/class-use/StateStoreUnavailableException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/class-use/StateStoreCacheUpdateService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/class-use/StateStoreUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/class-use/StateStoreCache.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/driver/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/driver/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/driver/class-use/StateStoreSerializer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/driver/class-use/StateStoreDriver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/driver/impl/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/driver/impl/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/driver/impl/class-use/StateStoreZooKeeperImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/driver/impl/class-use/StateStoreFileImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/driver/impl/class-use/StateStoreFileSystemImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/driver/impl/class-use/StateStoreBaseImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/driver/impl/class-use/StateStoreSerializableImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/driver/impl/class-use/StateStoreFileBaseImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/driver/impl/class-use/StateStoreSerializerPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/class-use/QueryResult.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/class-use/StateStoreVersion.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/class-use/MountTable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/class-use/MembershipState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/class-use/BaseRecord.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/class-use/DisabledNameservice.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/class-use/Query.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/class-use/RouterState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/class-use/MembershipStats.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/impl/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/impl/pb/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/impl/pb/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/impl/pb/class-use/StateStoreVersionPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/impl/pb/class-use/MembershipStatsPBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/impl/pb/class-use/DisabledNameservicePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/impl/pb/class-use/PBRecord.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/impl/pb/class-use/MembershipStatePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/impl/pb/class-use/MountTablePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/store/records/impl/pb/class-use/RouterStatePBImpl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/NamenodePriorityComparator.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/PathLocation.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/RouterResolveException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/FederationNamespaceInfo.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/MembershipNamenodeResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/RouterGenericManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/RemoteLocation.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/MountTableResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/NamenodeStatusReport.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/FederationNamenodeContext.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/MountTableManager.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/FederationNamenodeServiceState.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/class-use/MultipleDestinationMountTableResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/order/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/order/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/order/class-use/HashFirstResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/order/class-use/AvailableSpaceResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/order/class-use/DestinationOrder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/order/class-use/OrderedResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/order/class-use/RouterResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/order/class-use/LocalResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/order/class-use/HashResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/resolver/order/class-use/RandomResolver.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/utils/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/utils/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/server/federation/utils/class-use/ConsistentHashRing.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocolPB/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocolPB/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocolPB/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocolPB/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/protocolPB/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetDestinationResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetNamenodeRegistrationsResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetRouterRegistrationRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.AddMountTableEntryResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.DisableNameserviceResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.UpdateNamenodeRegistrationResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RemoteLocationProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RefreshMountTableEntriesResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.DisableNameserviceResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.AddMountTableEntryResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.LeaveSafeModeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RemoveMountTableEntryResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.AddMountTableEntryRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.FederationNamespaceInfoProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.UpdateMountTableEntryResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetNamenodeRegistrationsResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.EnableNameserviceRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetDestinationResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.EnableNameserviceRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.NamenodeHeartbeatRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RefreshMountTableEntriesRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetDisabledNameservicesRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RemoveMountTableEntryRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.DisableNameserviceRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RefreshMountTableEntriesRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetRouterRegistrationRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RemoveMountTableEntryResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.LeaveSafeModeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RefreshMountTableEntriesResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RemoveMountTableEntryRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetRouterRegistrationsResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.MountTableRecordProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RouterHeartbeatRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.LeaveSafeModeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RefreshMountTableEntriesResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.EnableNameserviceResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RefreshSuperUserGroupsConfigurationResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RouterHeartbeatResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetSafeModeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.EnterSafeModeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetDestinationRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.DisabledNameserviceRecordProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.StateStoreVersionRecordProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetNamespaceInfoRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetDisabledNameservicesResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.MountTableRecordProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.UpdateNamenodeRegistrationRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.DisableNameserviceRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetNamenodeRegistrationsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.StateStoreVersionRecordProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RemoteLocationProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RefreshMountTableEntriesRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetDestinationResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetNamenodeRegistrationsResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetRouterRegistrationRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.AddMountTableEntryResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.DisableNameserviceResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.UpdateNamenodeRegistrationResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RemoteLocationProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RefreshMountTableEntriesResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.DisableNameserviceResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.AddMountTableEntryResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.LeaveSafeModeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RemoveMountTableEntryResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.AddMountTableEntryRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.FederationNamespaceInfoProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.UpdateMountTableEntryResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetNamenodeRegistrationsResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.EnableNameserviceRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetDestinationResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.EnableNameserviceRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.NamenodeHeartbeatRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RefreshMountTableEntriesRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetDisabledNameservicesRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RemoveMountTableEntryRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.DisableNameserviceRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RefreshMountTableEntriesRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetRouterRegistrationRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RemoveMountTableEntryResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.LeaveSafeModeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RefreshMountTableEntriesResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RemoveMountTableEntryRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetRouterRegistrationsResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.MountTableRecordProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RouterHeartbeatRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.LeaveSafeModeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RefreshMountTableEntriesResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.EnableNameserviceResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RefreshSuperUserGroupsConfigurationResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RouterHeartbeatResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetSafeModeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.EnterSafeModeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetDestinationRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.DisabledNameserviceRecordProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.StateStoreVersionRecordProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetNamespaceInfoRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetDisabledNameservicesResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.MountTableRecordProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.UpdateNamenodeRegistrationRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.DisableNameserviceRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetNamenodeRegistrationsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.StateStoreVersionRecordProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RemoteLocationProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RefreshMountTableEntriesRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetDisabledNameservicesResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.UpdateMountTableEntryResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.DisableNameserviceResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetDestinationResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RemoveMountTableEntryRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.NamenodeMembershipStatsRecordProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetDestinationRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.NamenodeHeartbeatRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.DisabledNameserviceRecordProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.EnterSafeModeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.EnterSafeModeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.LeaveSafeModeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.UpdateMountTableEntryRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetRouterRegistrationResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetMountTableEntriesRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.StateStoreVersionRecordProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.EnterSafeModeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetExpiredRegistrationsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.EnableNameserviceRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.EnterSafeModeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RefreshSuperUserGroupsConfigurationResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.UpdateNamenodeRegistrationRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetRouterRegistrationRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetSafeModeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetNamespaceInfoResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetDisabledNameservicesRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetNamespaceInfoRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RouterRecordProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.FederationNamespaceInfoProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.UpdateMountTableEntryResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.LeaveSafeModeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetSafeModeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.NamenodeHeartbeatRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RouterHeartbeatRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.UpdateMountTableEntryRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetNamespaceInfoResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetMountTableEntriesRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetRouterRegistrationsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.NamenodeMembershipRecordProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.DisableNameserviceRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.FederationNamespaceInfoProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.AddMountTableEntryRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.EnableNameserviceResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetMountTableEntriesResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RefreshSuperUserGroupsConfigurationResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.EnterSafeModeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.NamenodeHeartbeatResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.AddMountTableEntryResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetRouterRegistrationsResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.MountTableRecordProto.DestOrder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetRouterRegistrationsResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetSafeModeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.LeaveSafeModeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetRouterRegistrationResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetSafeModeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.NamenodeHeartbeatResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RefreshSuperUserGroupsConfigurationRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetRouterRegistrationResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RefreshSuperUserGroupsConfigurationRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetSafeModeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.NamenodeMembershipStatsRecordProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetExpiredRegistrationsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetExpiredRegistrationsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.UpdateNamenodeRegistrationResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RemoveMountTableEntryResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.EnableNameserviceResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RouterRecordProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.UpdateMountTableEntryRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetNamespaceInfoRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetMountTableEntriesResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetMountTableEntriesResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.NamenodeHeartbeatResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.DisabledNameserviceRecordProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetDisabledNameservicesResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.MountTableRecordProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetMountTableEntriesRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.AddMountTableEntryRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.UpdateNamenodeRegistrationResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetNamenodeRegistrationsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetNamenodeRegistrationsResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.NamenodeMembershipStatsRecordProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RouterHeartbeatResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetDestinationRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RefreshSuperUserGroupsConfigurationRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetRouterRegistrationsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetNamenodeRegistrationsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.NamenodeMembershipRecordProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RouterHeartbeatResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.UpdateNamenodeRegistrationRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetDisabledNameservicesRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.NamenodeMembershipRecordProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetNamespaceInfoResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RemoteLocationProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RouterHeartbeatRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.RouterRecordProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/class-use/HdfsServerFederationProtos.GetRouterRegistrationsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetDisabledNameservicesResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.UpdateMountTableEntryResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.DisableNameserviceResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetDestinationResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RemoveMountTableEntryRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.NamenodeMembershipStatsRecordProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetDestinationRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.NamenodeHeartbeatRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.DisabledNameserviceRecordProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.EnterSafeModeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.EnterSafeModeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.LeaveSafeModeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.UpdateMountTableEntryRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetRouterRegistrationResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetMountTableEntriesRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.StateStoreVersionRecordProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.EnterSafeModeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetExpiredRegistrationsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.EnableNameserviceRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.EnterSafeModeRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RefreshSuperUserGroupsConfigurationResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.UpdateNamenodeRegistrationRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetRouterRegistrationRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetSafeModeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetNamespaceInfoResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetDisabledNameservicesRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetNamespaceInfoRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RouterRecordProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.FederationNamespaceInfoProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.UpdateMountTableEntryResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.LeaveSafeModeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetSafeModeRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.NamenodeHeartbeatRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RouterHeartbeatRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.UpdateMountTableEntryRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetNamespaceInfoResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetMountTableEntriesRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetRouterRegistrationsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.NamenodeMembershipRecordProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.DisableNameserviceRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.FederationNamespaceInfoProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.AddMountTableEntryRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.EnableNameserviceResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetMountTableEntriesResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RefreshSuperUserGroupsConfigurationResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.EnterSafeModeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.NamenodeHeartbeatResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.AddMountTableEntryResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetRouterRegistrationsResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.MountTableRecordProto.DestOrder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetRouterRegistrationsResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetSafeModeResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.LeaveSafeModeResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetRouterRegistrationResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetSafeModeResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.NamenodeHeartbeatResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RefreshSuperUserGroupsConfigurationRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetRouterRegistrationResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RefreshSuperUserGroupsConfigurationRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetSafeModeRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.NamenodeMembershipStatsRecordProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetExpiredRegistrationsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetExpiredRegistrationsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.UpdateNamenodeRegistrationResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RemoveMountTableEntryResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.EnableNameserviceResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RouterRecordProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.UpdateMountTableEntryRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetNamespaceInfoRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetMountTableEntriesResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetMountTableEntriesResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.NamenodeHeartbeatResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.DisabledNameserviceRecordProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetDisabledNameservicesResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.MountTableRecordProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetMountTableEntriesRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.AddMountTableEntryRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.UpdateNamenodeRegistrationResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetNamenodeRegistrationsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetNamenodeRegistrationsResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.NamenodeMembershipStatsRecordProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RouterHeartbeatResponseProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetDestinationRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RefreshSuperUserGroupsConfigurationRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetRouterRegistrationsRequestProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetNamenodeRegistrationsRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.NamenodeMembershipRecordProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RouterHeartbeatResponseProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.UpdateNamenodeRegistrationRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetDisabledNameservicesRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.NamenodeMembershipRecordProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetNamespaceInfoResponseProto.Builder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RemoteLocationProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RouterHeartbeatRequestProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.RouterRecordProtoOrBuilder.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/federation/protocol/proto/HdfsServerFederationProtos.GetRouterRegistrationsRequestProto.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/tools/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/tools/federation/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/tools/federation/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/tools/federation/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/tools/federation/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/org/apache/hadoop/hdfs/tools/federation/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/overview-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/overview-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/allclasses-noframe.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/build/source/hadoop-hdfs-project/hadoop-hdfs-rbf/target/api/package-list\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs-rbf/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/project-reports.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/expanded.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/banner.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/icon_warning_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/collapsed.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/logo_apache.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/newwindow.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/h5.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/apache-maven-project-2.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/external.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/h3.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/icon_success_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/maven-logo-2.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/logo_maven.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/breadcrumbs.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/logos/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/logos/build-by-maven-white.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/logos/maven-feather.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/logos/build-by-maven-black.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/icon_info_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/bg.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/images/icon_error_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/project-reports.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-tools-dist/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/expanded.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/banner.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/icon_warning_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/collapsed.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/logo_apache.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/newwindow.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/h5.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/apache-maven-project-2.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/external.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/h3.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/icon_success_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/maven-logo-2.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/logo_maven.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/breadcrumbs.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/logos/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/logos/build-by-maven-white.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/logos/maven-feather.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/logos/build-by-maven-black.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/icon_info_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/bg.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/images/icon_error_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/project-reports.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-dynamometer-dist/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/expanded.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/banner.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/icon_warning_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/collapsed.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/logo_apache.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/newwindow.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/h5.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/apache-maven-project-2.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/external.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/h3.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/icon_success_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/maven-logo-2.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/logo_maven.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/breadcrumbs.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/logos/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/logos/build-by-maven-white.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/logos/maven-feather.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/logos/build-by-maven-black.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/icon_info_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/bg.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/images/icon_error_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/project-reports.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/hadoop-client/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-project-dist/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/expanded.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/banner.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/icon_warning_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/collapsed.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/logo_apache.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/newwindow.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/h5.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/apache-maven-project-2.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/external.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/h3.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/icon_success_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/maven-logo-2.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/logo_maven.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/breadcrumbs.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/logos/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/logos/build-by-maven-white.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/logos/maven-feather.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/logos/build-by-maven-black.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/icon_info_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/bg.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/images/icon_error_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/project-reports.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-nfs/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/expanded.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/banner.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/icon_warning_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/collapsed.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/logo_apache.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/newwindow.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/h5.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/apache-maven-project-2.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/external.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/h3.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/icon_success_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/maven-logo-2.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/logo_maven.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/breadcrumbs.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/logos/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/logos/build-by-maven-white.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/logos/maven-feather.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/logos/build-by-maven-black.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/icon_info_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/bg.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/images/icon_error_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/project-reports.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-runtime/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/expanded.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/banner.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/icon_warning_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/collapsed.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/logo_apache.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/newwindow.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/h5.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/apache-maven-project-2.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/external.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/h3.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/icon_success_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/maven-logo-2.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/logo_maven.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/breadcrumbs.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/logos/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/logos/build-by-maven-white.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/logos/maven-feather.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/logos/build-by-maven-black.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/icon_info_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/bg.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/images/icon_error_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/project-reports.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-client-modules/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/expanded.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/banner.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/icon_warning_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/collapsed.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/logo_apache.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/newwindow.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/h5.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/apache-maven-project-2.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/external.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/h3.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/icon_success_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/maven-logo-2.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/logo_maven.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/breadcrumbs.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/logos/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/logos/build-by-maven-white.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/logos/maven-feather.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/logos/build-by-maven-black.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/icon_info_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/bg.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/images/icon_error_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/project-reports.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-annotations/dependency-analysis.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/index.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/expanded.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/banner.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/icon_warning_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/collapsed.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/logo_apache.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/newwindow.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/h5.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/apache-maven-project-2.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/external.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/h3.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/icon_success_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/maven-logo-2.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/logo_maven.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/breadcrumbs.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/logos/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/logos/build-by-maven-white.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/logos/maven-feather.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/logos/build-by-maven-black.png\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/icon_info_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/bg.jpg\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/images/icon_error_sml.gif\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/project-reports.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/ServerSetup.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/UsingHttpTools.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/css/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/css/maven-base.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/css/maven-theme.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/css/site.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/css/print.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/serialized-form.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/index.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/stylesheet.css\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/index-all.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/constant-values.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/overview-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/help-doc.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/deprecated-list.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/allclasses-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/script.js\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSDeleteSnapshot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSGetAllStoragePolicies.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSCreateSnapshot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSExceptionProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSSetReplication.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSListStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.SourcesParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.SnapshotNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSServerWebServer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSSetXAttr.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.XAttrValueParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.StartAfterParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSSetStoragePolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.ReplicationParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.ECPolicyParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSGetSnapshotDiff.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.OperationParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.UnmaskedPermissionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSRemoveAcl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.OldSnapshotNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/CheckUploadContentTypeFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.ModifiedTimeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSSatisyStoragePolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.NoRedirectParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSDeleteSnapshot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSGetAllStoragePolicies.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSCreateSnapshot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSExceptionProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSSetReplication.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSListStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.SourcesParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.SnapshotNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSServerWebServer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSSetXAttr.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.XAttrValueParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.StartAfterParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSSetStoragePolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.ReplicationParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.ECPolicyParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSGetSnapshotDiff.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.OperationParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.UnmaskedPermissionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSRemoveAcl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.OldSnapshotNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/CheckUploadContentTypeFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.ModifiedTimeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSSatisyStoragePolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.NoRedirectParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.GroupParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSRename.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSSetPermission.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.BlockSizeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.XAttrNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSListXAttrs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.OverwriteParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSServerWebApp.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSServer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSFileStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.FsActionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSOpen.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSAclStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSGetErasureCodingPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSSetErasureCodingPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.FilterParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSSetOwner.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSGetServerDefaults.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSGetStoragePolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.RecursiveParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSAppend.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSFileChecksum.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSReleaseFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.XAttrSetFlagParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSAllowSnapshot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.NewLengthParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSAccess.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.OffsetParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSRenameSnapshot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSUnSetErasureCodingPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSQuotaUsage.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSModifyAclEntries.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.DataParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSDelete.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSHomeDir.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSSetTimes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSSetAcl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.AccessTimeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSRemoveDefaultAcl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.PolicyNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSTruncate.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.PermissionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSCreate.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSTrashRoot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSAuthenticationFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSRemoveAclEntries.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSConcat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.OwnerParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSDisallowSnapshot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSListStatusBatch.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.DestinationParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSGetXAttrs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSRemoveXAttr.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.LenParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.AclPermissionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSContentSummary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSMkdirs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSGetSnapshottableDirListing.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/HttpFSParametersProvider.XAttrEncodingParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/class-use/FSOperations.FSUnsetStoragePolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.GroupParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSRename.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSSetPermission.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.BlockSizeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.XAttrNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSListXAttrs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.OverwriteParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSServerWebApp.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSServer.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSFileStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.FsActionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSOpen.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSAclStatus.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSGetErasureCodingPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSSetErasureCodingPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.FilterParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSSetOwner.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSGetServerDefaults.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSGetStoragePolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.RecursiveParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSAppend.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSFileChecksum.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSReleaseFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.XAttrSetFlagParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSAllowSnapshot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.NewLengthParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSAccess.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.OffsetParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSRenameSnapshot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSUnSetErasureCodingPolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSQuotaUsage.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSModifyAclEntries.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.DataParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSDelete.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSHomeDir.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSSetTimes.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSSetAcl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.AccessTimeParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSRemoveDefaultAcl.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.PolicyNameParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSTruncate.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.PermissionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSCreate.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSTrashRoot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSAuthenticationFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSRemoveAclEntries.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSConcat.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.OwnerParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSDisallowSnapshot.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSListStatusBatch.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.DestinationParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSGetXAttrs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSRemoveXAttr.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.LenParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.AclPermissionParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSContentSummary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSMkdirs.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSGetSnapshottableDirListing.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/HttpFSParametersProvider.XAttrEncodingParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/server/FSOperations.FSUnsetStoragePolicy.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/class-use/HttpFSFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/class-use/HttpFSUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/class-use/HttpsFSFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/class-use/HttpFSFileSystem.Operation.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/class-use/HttpFSFileSystem.FILE_TYPE.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/HttpFSFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/HttpFSUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/HttpsFSFileSystem.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/HttpFSFileSystem.Operation.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/HttpFSFileSystem.FILE_TYPE.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/fs/http/client/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/lang/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/lang/RunnableCallable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/lang/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/lang/class-use/RunnableCallable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/lang/class-use/XException.ERROR.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/lang/class-use/XException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/lang/XException.ERROR.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/lang/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/lang/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/lang/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/lang/XException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/lang/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/util/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/util/ConfigurationUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/util/Check.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/util/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/util/class-use/ConfigurationUtils.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/util/class-use/Check.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/util/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/util/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/util/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/util/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/Server.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/class-use/Server.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/class-use/Service.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/class-use/ServerException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/class-use/Server.Status.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/class-use/BaseService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/class-use/ServerException.ERROR.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/class-use/ServiceException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/Service.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/ServerException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/Server.Status.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/BaseService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/ServerException.ERROR.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/ServiceException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/server/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/MDCFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/ServerWebApp.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/HostnameFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/class-use/MDCFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/class-use/ServerWebApp.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/class-use/HostnameFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/class-use/FileSystemReleaseFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/FileSystemReleaseFilter.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/servlet/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/Scheduler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/scheduler/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/scheduler/SchedulerService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/scheduler/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/scheduler/class-use/SchedulerService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/scheduler/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/scheduler/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/scheduler/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/scheduler/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/Instrumentation.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/instrumentation/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/instrumentation/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/instrumentation/class-use/InstrumentationService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/instrumentation/InstrumentationService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/instrumentation/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/instrumentation/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/instrumentation/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/instrumentation/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/Groups.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/FileSystemAccess.FileSystemExecutor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/class-use/Scheduler.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/class-use/Instrumentation.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/class-use/Groups.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/class-use/FileSystemAccess.FileSystemExecutor.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/class-use/Instrumentation.Cron.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/class-use/FileSystemAccessException.ERROR.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/class-use/FileSystemAccessException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/class-use/Instrumentation.Variable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/class-use/FileSystemAccess.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/Instrumentation.Cron.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/security/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/security/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/security/class-use/GroupsService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/security/GroupsService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/security/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/security/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/security/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/security/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/hadoop/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/hadoop/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/hadoop/class-use/FileSystemAccessService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/hadoop/FileSystemAccessService.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/hadoop/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/hadoop/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/hadoop/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/hadoop/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/FileSystemAccessException.ERROR.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/FileSystemAccessException.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/Instrumentation.Variable.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/FileSystemAccess.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/service/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/EnumSetParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/Parameters.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/BooleanParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/ShortParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/StringParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/JSONMapProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/ExceptionProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/IntegerParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/Param.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/EnumSetParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/Parameters.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/BooleanParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/ShortParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/StringParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/JSONMapProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/ExceptionProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/IntegerParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/Param.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/LongParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/ParametersProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/JSONProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/EnumParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/ByteParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/class-use/InputStreamEntity.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/LongParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/ParametersProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/JSONProvider.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/EnumParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/ByteParam.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/package-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/InputStreamEntity.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/package-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/package-use.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/org/apache/hadoop/lib/wsrs/package-tree.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/overview-summary.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/overview-frame.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/allclasses-noframe.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/apidocs/package-list\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/httpfs-default.html\n",
            "hadoop-3.3.0/share/doc/hadoop/hadoop-hdfs-httpfs/dependency-analysis.html\n",
            "hadoop-3.3.0/lib/\n",
            "hadoop-3.3.0/lib/native/\n",
            "hadoop-3.3.0/lib/native/libhadoop.a\n",
            "hadoop-3.3.0/lib/native/libhadooputils.a\n",
            "hadoop-3.3.0/lib/native/libhadoop.so.1.0.0\n",
            "hadoop-3.3.0/lib/native/examples/\n",
            "hadoop-3.3.0/lib/native/examples/wordcount-simple\n",
            "hadoop-3.3.0/lib/native/examples/pipes-sort\n",
            "hadoop-3.3.0/lib/native/examples/wordcount-nopipe\n",
            "hadoop-3.3.0/lib/native/examples/wordcount-part\n",
            "hadoop-3.3.0/lib/native/libnativetask.so\n",
            "hadoop-3.3.0/lib/native/libhadoop.so\n",
            "hadoop-3.3.0/lib/native/libhadooppipes.a\n",
            "hadoop-3.3.0/lib/native/libnativetask.so.1.0.0\n",
            "hadoop-3.3.0/lib/native/libhdfs.so.0.0.0\n",
            "hadoop-3.3.0/lib/native/libhdfs.a\n",
            "hadoop-3.3.0/lib/native/libhdfs.so\n",
            "hadoop-3.3.0/lib/native/libnativetask.a\n",
            "hadoop-3.3.0/etc/\n",
            "hadoop-3.3.0/etc/hadoop/\n",
            "hadoop-3.3.0/etc/hadoop/hadoop-env.cmd\n",
            "hadoop-3.3.0/etc/hadoop/workers\n",
            "hadoop-3.3.0/etc/hadoop/log4j.properties\n",
            "hadoop-3.3.0/etc/hadoop/yarnservice-log4j.properties\n",
            "hadoop-3.3.0/etc/hadoop/hadoop-policy.xml\n",
            "hadoop-3.3.0/etc/hadoop/kms-acls.xml\n",
            "hadoop-3.3.0/etc/hadoop/hdfs-rbf-site.xml\n",
            "hadoop-3.3.0/etc/hadoop/configuration.xsl\n",
            "hadoop-3.3.0/etc/hadoop/container-executor.cfg\n",
            "hadoop-3.3.0/etc/hadoop/ssl-client.xml.example\n",
            "hadoop-3.3.0/etc/hadoop/httpfs-env.sh\n",
            "hadoop-3.3.0/etc/hadoop/hadoop-user-functions.sh.example\n",
            "hadoop-3.3.0/etc/hadoop/ssl-server.xml.example\n",
            "hadoop-3.3.0/etc/hadoop/shellprofile.d/\n",
            "hadoop-3.3.0/etc/hadoop/shellprofile.d/example.sh\n",
            "hadoop-3.3.0/etc/hadoop/hdfs-site.xml\n",
            "hadoop-3.3.0/etc/hadoop/kms-env.sh\n",
            "hadoop-3.3.0/etc/hadoop/core-site.xml\n",
            "hadoop-3.3.0/etc/hadoop/hadoop-env.sh\n",
            "hadoop-3.3.0/etc/hadoop/mapred-queues.xml.template\n",
            "hadoop-3.3.0/etc/hadoop/yarn-env.cmd\n",
            "hadoop-3.3.0/etc/hadoop/mapred-env.cmd\n",
            "hadoop-3.3.0/etc/hadoop/yarn-env.sh\n",
            "hadoop-3.3.0/etc/hadoop/httpfs-site.xml\n",
            "hadoop-3.3.0/etc/hadoop/kms-log4j.properties\n",
            "hadoop-3.3.0/etc/hadoop/mapred-site.xml\n",
            "hadoop-3.3.0/etc/hadoop/yarn-site.xml\n",
            "hadoop-3.3.0/etc/hadoop/capacity-scheduler.xml\n",
            "hadoop-3.3.0/etc/hadoop/hadoop-metrics2.properties\n",
            "hadoop-3.3.0/etc/hadoop/user_ec_policies.xml.template\n",
            "hadoop-3.3.0/etc/hadoop/mapred-env.sh\n",
            "hadoop-3.3.0/etc/hadoop/kms-site.xml\n",
            "hadoop-3.3.0/etc/hadoop/httpfs-log4j.properties\n"
          ]
        }
      ],
      "source": [
        "!tar -xzvf hadoop-3.3.0.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMihsUJcb8mc"
      },
      "source": [
        "Copie du dossier extrait dans l'emplacement <user/local>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiZu2f2MvfFJ"
      },
      "outputs": [],
      "source": [
        "!cp -r hadoop-3.3.0/ /usr/local/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPA7R0jj7Efs"
      },
      "source": [
        "## Programmation de tâches distribuées avec <i>MapReduce</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrgy3AhU6-ue"
      },
      "source": [
        "Création d'un repertoire <myinput> pour contenir le jeu de données à tester durant cet exercice e d'un second pour les résultats du traitement distribué"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdW4R_x5vqoo"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/myinput\n",
        "!mkdir -p ~/myoutput"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YYbaWQKbwgI"
      },
      "source": [
        "Télachargement du jeu de données dans le fichier <u>purchases.txt</u>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1H5BOHtGgvK",
        "outputId": "a1de55c9-8149-46d2-892e-4189385e240d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  201M  100  201M    0     0   142M      0  0:00:01  0:00:01 --:--:--  204M\n"
          ]
        }
      ],
      "source": [
        "!curl -L -o 'purchases.txt' 'https://drive.google.com/u/0/uc?id=1NS-PSXW8bSNpzFH4XRbtmMnMGhXBdYy6&export=download&confirm=t'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4UhTIPWHalM"
      },
      "source": [
        "Déplacement du fichier <u>purchases.txt</u> dans le répertoire <myinput>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxrmwexRvtra"
      },
      "outputs": [],
      "source": [
        "!mv purchases.txt ~/myinput/purchases.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU3iICMSbt5b"
      },
      "source": [
        "Vérification que les fichiers ont été bien copiés"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pNAZrlXvxax",
        "outputId": "36abc9fa-16ed-4a26-83cf-3955db1c512d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "purchases.txt\n"
          ]
        }
      ],
      "source": [
        "!ls ~/myinput"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg4_s72GbrXI"
      },
      "source": [
        "Affichage des premiers lignes du fichier. Le format des enregistrement est le suivant:\n",
        "<table border='1'><tr>\n",
        "<td>Date</td><td>Heure</td><td>Magasin</td><td>Produit</td><td>Montant</td><td>Moyen_de_paiement</td>\n",
        "</tr></table>\n",
        "La tabulation <b>\\t</b> est utilisée comme séparateur de colonne ✅"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz1Hu-tgvz32",
        "outputId": "8f8779a5-cd4a-4049-9c6f-00fdac33d72f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2012-01-01\t09:00\tSan Jose\tMen's Clothing\t214.05\tAmex\n",
            "2012-01-01\t09:00\tFort Worth\tWomen's Clothing\t153.57\tVisa\n",
            "2012-01-01\t09:00\tSan Diego\tMusic\t66.08\tCash\n",
            "2012-01-01\t09:00\tPittsburgh\tPet Supplies\t493.51\tDiscover\n",
            "2012-01-01\t09:00\tOmaha\tChildren's Clothing\t235.63\tMasterCard\n",
            "2012-01-01\t09:00\tStockton\tMen's Clothing\t247.18\tMasterCard\n",
            "2012-01-01\t09:00\tAustin\tCameras\t379.6\tVisa\n",
            "2012-01-01\t09:00\tNew York\tConsumer Electronics\t296.8\tCash\n",
            "2012-01-01\t09:00\tCorpus Christi\tToys\t25.38\tDiscover\n",
            "2012-01-01\t09:00\tFort Worth\tToys\t213.88\tVisa\n"
          ]
        }
      ],
      "source": [
        "!head -10  ~/myinput/purchases.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y1p3diBzHnO"
      },
      "source": [
        "## Activité 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKN45LMXblJb"
      },
      "source": [
        "Le travail consiste à utiliser <i>MapReduce</i> avec le langage Python et effectuer un traitement distribué. Notre but est de déterminer le total des achats par magasin en exploitant les données du fichier <purchases.txt>.\n",
        "\n",
        "Vous devrez implémenter les fonctions <i>Map<i> et <i>Reduce</> du traitement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwmgOTGZbap2"
      },
      "source": [
        "Contenu de traitement dans la phase \\<map>. <h2>C'est à vous de le faire &#8987;</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DORC5LGPzXTf"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "import sys\n",
        "# Mettez vos instructions ...\n",
        "for line in sys.stdin:\n",
        "  data = line.strip().split(\"\\t\")\n",
        "  if len(data) == 6:\n",
        "    date, time, store, item, amount, payment = data\n",
        "    print(store, \"\\t\", str(amount))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FMoUYz0bJk6"
      },
      "source": [
        "Sauvegarde du code de traitement de la phase <map> dans le fichier \"/content/map.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hF1orBgT3xZk"
      },
      "outputs": [],
      "source": [
        "# All cell codes are stored in a List variable \"In\"\n",
        "with open('/content/mapper.py', 'w') as f:\n",
        "  f.write(In[11]) \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmdthu1tT9ah"
      },
      "source": [
        "Attribution de permission d'accès et d'exécution sur le fichier <mapper.py>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4o54WVW0UENR"
      },
      "outputs": [],
      "source": [
        "!chmod u+rwx /content/mapper.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaCsrIzRTHRV"
      },
      "source": [
        "Test du traitement de la phase <map> sur quelques enregistrements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkc1LChRTIoj",
        "outputId": "8a428a7b-9834-480e-e533-2679b6125236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "San Jose \t 214.05\n",
            "Fort Worth \t 153.57\n",
            "San Diego \t 66.08\n",
            "Pittsburgh \t 493.51\n",
            "Omaha \t 235.63\n",
            "Stockton \t 247.18\n",
            "Austin \t 379.6\n",
            "New York \t 296.8\n",
            "Corpus Christi \t 25.38\n",
            "Fort Worth \t 213.88\n"
          ]
        }
      ],
      "source": [
        "!head -10 ~/myinput/purchases.txt | python3 /content/mapper.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMb1kR3ibXTy"
      },
      "source": [
        "Contenu de traitement de la phase \\<reduce>. <h2>C'est à vous de le faire aussi &#128521;</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47sDnvcIzfsJ"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "from operator import itemgetter\n",
        "import sys\n",
        "# Mettez vos instructions ...\n",
        "salesTotal = 0\n",
        "oldKey = None\n",
        "\n",
        "for line in sys.stdin:\n",
        "  data = line.strip().split(\"\\t\")\n",
        "  if len(data) != 2:\n",
        "    continue\n",
        "  \n",
        "  thisKey, thisSale = data\n",
        "  if oldKey and oldKey != thisKey:\n",
        "    print(oldKey, \"\\t\", str(salesTotal))\n",
        "    salesTotal = 0\n",
        "    \n",
        "  oldKey = thisKey\n",
        "  salesTotal += float (thisSale)\n",
        "\n",
        "if oldKey != None:\n",
        "  print(oldKey, \"\\t\", str(salesTotal))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4-Y8tM7bO_P"
      },
      "source": [
        "Sauvegarde du code de traitement de la phase <reduce> dans le fichier \"/content/reduce.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQBTPRMtz_M_"
      },
      "outputs": [],
      "source": [
        "# All cell codes are stored in a List variable \"In\"\n",
        "with open('/content/reducer.py', 'w') as f:\n",
        "  f.write(In[15]) \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmGnEPdz5YO-"
      },
      "source": [
        "Attribution de permission d'accès et d'exécution sur le fichier <reducer.py>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY6L7F6G5LJX"
      },
      "outputs": [],
      "source": [
        "!chmod u+rwx /content/reducer.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrMCnnh7UZAp"
      },
      "source": [
        "Test du traitement distribué sur quelques enregistrements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aPj3aTbUfNV",
        "outputId": "8df16726-3af7-41a7-a098-4414d64dd758"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anchorage  \t 327.6\n",
            "Aurora  \t 117.81\n",
            "Austin  \t 1176.98\n",
            "Boston  \t 418.94\n",
            "Buffalo  \t 483.82\n",
            "Chandler  \t 758.17\n",
            "Chicago  \t 31.08\n",
            "Corpus Christi  \t 25.38\n",
            "Fort Wayne  \t 370.55\n",
            "Fort Worth  \t 367.45\n",
            "Fremont  \t 222.61\n",
            "Fresno  \t 466.64\n",
            "Greensboro  \t 290.82\n",
            "Honolulu  \t 345.18\n",
            "Houston  \t 309.16\n",
            "Indianapolis  \t 135.96\n",
            "Las Vegas  \t 146.65\n",
            "Lincoln  \t 136.9\n",
            "Madison  \t 16.78\n",
            "Minneapolis  \t 182.05\n",
            "Newark  \t 39.75\n",
            "New York  \t 296.8\n",
            "Norfolk  \t 189.01\n",
            "Omaha  \t 491.31\n",
            "Philadelphia  \t 351.31\n",
            "Pittsburgh  \t 968.77\n",
            "Portland  \t 108.69\n",
            "Reno  \t 168.70999999999998\n",
            "Riverside  \t 268.29\n",
            "San Bernardino  \t 170.2\n",
            "San Diego  \t 66.08\n",
            "San Francisco  \t 260.65\n",
            "San Jose  \t 429.87\n",
            "Spokane  \t 291.5\n",
            "Stockton  \t 247.18\n",
            "Tulsa  \t 205.06\n",
            "Virginia Beach  \t 376.11\n"
          ]
        }
      ],
      "source": [
        "!head -50 ~/myinput/purchases.txt | python3 /content/mapper.py | sort | python3 /content/reducer.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qORR_Ag5WR1"
      },
      "source": [
        "Lancement d'un job entier. Le résultat est dans le dossier \"~/tryout\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGE52cAm5ZyW",
        "outputId": "5d77e49a-211c-48b4-c2d2-18f3d1106455"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-17 14:01:17,373 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
            "packageJobJar: [/content/mapper.py, /content/reducer.py] [] /tmp/streamjob5218509498225147991.jar tmpDir=null\n",
            "2023-01-17 14:01:18,373 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2023-01-17 14:01:18,505 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2023-01-17 14:01:18,505 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2023-01-17 14:01:18,527 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2023-01-17 14:01:18,716 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2023-01-17 14:01:18,740 INFO mapreduce.JobSubmitter: number of splits:7\n",
            "2023-01-17 14:01:18,996 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local534642282_0001\n",
            "2023-01-17 14:01:18,996 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2023-01-17 14:01:19,393 INFO mapred.LocalDistributedCacheManager: Localized file:/content/mapper.py as file:/tmp/hadoop-root/mapred/local/job_local534642282_0001_b556b1e2-6517-4d15-ad2c-2934ecf80b87/mapper.py\n",
            "2023-01-17 14:01:19,420 INFO mapred.LocalDistributedCacheManager: Localized file:/content/reducer.py as file:/tmp/hadoop-root/mapred/local/job_local534642282_0001_bb3b0ad1-9ed1-445d-bd00-efcd24ba32bd/reducer.py\n",
            "2023-01-17 14:01:19,556 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2023-01-17 14:01:19,558 INFO mapreduce.Job: Running job: job_local534642282_0001\n",
            "2023-01-17 14:01:19,566 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2023-01-17 14:01:19,568 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "2023-01-17 14:01:19,576 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 14:01:19,576 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 14:01:19,637 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2023-01-17 14:01:19,643 INFO mapred.LocalJobRunner: Starting task: attempt_local534642282_0001_m_000000_0\n",
            "2023-01-17 14:01:19,683 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 14:01:19,684 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 14:01:19,713 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 14:01:19,729 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:0+33554432\n",
            "2023-01-17 14:01:19,887 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 14:01:19,985 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 14:01:19,985 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 14:01:19,985 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 14:01:19,985 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 14:01:19,985 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 14:01:19,989 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 14:01:20,235 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 14:01:20,243 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "2023-01-17 14:01:20,260 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "2023-01-17 14:01:20,261 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "2023-01-17 14:01:20,261 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2023-01-17 14:01:20,263 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "2023-01-17 14:01:20,263 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "2023-01-17 14:01:20,263 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "2023-01-17 14:01:20,264 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2023-01-17 14:01:20,264 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "2023-01-17 14:01:20,265 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "2023-01-17 14:01:20,265 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2023-01-17 14:01:20,266 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "2023-01-17 14:01:20,306 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:20,307 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:20,309 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:20,330 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:20,446 INFO streaming.PipeMapRed: Records R/W=2565/1\n",
            "2023-01-17 14:01:20,493 INFO streaming.PipeMapRed: R/W/S=10000/1635/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:20,564 INFO mapreduce.Job: Job job_local534642282_0001 running in uber mode : false\n",
            "2023-01-17 14:01:20,565 INFO mapreduce.Job:  map 0% reduce 0%\n",
            "2023-01-17 14:01:20,966 INFO streaming.PipeMapRed: R/W/S=100000/97043/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:21,272 INFO streaming.PipeMapRed: R/W/S=200000/196631/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:21,591 INFO streaming.PipeMapRed: R/W/S=300000/296146/0 in:300000=300000/1 [rec/s] out:296146=296146/1 [rec/s]\n",
            "2023-01-17 14:01:21,951 INFO streaming.PipeMapRed: R/W/S=400000/396856/0 in:400000=400000/1 [rec/s] out:396856=396856/1 [rec/s]\n",
            "2023-01-17 14:01:22,254 INFO streaming.PipeMapRed: R/W/S=500000/496668/0 in:500000=500000/1 [rec/s] out:496668=496668/1 [rec/s]\n",
            "2023-01-17 14:01:22,552 INFO streaming.PipeMapRed: R/W/S=600000/596110/0 in:300000=600000/2 [rec/s] out:298055=596110/2 [rec/s]\n",
            "2023-01-17 14:01:22,729 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 14:01:22,731 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 14:01:22,735 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 14:01:22,735 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 14:01:22,735 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 14:01:22,735 INFO mapred.MapTask: bufstart = 0; bufend = 12014458; bufvoid = 104857600\n",
            "2023-01-17 14:01:22,735 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586356(94345424); length = 2628041/6553600\n",
            "2023-01-17 14:01:23,730 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 14:01:23,743 INFO mapred.Task: Task:attempt_local534642282_0001_m_000000_0 is done. And is in the process of committing\n",
            "2023-01-17 14:01:23,747 INFO mapred.LocalJobRunner: Records R/W=2565/1\n",
            "2023-01-17 14:01:23,748 INFO mapred.Task: Task 'attempt_local534642282_0001_m_000000_0' done.\n",
            "2023-01-17 14:01:23,756 INFO mapred.Task: Final Counters for attempt_local534642282_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=33560622\n",
            "\t\tFILE: Number of bytes written=13942675\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657011\n",
            "\t\tMap output records=657011\n",
            "\t\tMap output bytes=12014458\n",
            "\t\tMap output materialized bytes=13328486\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657011\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=344\n",
            "\t\tTotal committed heap usage (bytes)=595066880\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 14:01:23,756 INFO mapred.LocalJobRunner: Finishing task: attempt_local534642282_0001_m_000000_0\n",
            "2023-01-17 14:01:23,756 INFO mapred.LocalJobRunner: Starting task: attempt_local534642282_0001_m_000001_0\n",
            "2023-01-17 14:01:23,758 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 14:01:23,758 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 14:01:23,759 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 14:01:23,762 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:33554432+33554432\n",
            "2023-01-17 14:01:23,768 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 14:01:23,851 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 14:01:23,851 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 14:01:23,851 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 14:01:23,851 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 14:01:23,851 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 14:01:23,852 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 14:01:23,859 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 14:01:23,884 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:23,884 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:23,885 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:23,889 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:24,019 INFO streaming.PipeMapRed: Records R/W=2572/1\n",
            "2023-01-17 14:01:24,053 INFO streaming.PipeMapRed: R/W/S=10000/6262/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:24,570 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 14:01:24,616 INFO streaming.PipeMapRed: R/W/S=100000/95805/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:24,897 INFO streaming.PipeMapRed: R/W/S=200000/196641/0 in:200000=200000/1 [rec/s] out:196641=196641/1 [rec/s]\n",
            "2023-01-17 14:01:25,296 INFO streaming.PipeMapRed: R/W/S=300000/296071/0 in:300000=300000/1 [rec/s] out:296071=296071/1 [rec/s]\n",
            "2023-01-17 14:01:25,641 INFO streaming.PipeMapRed: R/W/S=400000/396526/0 in:400000=400000/1 [rec/s] out:396526=396526/1 [rec/s]\n",
            "2023-01-17 14:01:25,931 INFO streaming.PipeMapRed: R/W/S=500000/496424/0 in:250000=500000/2 [rec/s] out:248212=496424/2 [rec/s]\n",
            "2023-01-17 14:01:26,234 INFO streaming.PipeMapRed: R/W/S=600000/596394/0 in:300000=600000/2 [rec/s] out:298197=596394/2 [rec/s]\n",
            "2023-01-17 14:01:26,405 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 14:01:26,407 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 14:01:26,409 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 14:01:26,409 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 14:01:26,409 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 14:01:26,409 INFO mapred.MapTask: bufstart = 0; bufend = 12012608; bufvoid = 104857600\n",
            "2023-01-17 14:01:26,409 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585260(94341040); length = 2629137/6553600\n",
            "2023-01-17 14:01:26,571 INFO mapreduce.Job:  map 14% reduce 0%\n",
            "2023-01-17 14:01:27,244 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 14:01:27,247 INFO mapred.Task: Task:attempt_local534642282_0001_m_000001_0 is done. And is in the process of committing\n",
            "2023-01-17 14:01:27,249 INFO mapred.LocalJobRunner: Records R/W=2572/1\n",
            "2023-01-17 14:01:27,249 INFO mapred.Task: Task 'attempt_local534642282_0001_m_000001_0' done.\n",
            "2023-01-17 14:01:27,250 INFO mapred.Task: Final Counters for attempt_local534642282_0001_m_000001_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=67119761\n",
            "\t\tFILE: Number of bytes written=27269891\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657285\n",
            "\t\tMap output records=657285\n",
            "\t\tMap output bytes=12012608\n",
            "\t\tMap output materialized bytes=13327184\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657285\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=229\n",
            "\t\tTotal committed heap usage (bytes)=709885952\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 14:01:27,250 INFO mapred.LocalJobRunner: Finishing task: attempt_local534642282_0001_m_000001_0\n",
            "2023-01-17 14:01:27,250 INFO mapred.LocalJobRunner: Starting task: attempt_local534642282_0001_m_000002_0\n",
            "2023-01-17 14:01:27,251 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 14:01:27,251 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 14:01:27,252 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 14:01:27,253 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:67108864+33554432\n",
            "2023-01-17 14:01:27,256 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 14:01:27,273 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 14:01:27,274 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 14:01:27,274 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 14:01:27,274 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 14:01:27,274 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 14:01:27,274 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 14:01:27,282 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 14:01:27,305 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:27,305 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:27,305 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:27,306 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:27,416 INFO streaming.PipeMapRed: Records R/W=2566/1\n",
            "2023-01-17 14:01:27,433 INFO streaming.PipeMapRed: R/W/S=10000/6178/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:27,572 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 14:01:27,691 INFO streaming.PipeMapRed: R/W/S=100000/96262/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:27,980 INFO streaming.PipeMapRed: R/W/S=200000/196653/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:28,380 INFO streaming.PipeMapRed: R/W/S=300000/296534/0 in:300000=300000/1 [rec/s] out:296534=296534/1 [rec/s]\n",
            "2023-01-17 14:01:28,665 INFO streaming.PipeMapRed: R/W/S=400000/395913/0 in:400000=400000/1 [rec/s] out:395913=395913/1 [rec/s]\n",
            "2023-01-17 14:01:28,948 INFO streaming.PipeMapRed: R/W/S=500000/496267/0 in:500000=500000/1 [rec/s] out:496267=496267/1 [rec/s]\n",
            "2023-01-17 14:01:29,257 INFO streaming.PipeMapRed: R/W/S=600000/596577/0 in:600000=600000/1 [rec/s] out:596577=596577/1 [rec/s]\n",
            "2023-01-17 14:01:29,429 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 14:01:29,430 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 14:01:29,430 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 14:01:29,430 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 14:01:29,430 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 14:01:29,430 INFO mapred.MapTask: bufstart = 0; bufend = 12013306; bufvoid = 104857600\n",
            "2023-01-17 14:01:29,430 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586148(94344592); length = 2628249/6553600\n",
            "2023-01-17 14:01:29,573 INFO mapreduce.Job:  map 29% reduce 0%\n",
            "2023-01-17 14:01:30,155 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 14:01:30,158 INFO mapred.Task: Task:attempt_local534642282_0001_m_000002_0 is done. And is in the process of committing\n",
            "2023-01-17 14:01:30,170 INFO mapred.LocalJobRunner: Records R/W=2566/1\n",
            "2023-01-17 14:01:30,170 INFO mapred.Task: Task 'attempt_local534642282_0001_m_000002_0' done.\n",
            "2023-01-17 14:01:30,171 INFO mapred.Task: Final Counters for attempt_local534642282_0001_m_000002_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=100678900\n",
            "\t\tFILE: Number of bytes written=40597361\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657063\n",
            "\t\tMap output records=657063\n",
            "\t\tMap output bytes=12013306\n",
            "\t\tMap output materialized bytes=13327438\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657063\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=108\n",
            "\t\tTotal committed heap usage (bytes)=905445376\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 14:01:30,171 INFO mapred.LocalJobRunner: Finishing task: attempt_local534642282_0001_m_000002_0\n",
            "2023-01-17 14:01:30,171 INFO mapred.LocalJobRunner: Starting task: attempt_local534642282_0001_m_000003_0\n",
            "2023-01-17 14:01:30,174 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 14:01:30,174 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 14:01:30,176 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 14:01:30,177 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:100663296+33554432\n",
            "2023-01-17 14:01:30,181 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 14:01:30,198 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 14:01:30,198 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 14:01:30,198 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 14:01:30,198 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 14:01:30,198 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 14:01:30,199 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 14:01:30,210 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 14:01:30,230 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:30,230 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:30,230 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:30,230 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:30,329 INFO streaming.PipeMapRed: Records R/W=2570/1\n",
            "2023-01-17 14:01:30,346 INFO streaming.PipeMapRed: R/W/S=10000/6257/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:30,575 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 14:01:30,610 INFO streaming.PipeMapRed: R/W/S=100000/96319/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:30,924 INFO streaming.PipeMapRed: R/W/S=200000/196201/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:31,227 INFO streaming.PipeMapRed: R/W/S=300000/296472/0 in:300000=300000/1 [rec/s] out:296472=296472/1 [rec/s]\n",
            "2023-01-17 14:01:31,524 INFO streaming.PipeMapRed: R/W/S=400000/396408/0 in:400000=400000/1 [rec/s] out:396408=396408/1 [rec/s]\n",
            "2023-01-17 14:01:31,800 INFO streaming.PipeMapRed: R/W/S=500000/496704/0 in:500000=500000/1 [rec/s] out:496704=496704/1 [rec/s]\n",
            "2023-01-17 14:01:32,093 INFO streaming.PipeMapRed: R/W/S=600000/596590/0 in:600000=600000/1 [rec/s] out:596590=596590/1 [rec/s]\n",
            "2023-01-17 14:01:32,280 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 14:01:32,280 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 14:01:32,281 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 14:01:32,281 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 14:01:32,281 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 14:01:32,281 INFO mapred.MapTask: bufstart = 0; bufend = 12014400; bufvoid = 104857600\n",
            "2023-01-17 14:01:32,281 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586104(94344416); length = 2628293/6553600\n",
            "2023-01-17 14:01:32,580 INFO mapreduce.Job:  map 43% reduce 0%\n",
            "2023-01-17 14:01:33,075 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 14:01:33,078 INFO mapred.Task: Task:attempt_local534642282_0001_m_000003_0 is done. And is in the process of committing\n",
            "2023-01-17 14:01:33,080 INFO mapred.LocalJobRunner: Records R/W=2570/1\n",
            "2023-01-17 14:01:33,080 INFO mapred.Task: Task 'attempt_local534642282_0001_m_000003_0' done.\n",
            "2023-01-17 14:01:33,081 INFO mapred.Task: Final Counters for attempt_local534642282_0001_m_000003_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=134238039\n",
            "\t\tFILE: Number of bytes written=53925947\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657074\n",
            "\t\tMap output records=657074\n",
            "\t\tMap output bytes=12014400\n",
            "\t\tMap output materialized bytes=13328554\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657074\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=905445376\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 14:01:33,081 INFO mapred.LocalJobRunner: Finishing task: attempt_local534642282_0001_m_000003_0\n",
            "2023-01-17 14:01:33,081 INFO mapred.LocalJobRunner: Starting task: attempt_local534642282_0001_m_000004_0\n",
            "2023-01-17 14:01:33,083 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 14:01:33,083 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 14:01:33,083 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 14:01:33,084 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:134217728+33554432\n",
            "2023-01-17 14:01:33,088 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 14:01:33,111 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 14:01:33,112 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 14:01:33,112 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 14:01:33,112 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 14:01:33,112 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 14:01:33,113 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 14:01:33,120 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 14:01:33,145 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:33,145 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:33,145 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:33,145 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:33,272 INFO streaming.PipeMapRed: Records R/W=2562/1\n",
            "2023-01-17 14:01:33,301 INFO streaming.PipeMapRed: R/W/S=10000/5801/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:33,580 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 14:01:33,594 INFO streaming.PipeMapRed: R/W/S=100000/96219/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:33,883 INFO streaming.PipeMapRed: R/W/S=200000/196129/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:34,170 INFO streaming.PipeMapRed: R/W/S=300000/296485/0 in:300000=300000/1 [rec/s] out:296485=296485/1 [rec/s]\n",
            "2023-01-17 14:01:34,478 INFO streaming.PipeMapRed: R/W/S=400000/396306/0 in:400000=400000/1 [rec/s] out:396306=396306/1 [rec/s]\n",
            "2023-01-17 14:01:34,755 INFO streaming.PipeMapRed: R/W/S=500000/496669/0 in:500000=500000/1 [rec/s] out:496669=496669/1 [rec/s]\n",
            "2023-01-17 14:01:35,030 INFO streaming.PipeMapRed: R/W/S=600000/596624/0 in:600000=600000/1 [rec/s] out:596624=596624/1 [rec/s]\n",
            "2023-01-17 14:01:35,205 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 14:01:35,206 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 14:01:35,207 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 14:01:35,207 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 14:01:35,207 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 14:01:35,207 INFO mapred.MapTask: bufstart = 0; bufend = 12014153; bufvoid = 104857600\n",
            "2023-01-17 14:01:35,207 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585972(94343888); length = 2628425/6553600\n",
            "2023-01-17 14:01:35,582 INFO mapreduce.Job:  map 57% reduce 0%\n",
            "2023-01-17 14:01:36,022 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 14:01:36,025 INFO mapred.Task: Task:attempt_local534642282_0001_m_000004_0 is done. And is in the process of committing\n",
            "2023-01-17 14:01:36,027 INFO mapred.LocalJobRunner: Records R/W=2562/1\n",
            "2023-01-17 14:01:36,027 INFO mapred.Task: Task 'attempt_local534642282_0001_m_000004_0' done.\n",
            "2023-01-17 14:01:36,027 INFO mapred.Task: Final Counters for attempt_local534642282_0001_m_000004_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=167797178\n",
            "\t\tFILE: Number of bytes written=67254352\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657107\n",
            "\t\tMap output records=657107\n",
            "\t\tMap output bytes=12014153\n",
            "\t\tMap output materialized bytes=13328373\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657107\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=3\n",
            "\t\tTotal committed heap usage (bytes)=905445376\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 14:01:36,027 INFO mapred.LocalJobRunner: Finishing task: attempt_local534642282_0001_m_000004_0\n",
            "2023-01-17 14:01:36,028 INFO mapred.LocalJobRunner: Starting task: attempt_local534642282_0001_m_000005_0\n",
            "2023-01-17 14:01:36,029 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 14:01:36,029 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 14:01:36,029 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 14:01:36,034 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:167772160+33554432\n",
            "2023-01-17 14:01:36,037 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 14:01:36,145 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 14:01:36,145 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 14:01:36,145 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 14:01:36,145 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 14:01:36,145 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 14:01:36,146 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 14:01:36,153 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 14:01:36,173 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:36,173 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:36,173 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:36,174 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:36,284 INFO streaming.PipeMapRed: Records R/W=2576/1\n",
            "2023-01-17 14:01:36,301 INFO streaming.PipeMapRed: R/W/S=10000/5821/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:36,563 INFO streaming.PipeMapRed: R/W/S=100000/96726/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:36,582 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 14:01:36,855 INFO streaming.PipeMapRed: R/W/S=200000/196650/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:37,147 INFO streaming.PipeMapRed: R/W/S=300000/296639/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:37,562 INFO streaming.PipeMapRed: R/W/S=400000/396554/0 in:400000=400000/1 [rec/s] out:396554=396554/1 [rec/s]\n",
            "2023-01-17 14:01:37,842 INFO streaming.PipeMapRed: R/W/S=500000/496850/0 in:500000=500000/1 [rec/s] out:496850=496850/1 [rec/s]\n",
            "2023-01-17 14:01:38,116 INFO streaming.PipeMapRed: R/W/S=600000/596773/0 in:600000=600000/1 [rec/s] out:596773=596773/1 [rec/s]\n",
            "2023-01-17 14:01:38,298 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 14:01:38,299 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 14:01:38,300 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 14:01:38,300 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 14:01:38,300 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 14:01:38,300 INFO mapred.MapTask: bufstart = 0; bufend = 12013464; bufvoid = 104857600\n",
            "2023-01-17 14:01:38,300 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585028(94340112); length = 2629369/6553600\n",
            "2023-01-17 14:01:38,584 INFO mapreduce.Job:  map 71% reduce 0%\n",
            "2023-01-17 14:01:39,033 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 14:01:39,035 INFO mapred.Task: Task:attempt_local534642282_0001_m_000005_0 is done. And is in the process of committing\n",
            "2023-01-17 14:01:39,038 INFO mapred.LocalJobRunner: Records R/W=2576/1\n",
            "2023-01-17 14:01:39,038 INFO mapred.Task: Task 'attempt_local534642282_0001_m_000005_0' done.\n",
            "2023-01-17 14:01:39,038 INFO mapred.Task: Final Counters for attempt_local534642282_0001_m_000005_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=201356317\n",
            "\t\tFILE: Number of bytes written=80582540\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657343\n",
            "\t\tMap output records=657343\n",
            "\t\tMap output bytes=12013464\n",
            "\t\tMap output materialized bytes=13328156\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657343\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=116\n",
            "\t\tTotal committed heap usage (bytes)=1126170624\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 14:01:39,038 INFO mapred.LocalJobRunner: Finishing task: attempt_local534642282_0001_m_000005_0\n",
            "2023-01-17 14:01:39,038 INFO mapred.LocalJobRunner: Starting task: attempt_local534642282_0001_m_000006_0\n",
            "2023-01-17 14:01:39,041 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 14:01:39,041 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 14:01:39,041 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 14:01:39,042 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:201326592+9986332\n",
            "2023-01-17 14:01:39,048 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 14:01:39,065 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 14:01:39,065 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 14:01:39,065 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 14:01:39,065 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 14:01:39,065 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 14:01:39,066 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 14:01:39,073 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 14:01:39,085 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:39,085 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:39,085 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:39,085 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:39,182 INFO streaming.PipeMapRed: Records R/W=2569/1\n",
            "2023-01-17 14:01:39,200 INFO streaming.PipeMapRed: R/W/S=10000/6271/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:39,466 INFO streaming.PipeMapRed: R/W/S=100000/95858/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:39,584 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 14:01:39,753 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 14:01:39,753 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 14:01:39,754 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 14:01:39,754 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 14:01:39,754 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 14:01:39,754 INFO mapred.MapTask: bufstart = 0; bufend = 3576453; bufvoid = 104857600\n",
            "2023-01-17 14:01:39,754 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25432028(101728112); length = 782369/6553600\n",
            "2023-01-17 14:01:39,928 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 14:01:39,930 INFO mapred.Task: Task:attempt_local534642282_0001_m_000006_0 is done. And is in the process of committing\n",
            "2023-01-17 14:01:39,931 INFO mapred.LocalJobRunner: Records R/W=2569/1\n",
            "2023-01-17 14:01:39,932 INFO mapred.Task: Task 'attempt_local534642282_0001_m_000006_0' done.\n",
            "2023-01-17 14:01:39,932 INFO mapred.Task: Final Counters for attempt_local534642282_0001_m_000006_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=211343260\n",
            "\t\tFILE: Number of bytes written=84550217\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=195593\n",
            "\t\tMap output records=195593\n",
            "\t\tMap output bytes=3576453\n",
            "\t\tMap output materialized bytes=3967645\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=195593\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1126170624\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=9986332\n",
            "2023-01-17 14:01:39,932 INFO mapred.LocalJobRunner: Finishing task: attempt_local534642282_0001_m_000006_0\n",
            "2023-01-17 14:01:39,932 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2023-01-17 14:01:39,936 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2023-01-17 14:01:39,936 INFO mapred.LocalJobRunner: Starting task: attempt_local534642282_0001_r_000000_0\n",
            "2023-01-17 14:01:39,948 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 14:01:39,948 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 14:01:39,948 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 14:01:39,952 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7fd0e32\n",
            "2023-01-17 14:01:39,953 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2023-01-17 14:01:39,973 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2119434240, maxSingleShuffleLimit=529858560, mergeThreshold=1398826624, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2023-01-17 14:01:39,982 INFO reduce.EventFetcher: attempt_local534642282_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2023-01-17 14:01:40,031 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local534642282_0001_m_000002_0 decomp: 13327434 len: 13327438 to MEMORY\n",
            "2023-01-17 14:01:40,055 INFO reduce.InMemoryMapOutput: Read 13327434 bytes from map-output for attempt_local534642282_0001_m_000002_0\n",
            "2023-01-17 14:01:40,057 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13327434, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13327434\n",
            "2023-01-17 14:01:40,064 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local534642282_0001_m_000005_0 decomp: 13328152 len: 13328156 to MEMORY\n",
            "2023-01-17 14:01:40,075 INFO reduce.InMemoryMapOutput: Read 13328152 bytes from map-output for attempt_local534642282_0001_m_000005_0\n",
            "2023-01-17 14:01:40,075 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13328152, inMemoryMapOutputs.size() -> 2, commitMemory -> 13327434, usedMemory ->26655586\n",
            "2023-01-17 14:01:40,078 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local534642282_0001_m_000006_0 decomp: 3967641 len: 3967645 to MEMORY\n",
            "2023-01-17 14:01:40,082 INFO reduce.InMemoryMapOutput: Read 3967641 bytes from map-output for attempt_local534642282_0001_m_000006_0\n",
            "2023-01-17 14:01:40,083 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3967641, inMemoryMapOutputs.size() -> 3, commitMemory -> 26655586, usedMemory ->30623227\n",
            "2023-01-17 14:01:40,088 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local534642282_0001_m_000000_0 decomp: 13328482 len: 13328486 to MEMORY\n",
            "2023-01-17 14:01:40,101 INFO reduce.InMemoryMapOutput: Read 13328482 bytes from map-output for attempt_local534642282_0001_m_000000_0\n",
            "2023-01-17 14:01:40,102 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13328482, inMemoryMapOutputs.size() -> 4, commitMemory -> 30623227, usedMemory ->43951709\n",
            "2023-01-17 14:01:40,106 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local534642282_0001_m_000003_0 decomp: 13328550 len: 13328554 to MEMORY\n",
            "2023-01-17 14:01:40,118 INFO reduce.InMemoryMapOutput: Read 13328550 bytes from map-output for attempt_local534642282_0001_m_000003_0\n",
            "2023-01-17 14:01:40,118 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13328550, inMemoryMapOutputs.size() -> 5, commitMemory -> 43951709, usedMemory ->57280259\n",
            "2023-01-17 14:01:40,124 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local534642282_0001_m_000004_0 decomp: 13328369 len: 13328373 to MEMORY\n",
            "2023-01-17 14:01:40,135 INFO reduce.InMemoryMapOutput: Read 13328369 bytes from map-output for attempt_local534642282_0001_m_000004_0\n",
            "2023-01-17 14:01:40,135 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13328369, inMemoryMapOutputs.size() -> 6, commitMemory -> 57280259, usedMemory ->70608628\n",
            "2023-01-17 14:01:40,139 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local534642282_0001_m_000001_0 decomp: 13327180 len: 13327184 to MEMORY\n",
            "2023-01-17 14:01:40,150 INFO reduce.InMemoryMapOutput: Read 13327180 bytes from map-output for attempt_local534642282_0001_m_000001_0\n",
            "2023-01-17 14:01:40,150 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 13327180, inMemoryMapOutputs.size() -> 7, commitMemory -> 70608628, usedMemory ->83935808\n",
            "2023-01-17 14:01:40,151 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2023-01-17 14:01:40,152 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 14:01:40,152 INFO reduce.MergeManagerImpl: finalMerge called with 7 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2023-01-17 14:01:40,162 INFO mapred.Merger: Merging 7 sorted segments\n",
            "2023-01-17 14:01:40,163 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 83935703 bytes\n",
            "2023-01-17 14:01:42,887 INFO reduce.MergeManagerImpl: Merged 7 segments, 83935808 bytes to disk to satisfy reduce memory limit\n",
            "2023-01-17 14:01:42,888 INFO reduce.MergeManagerImpl: Merging 1 files, 83935800 bytes from disk\n",
            "2023-01-17 14:01:42,897 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2023-01-17 14:01:42,901 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2023-01-17 14:01:42,902 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 83935781 bytes\n",
            "2023-01-17 14:01:42,903 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 14:01:42,941 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, reducer.py]\n",
            "2023-01-17 14:01:42,944 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2023-01-17 14:01:42,948 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2023-01-17 14:01:43,010 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:43,010 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:43,013 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:43,042 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:43,288 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:43,746 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 14:01:44,179 INFO streaming.PipeMapRed: R/W/S=200000/0/0 in:200000=200000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 14:01:44,459 INFO streaming.PipeMapRed: R/W/S=300000/0/0 in:300000=300000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 14:01:44,607 INFO streaming.PipeMapRed: R/W/S=400000/0/0 in:400000=400000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 14:01:44,736 INFO streaming.PipeMapRed: R/W/S=500000/0/0 in:500000=500000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 14:01:44,866 INFO streaming.PipeMapRed: R/W/S=600000/0/0 in:600000=600000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 14:01:44,994 INFO streaming.PipeMapRed: R/W/S=700000/0/0 in:350000=700000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 14:01:45,125 INFO streaming.PipeMapRed: R/W/S=800000/0/0 in:400000=800000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 14:01:45,248 INFO streaming.PipeMapRed: R/W/S=900000/0/0 in:450000=900000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 14:01:45,382 INFO streaming.PipeMapRed: R/W/S=1000000/0/0 in:500000=1000000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 14:01:45,511 INFO streaming.PipeMapRed: R/W/S=1100000/0/0 in:550000=1100000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 14:01:45,657 INFO streaming.PipeMapRed: R/W/S=1200000/0/0 in:600000=1200000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 14:01:45,776 INFO streaming.PipeMapRed: R/W/S=1300000/0/0 in:650000=1300000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 14:01:45,915 INFO streaming.PipeMapRed: R/W/S=1400000/0/0 in:700000=1400000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 14:01:46,046 INFO streaming.PipeMapRed: R/W/S=1500000/0/0 in:500000=1500000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 14:01:46,172 INFO streaming.PipeMapRed: R/W/S=1600000/0/0 in:533333=1600000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 14:01:46,311 INFO streaming.PipeMapRed: R/W/S=1700000/0/0 in:566666=1700000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 14:01:46,447 INFO streaming.PipeMapRed: R/W/S=1800000/0/0 in:600000=1800000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 14:01:46,571 INFO streaming.PipeMapRed: R/W/S=1900000/0/0 in:633333=1900000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 14:01:46,723 INFO streaming.PipeMapRed: R/W/S=2000000/0/0 in:666666=2000000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 14:01:46,852 INFO streaming.PipeMapRed: R/W/S=2100000/0/0 in:700000=2100000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 14:01:46,978 INFO streaming.PipeMapRed: R/W/S=2200000/0/0 in:550000=2200000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 14:01:47,114 INFO streaming.PipeMapRed: R/W/S=2300000/0/0 in:575000=2300000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 14:01:47,255 INFO streaming.PipeMapRed: R/W/S=2400000/0/0 in:600000=2400000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 14:01:47,391 INFO streaming.PipeMapRed: R/W/S=2500000/0/0 in:625000=2500000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 14:01:47,520 INFO streaming.PipeMapRed: R/W/S=2600000/0/0 in:650000=2600000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 14:01:47,654 INFO streaming.PipeMapRed: R/W/S=2700000/0/0 in:675000=2700000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 14:01:47,797 INFO streaming.PipeMapRed: R/W/S=2800000/0/0 in:700000=2800000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 14:01:47,927 INFO streaming.PipeMapRed: R/W/S=2900000/0/0 in:725000=2900000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 14:01:48,066 INFO streaming.PipeMapRed: R/W/S=3000000/0/0 in:600000=3000000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 14:01:48,199 INFO streaming.PipeMapRed: R/W/S=3100000/0/0 in:620000=3100000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 14:01:48,350 INFO streaming.PipeMapRed: R/W/S=3200000/0/0 in:640000=3200000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 14:01:48,488 INFO streaming.PipeMapRed: R/W/S=3300000/0/0 in:660000=3300000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 14:01:48,623 INFO streaming.PipeMapRed: R/W/S=3400000/0/0 in:680000=3400000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 14:01:48,756 INFO streaming.PipeMapRed: R/W/S=3500000/0/0 in:700000=3500000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 14:01:48,882 INFO streaming.PipeMapRed: R/W/S=3600000/0/0 in:720000=3600000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 14:01:49,013 INFO streaming.PipeMapRed: R/W/S=3700000/0/0 in:616666=3700000/6 [rec/s] out:0=0/6 [rec/s]\n",
            "2023-01-17 14:01:49,151 INFO streaming.PipeMapRed: R/W/S=3800000/0/0 in:633333=3800000/6 [rec/s] out:0=0/6 [rec/s]\n",
            "2023-01-17 14:01:49,276 INFO streaming.PipeMapRed: R/W/S=3900000/0/0 in:650000=3900000/6 [rec/s] out:0=0/6 [rec/s]\n",
            "2023-01-17 14:01:49,412 INFO streaming.PipeMapRed: R/W/S=4000000/0/0 in:666666=4000000/6 [rec/s] out:0=0/6 [rec/s]\n",
            "2023-01-17 14:01:49,564 INFO streaming.PipeMapRed: R/W/S=4100000/0/0 in:683333=4100000/6 [rec/s] out:0=0/6 [rec/s]\n",
            "2023-01-17 14:01:49,634 INFO streaming.PipeMapRed: Records R/W=4138476/1\n",
            "2023-01-17 14:01:49,640 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 14:01:49,641 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 14:01:49,642 INFO mapred.Task: Task:attempt_local534642282_0001_r_000000_0 is done. And is in the process of committing\n",
            "2023-01-17 14:01:49,643 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 14:01:49,643 INFO mapred.Task: Task attempt_local534642282_0001_r_000000_0 is allowed to commit now\n",
            "2023-01-17 14:01:49,645 INFO output.FileOutputCommitter: Saved output of task 'attempt_local534642282_0001_r_000000_0' to file:/root/myoutput\n",
            "2023-01-17 14:01:49,646 INFO mapred.LocalJobRunner: Records R/W=4138476/1 > reduce\n",
            "2023-01-17 14:01:49,646 INFO mapred.Task: Task 'attempt_local534642282_0001_r_000000_0' done.\n",
            "2023-01-17 14:01:49,647 INFO mapred.Task: Final Counters for attempt_local534642282_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=379215120\n",
            "\t\tFILE: Number of bytes written=168489275\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=103\n",
            "\t\tReduce shuffle bytes=83935836\n",
            "\t\tReduce input records=4138476\n",
            "\t\tReduce output records=103\n",
            "\t\tSpilled Records=4138476\n",
            "\t\tShuffled Maps =7\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=7\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1126170624\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=3258\n",
            "2023-01-17 14:01:49,647 INFO mapred.LocalJobRunner: Finishing task: attempt_local534642282_0001_r_000000_0\n",
            "2023-01-17 14:01:49,647 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2023-01-17 14:01:50,594 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2023-01-17 14:01:50,595 INFO mapreduce.Job: Job job_local534642282_0001 completed successfully\n",
            "2023-01-17 14:01:50,620 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1295309197\n",
            "\t\tFILE: Number of bytes written=536612258\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=4138476\n",
            "\t\tMap output records=4138476\n",
            "\t\tMap output bytes=75658842\n",
            "\t\tMap output materialized bytes=83935836\n",
            "\t\tInput split bytes=588\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=103\n",
            "\t\tReduce shuffle bytes=83935836\n",
            "\t\tReduce input records=4138476\n",
            "\t\tReduce output records=103\n",
            "\t\tSpilled Records=8276952\n",
            "\t\tShuffled Maps =7\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=7\n",
            "\t\tGC time elapsed (ms)=800\n",
            "\t\tTotal committed heap usage (bytes)=7399800832\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=211337500\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=3258\n",
            "2023-01-17 14:01:50,621 INFO streaming.StreamJob: Output directory: /root/myoutput\n"
          ]
        }
      ],
      "source": [
        "!rm -r ~/myoutput\n",
        "!/usr/local/hadoop-3.3.0/bin/hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input ~/myinput -output ~/myoutput -file /content/mapper.py  -file /content/reducer.py  -mapper 'python mapper.py'  -reducer 'python reducer.py'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t76GHsU5ses"
      },
      "source": [
        "Affichage du contenu du dossier \"~/myoutput\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRkWnc8D5ule",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c9f6b86-4468-4215-fe1a-71232010e939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000  _SUCCESS\n"
          ]
        }
      ],
      "source": [
        "!ls ~/myoutput"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6lEMkuYX6YI"
      },
      "source": [
        "Affichage d'un part du résultat contenu dans le fichier de sortie. On y trouve la fréquence de chaque mot contenu dans le corpus de documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dU_89Wr6PSv",
        "outputId": "4d359763-16c5-4219-c5d7-32ecf2406e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pittsburgh  \t 10090124.820000002\n",
            "Plano  \t 10046103.609999977\n",
            "Portland  \t 10007635.769999985\n",
            "Raleigh  \t 10061442.540000036\n",
            "Reno  \t 10079955.160000028\n",
            "Richmond  \t 9992941.589999935\n",
            "Riverside  \t 10006695.420000065\n",
            "Rochester  \t 10067606.92000001\n",
            "Sacramento  \t 10123468.179999929\n",
            "Saint Paul  \t 10057233.569999969\n",
            "San Antonio  \t 10014441.700000057\n",
            "San Bernardino  \t 9965152.03999996\n",
            "San Diego  \t 9966038.389999935\n",
            "San Francisco  \t 9995570.540000021\n",
            "San Jose  \t 9936721.410000049\n",
            "Santa Ana  \t 10050309.929999996\n",
            "Scottsdale  \t 10037929.849999992\n",
            "Seattle  \t 9936267.37000001\n",
            "Spokane  \t 10083362.979999928\n",
            "St. Louis  \t 10002105.14000001\n",
            "St. Petersburg  \t 9986495.539999947\n",
            "Stockton  \t 10006412.639999853\n",
            "Tampa  \t 10106428.550000058\n",
            "Toledo  \t 10020768.880000055\n",
            "Tucson  \t 9998252.469999956\n",
            "Tulsa  \t 10064955.899999967\n",
            "Virginia Beach  \t 10086553.500000007\n",
            "Washington  \t 10139363.38999994\n",
            "Wichita  \t 10083643.209999999\n",
            "Winston–Salem  \t 10044011.830000004\n"
          ]
        }
      ],
      "source": [
        "!tail -n 30 ~/myoutput/part-00000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG0ZeTjD7GxQ"
      },
      "source": [
        "# Activité 2\n",
        "Nous continuons à travailler avec le même fichier en entrées (purchases.txt), mais pour obtenir des résultats différents. <u>Le but est donc d’écrire vos propres Mappers et Reducers</u>.\n",
        "<ol>\n",
        "<li>Donner le nombre de paiement par mode de paiement.</li>\n",
        "<li>Quel est le chiffre d'affaire réalisé selon les jours de la semaine ?</li>\n",
        "<li>Quelle est la liste des magasins ?</li>\n",
        "<li>Quel est le nombre total des ventes et la valeur totale des ventes de tous magasins confondus ?</i>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvD7RF0tACLa"
      },
      "source": [
        "# **Correction**\n",
        "\n",
        "**1 - Donner le nombre de paiement par mode de paiement.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqSxNP2LAOpy"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "import sys\n",
        "# Mettez vos instructions ...\n",
        "for line in sys.stdin:\n",
        "  data = line.strip().split(\"\\t\")\n",
        "  if len(data) == 6:\n",
        "    date, time, store, item, amount, payment = data\n",
        "    print(payment, \"\\t\", 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rm2ff1RTAZma"
      },
      "outputs": [],
      "source": [
        "# All cell codes are stored in a List variable \"In\"\n",
        "with open('/content/mapper.py', 'w') as f:\n",
        "  f.write(In[97]) \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g40VpkMJAnMm"
      },
      "outputs": [],
      "source": [
        "!chmod u+rwx /content/mapper.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiTXLRzvArTu",
        "outputId": "7313dfc7-1c46-4b41-de17-af1e02ae72bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amex \t 1\n",
            "Visa \t 1\n",
            "Cash \t 1\n",
            "Discover \t 1\n",
            "MasterCard \t 1\n",
            "MasterCard \t 1\n",
            "Visa \t 1\n",
            "Cash \t 1\n",
            "Discover \t 1\n",
            "Visa \t 1\n"
          ]
        }
      ],
      "source": [
        "!head -10 ~/myinput/purchases.txt | python3 /content/mapper.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ycK-3VAAy0U"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "from operator import itemgetter\n",
        "import sys\n",
        "# Mettez vos instructions ...\n",
        "current_count = 0\n",
        "oldKey = None\n",
        "\n",
        "for line in sys.stdin:\n",
        "  data = line.strip().split(\"\\t\")\n",
        "  if len(data) != 2:\n",
        "    continue\n",
        "  \n",
        "  thisKey, count = data\n",
        "\n",
        "  try:\n",
        "      count = int(count)\n",
        "  except ValueError:\n",
        "      #count was not a number, so silently\n",
        "      #ignore/discard this line\n",
        "      continue\n",
        "\n",
        "  if oldKey and oldKey != thisKey:\n",
        "    print(oldKey, \"\\t\", int(current_count))\n",
        "    current_count = 0\n",
        "    \n",
        "  oldKey = thisKey\n",
        "  current_count += count\n",
        "\n",
        "if oldKey != None:\n",
        "  print(oldKey, \"\\t\", int(current_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xIegra-A48C"
      },
      "outputs": [],
      "source": [
        "# All cell codes are stored in a List variable \"In\"\n",
        "with open('/content/reducer.py', 'w') as f:\n",
        "  f.write(In[109]) \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8jHGfGSBDr_"
      },
      "outputs": [],
      "source": [
        "!chmod u+rwx /content/reducer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xqn05JDBHX8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12425494-b856-4b0a-af1e-ac7eb5ba2fd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amex  \t 10\n",
            "Cash  \t 20\n",
            "Discover  \t 28\n",
            "MasterCard  \t 37\n",
            "Visa  \t 50\n"
          ]
        }
      ],
      "source": [
        "!head -50 ~/myinput/purchases.txt | python3 /content/mapper.py | sort | python3 /content/reducer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcd71BtWBNqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb79a1a5-b29e-4d3f-e50a-71112e373917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-17 15:02:03,250 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
            "packageJobJar: [/content/mapper.py, /content/reducer.py] [] /tmp/streamjob1446424535333531386.jar tmpDir=null\n",
            "2023-01-17 15:02:03,956 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2023-01-17 15:02:04,052 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2023-01-17 15:02:04,052 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2023-01-17 15:02:04,071 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2023-01-17 15:02:04,256 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2023-01-17 15:02:04,283 INFO mapreduce.JobSubmitter: number of splits:7\n",
            "2023-01-17 15:02:04,502 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1574291105_0001\n",
            "2023-01-17 15:02:04,502 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2023-01-17 15:02:04,946 INFO mapred.LocalDistributedCacheManager: Localized file:/content/mapper.py as file:/tmp/hadoop-root/mapred/local/job_local1574291105_0001_0216b97e-1473-4c8d-8e0a-f4205ace24c0/mapper.py\n",
            "2023-01-17 15:02:04,979 INFO mapred.LocalDistributedCacheManager: Localized file:/content/reducer.py as file:/tmp/hadoop-root/mapred/local/job_local1574291105_0001_df50b73f-1a32-402d-b7a7-e9c70c4b4756/reducer.py\n",
            "2023-01-17 15:02:05,168 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2023-01-17 15:02:05,171 INFO mapreduce.Job: Running job: job_local1574291105_0001\n",
            "2023-01-17 15:02:05,179 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2023-01-17 15:02:05,182 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "2023-01-17 15:02:05,193 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:02:05,193 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:02:05,253 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2023-01-17 15:02:05,259 INFO mapred.LocalJobRunner: Starting task: attempt_local1574291105_0001_m_000000_0\n",
            "2023-01-17 15:02:05,294 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:02:05,294 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:02:05,326 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:02:05,343 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:0+33554432\n",
            "2023-01-17 15:02:05,458 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:02:05,549 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:02:05,549 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:02:05,550 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:02:05,550 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:02:05,550 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:02:05,553 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:02:05,563 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:02:05,570 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "2023-01-17 15:02:05,571 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "2023-01-17 15:02:05,572 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "2023-01-17 15:02:05,572 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2023-01-17 15:02:05,573 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "2023-01-17 15:02:05,574 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "2023-01-17 15:02:05,574 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "2023-01-17 15:02:05,575 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2023-01-17 15:02:05,575 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "2023-01-17 15:02:05,576 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "2023-01-17 15:02:05,576 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2023-01-17 15:02:05,577 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "2023-01-17 15:02:05,613 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:05,614 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:05,617 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:05,638 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:05,744 INFO streaming.PipeMapRed: Records R/W=2565/1\n",
            "2023-01-17 15:02:05,789 INFO streaming.PipeMapRed: R/W/S=10000/3775/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:06,177 INFO mapreduce.Job: Job job_local1574291105_0001 running in uber mode : false\n",
            "2023-01-17 15:02:06,179 INFO mapreduce.Job:  map 0% reduce 0%\n",
            "2023-01-17 15:02:06,221 INFO streaming.PipeMapRed: R/W/S=100000/96062/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:06,507 INFO streaming.PipeMapRed: R/W/S=200000/196648/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:06,821 INFO streaming.PipeMapRed: R/W/S=300000/295709/0 in:300000=300000/1 [rec/s] out:295709=295709/1 [rec/s]\n",
            "2023-01-17 15:02:07,188 INFO streaming.PipeMapRed: R/W/S=400000/396253/0 in:400000=400000/1 [rec/s] out:396253=396253/1 [rec/s]\n",
            "2023-01-17 15:02:07,464 INFO streaming.PipeMapRed: R/W/S=500000/496740/0 in:500000=500000/1 [rec/s] out:496740=496740/1 [rec/s]\n",
            "2023-01-17 15:02:07,735 INFO streaming.PipeMapRed: R/W/S=600000/596629/0 in:300000=600000/2 [rec/s] out:298314=596629/2 [rec/s]\n",
            "2023-01-17 15:02:07,912 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:02:07,913 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:02:07,917 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:02:07,917 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:02:07,918 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:02:07,918 INFO mapred.MapTask: bufstart = 0; bufend = 7225729; bufvoid = 104857600\n",
            "2023-01-17 15:02:07,918 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586356(94345424); length = 2628041/6553600\n",
            "2023-01-17 15:02:08,480 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:02:08,499 INFO mapred.Task: Task:attempt_local1574291105_0001_m_000000_0 is done. And is in the process of committing\n",
            "2023-01-17 15:02:08,502 INFO mapred.LocalJobRunner: Records R/W=2565/1\n",
            "2023-01-17 15:02:08,503 INFO mapred.Task: Task 'attempt_local1574291105_0001_m_000000_0' done.\n",
            "2023-01-17 15:02:08,513 INFO mapred.Task: Final Counters for attempt_local1574291105_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=33560821\n",
            "\t\tFILE: Number of bytes written=9157133\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657011\n",
            "\t\tMap output records=657011\n",
            "\t\tMap output bytes=7225729\n",
            "\t\tMap output materialized bytes=8539757\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657011\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=88\n",
            "\t\tTotal committed heap usage (bytes)=303562752\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:02:08,514 INFO mapred.LocalJobRunner: Finishing task: attempt_local1574291105_0001_m_000000_0\n",
            "2023-01-17 15:02:08,514 INFO mapred.LocalJobRunner: Starting task: attempt_local1574291105_0001_m_000001_0\n",
            "2023-01-17 15:02:08,515 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:02:08,515 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:02:08,516 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:02:08,517 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:33554432+33554432\n",
            "2023-01-17 15:02:08,523 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:02:08,596 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:02:08,596 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:02:08,597 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:02:08,597 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:02:08,597 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:02:08,597 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:02:08,606 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:02:08,638 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:08,638 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:08,638 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:08,641 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:08,775 INFO streaming.PipeMapRed: Records R/W=2572/1\n",
            "2023-01-17 15:02:08,824 INFO streaming.PipeMapRed: R/W/S=10000/5979/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:09,179 INFO streaming.PipeMapRed: R/W/S=100000/96126/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:09,184 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 15:02:09,444 INFO streaming.PipeMapRed: R/W/S=200000/196660/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:09,826 INFO streaming.PipeMapRed: R/W/S=300000/296483/0 in:300000=300000/1 [rec/s] out:296483=296483/1 [rec/s]\n",
            "2023-01-17 15:02:10,202 INFO streaming.PipeMapRed: R/W/S=400000/396260/0 in:400000=400000/1 [rec/s] out:396260=396260/1 [rec/s]\n",
            "2023-01-17 15:02:10,515 INFO streaming.PipeMapRed: R/W/S=500000/496746/0 in:500000=500000/1 [rec/s] out:496746=496746/1 [rec/s]\n",
            "2023-01-17 15:02:10,785 INFO streaming.PipeMapRed: R/W/S=600000/596627/0 in:300000=600000/2 [rec/s] out:298313=596627/2 [rec/s]\n",
            "2023-01-17 15:02:10,965 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:02:10,966 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:02:10,969 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:02:10,969 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:02:10,969 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:02:10,969 INFO mapred.MapTask: bufstart = 0; bufend = 7228371; bufvoid = 104857600\n",
            "2023-01-17 15:02:10,969 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585260(94341040); length = 2629137/6553600\n",
            "2023-01-17 15:02:11,185 INFO mapreduce.Job:  map 14% reduce 0%\n",
            "2023-01-17 15:02:11,427 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:02:11,431 INFO mapred.Task: Task:attempt_local1574291105_0001_m_000001_0 is done. And is in the process of committing\n",
            "2023-01-17 15:02:11,433 INFO mapred.LocalJobRunner: Records R/W=2572/1\n",
            "2023-01-17 15:02:11,433 INFO mapred.Task: Task 'attempt_local1574291105_0001_m_000001_0' done.\n",
            "2023-01-17 15:02:11,434 INFO mapred.Task: Final Counters for attempt_local1574291105_0001_m_000001_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=67119960\n",
            "\t\tFILE: Number of bytes written=17700112\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657285\n",
            "\t\tMap output records=657285\n",
            "\t\tMap output bytes=7228371\n",
            "\t\tMap output materialized bytes=8542947\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657285\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=7\n",
            "\t\tTotal committed heap usage (bytes)=408944640\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:02:11,435 INFO mapred.LocalJobRunner: Finishing task: attempt_local1574291105_0001_m_000001_0\n",
            "2023-01-17 15:02:11,435 INFO mapred.LocalJobRunner: Starting task: attempt_local1574291105_0001_m_000002_0\n",
            "2023-01-17 15:02:11,437 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:02:11,439 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:02:11,440 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:02:11,442 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:67108864+33554432\n",
            "2023-01-17 15:02:11,445 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:02:11,517 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:02:11,517 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:02:11,517 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:02:11,517 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:02:11,517 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:02:11,518 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:02:11,524 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:02:11,545 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:11,545 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:11,545 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:11,546 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:11,636 INFO streaming.PipeMapRed: Records R/W=2566/1\n",
            "2023-01-17 15:02:11,651 INFO streaming.PipeMapRed: R/W/S=10000/5964/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:11,904 INFO streaming.PipeMapRed: R/W/S=100000/96815/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:12,169 INFO streaming.PipeMapRed: R/W/S=200000/195883/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:12,186 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 15:02:12,436 INFO streaming.PipeMapRed: R/W/S=300000/296443/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:12,703 INFO streaming.PipeMapRed: R/W/S=400000/396259/0 in:400000=400000/1 [rec/s] out:396259=396259/1 [rec/s]\n",
            "2023-01-17 15:02:12,982 INFO streaming.PipeMapRed: R/W/S=500000/495917/0 in:500000=500000/1 [rec/s] out:495917=495917/1 [rec/s]\n",
            "2023-01-17 15:02:13,253 INFO streaming.PipeMapRed: R/W/S=600000/596392/0 in:600000=600000/1 [rec/s] out:596392=596392/1 [rec/s]\n",
            "2023-01-17 15:02:13,413 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:02:13,413 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:02:13,414 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:02:13,414 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:02:13,414 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:02:13,414 INFO mapred.MapTask: bufstart = 0; bufend = 7227827; bufvoid = 104857600\n",
            "2023-01-17 15:02:13,414 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586148(94344592); length = 2628249/6553600\n",
            "2023-01-17 15:02:13,711 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:02:13,714 INFO mapred.Task: Task:attempt_local1574291105_0001_m_000002_0 is done. And is in the process of committing\n",
            "2023-01-17 15:02:13,718 INFO mapred.LocalJobRunner: Records R/W=2566/1\n",
            "2023-01-17 15:02:13,718 INFO mapred.Task: Task 'attempt_local1574291105_0001_m_000002_0' done.\n",
            "2023-01-17 15:02:13,721 INFO mapred.Task: Final Counters for attempt_local1574291105_0001_m_000002_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=100679099\n",
            "\t\tFILE: Number of bytes written=26242103\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657063\n",
            "\t\tMap output records=657063\n",
            "\t\tMap output bytes=7227827\n",
            "\t\tMap output materialized bytes=8541959\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657063\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=6\n",
            "\t\tTotal committed heap usage (bytes)=565182464\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:02:13,721 INFO mapred.LocalJobRunner: Finishing task: attempt_local1574291105_0001_m_000002_0\n",
            "2023-01-17 15:02:13,721 INFO mapred.LocalJobRunner: Starting task: attempt_local1574291105_0001_m_000003_0\n",
            "2023-01-17 15:02:13,722 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:02:13,722 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:02:13,723 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:02:13,725 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:100663296+33554432\n",
            "2023-01-17 15:02:13,728 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:02:13,750 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:02:13,750 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:02:13,750 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:02:13,750 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:02:13,750 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:02:13,751 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:02:13,757 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:02:13,774 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:13,774 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:13,775 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:13,779 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:13,881 INFO streaming.PipeMapRed: Records R/W=2570/1\n",
            "2023-01-17 15:02:13,900 INFO streaming.PipeMapRed: R/W/S=10000/5962/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:14,151 INFO streaming.PipeMapRed: R/W/S=100000/96026/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:14,420 INFO streaming.PipeMapRed: R/W/S=200000/196330/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:14,683 INFO streaming.PipeMapRed: R/W/S=300000/296038/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:14,953 INFO streaming.PipeMapRed: R/W/S=400000/396700/0 in:400000=400000/1 [rec/s] out:396700=396700/1 [rec/s]\n",
            "2023-01-17 15:02:15,413 INFO streaming.PipeMapRed: R/W/S=500000/496459/0 in:500000=500000/1 [rec/s] out:496459=496459/1 [rec/s]\n",
            "2023-01-17 15:02:15,662 INFO streaming.PipeMapRed: R/W/S=600000/596146/0 in:600000=600000/1 [rec/s] out:596146=596146/1 [rec/s]\n",
            "2023-01-17 15:02:15,825 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:02:15,829 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:02:15,829 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:02:15,829 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:02:15,829 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:02:15,829 INFO mapred.MapTask: bufstart = 0; bufend = 7231058; bufvoid = 104857600\n",
            "2023-01-17 15:02:15,829 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586104(94344416); length = 2628293/6553600\n",
            "2023-01-17 15:02:16,160 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:02:16,164 INFO mapred.Task: Task:attempt_local1574291105_0001_m_000003_0 is done. And is in the process of committing\n",
            "2023-01-17 15:02:16,166 INFO mapred.LocalJobRunner: Records R/W=2570/1\n",
            "2023-01-17 15:02:16,166 INFO mapred.Task: Task 'attempt_local1574291105_0001_m_000003_0' done.\n",
            "2023-01-17 15:02:16,167 INFO mapred.Task: Final Counters for attempt_local1574291105_0001_m_000003_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=134238238\n",
            "\t\tFILE: Number of bytes written=34787347\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657074\n",
            "\t\tMap output records=657074\n",
            "\t\tMap output bytes=7231058\n",
            "\t\tMap output materialized bytes=8545212\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657074\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=200\n",
            "\t\tTotal committed heap usage (bytes)=504889344\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:02:16,167 INFO mapred.LocalJobRunner: Finishing task: attempt_local1574291105_0001_m_000003_0\n",
            "2023-01-17 15:02:16,167 INFO mapred.LocalJobRunner: Starting task: attempt_local1574291105_0001_m_000004_0\n",
            "2023-01-17 15:02:16,173 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:02:16,173 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:02:16,174 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:02:16,176 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:134217728+33554432\n",
            "2023-01-17 15:02:16,179 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:02:16,200 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:02:16,200 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:02:16,200 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:02:16,200 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:02:16,200 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:02:16,201 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:02:16,210 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:02:16,234 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:16,234 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:16,234 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:16,234 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:16,395 INFO streaming.PipeMapRed: Records R/W=2562/1\n",
            "2023-01-17 15:02:16,415 INFO streaming.PipeMapRed: R/W/S=10000/5928/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:16,649 INFO streaming.PipeMapRed: R/W/S=100000/96013/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:16,916 INFO streaming.PipeMapRed: R/W/S=200000/196524/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:17,318 INFO streaming.PipeMapRed: R/W/S=300000/296261/0 in:300000=300000/1 [rec/s] out:296261=296261/1 [rec/s]\n",
            "2023-01-17 15:02:17,573 INFO streaming.PipeMapRed: R/W/S=400000/396701/0 in:400000=400000/1 [rec/s] out:396701=396701/1 [rec/s]\n",
            "2023-01-17 15:02:17,832 INFO streaming.PipeMapRed: R/W/S=500000/496466/0 in:500000=500000/1 [rec/s] out:496466=496466/1 [rec/s]\n",
            "2023-01-17 15:02:18,142 INFO streaming.PipeMapRed: R/W/S=600000/596050/0 in:600000=600000/1 [rec/s] out:596050=596050/1 [rec/s]\n",
            "2023-01-17 15:02:18,307 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:02:18,308 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:02:18,308 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:02:18,308 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:02:18,308 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:02:18,308 INFO mapred.MapTask: bufstart = 0; bufend = 7232045; bufvoid = 104857600\n",
            "2023-01-17 15:02:18,308 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585972(94343888); length = 2628425/6553600\n",
            "2023-01-17 15:02:18,635 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:02:18,640 INFO mapred.Task: Task:attempt_local1574291105_0001_m_000004_0 is done. And is in the process of committing\n",
            "2023-01-17 15:02:18,642 INFO mapred.LocalJobRunner: Records R/W=2562/1\n",
            "2023-01-17 15:02:18,642 INFO mapred.Task: Task 'attempt_local1574291105_0001_m_000004_0' done.\n",
            "2023-01-17 15:02:18,643 INFO mapred.Task: Final Counters for attempt_local1574291105_0001_m_000004_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=167797377\n",
            "\t\tFILE: Number of bytes written=43333644\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657107\n",
            "\t\tMap output records=657107\n",
            "\t\tMap output bytes=7232045\n",
            "\t\tMap output materialized bytes=8546265\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657107\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=139\n",
            "\t\tTotal committed heap usage (bytes)=698351616\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:02:18,643 INFO mapred.LocalJobRunner: Finishing task: attempt_local1574291105_0001_m_000004_0\n",
            "2023-01-17 15:02:18,643 INFO mapred.LocalJobRunner: Starting task: attempt_local1574291105_0001_m_000005_0\n",
            "2023-01-17 15:02:18,644 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:02:18,645 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:02:18,645 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:02:18,649 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:167772160+33554432\n",
            "2023-01-17 15:02:18,652 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:02:18,671 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:02:18,671 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:02:18,671 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:02:18,671 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:02:18,671 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:02:18,672 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:02:18,678 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:02:18,699 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:18,699 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:18,699 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:18,699 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:18,797 INFO streaming.PipeMapRed: Records R/W=2576/1\n",
            "2023-01-17 15:02:18,813 INFO streaming.PipeMapRed: R/W/S=10000/5966/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:19,065 INFO streaming.PipeMapRed: R/W/S=100000/96145/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:19,355 INFO streaming.PipeMapRed: R/W/S=200000/195959/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:19,625 INFO streaming.PipeMapRed: R/W/S=300000/296528/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:19,895 INFO streaming.PipeMapRed: R/W/S=400000/396233/0 in:400000=400000/1 [rec/s] out:396233=396233/1 [rec/s]\n",
            "2023-01-17 15:02:20,176 INFO streaming.PipeMapRed: R/W/S=500000/496831/0 in:500000=500000/1 [rec/s] out:496831=496831/1 [rec/s]\n",
            "2023-01-17 15:02:20,452 INFO streaming.PipeMapRed: R/W/S=600000/596663/0 in:600000=600000/1 [rec/s] out:596663=596663/1 [rec/s]\n",
            "2023-01-17 15:02:20,619 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:02:20,620 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:02:20,620 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:02:20,620 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:02:20,620 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:02:20,620 INFO mapred.MapTask: bufstart = 0; bufend = 7228545; bufvoid = 104857600\n",
            "2023-01-17 15:02:20,621 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585028(94340112); length = 2629369/6553600\n",
            "2023-01-17 15:02:20,916 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:02:20,922 INFO mapred.Task: Task:attempt_local1574291105_0001_m_000005_0 is done. And is in the process of committing\n",
            "2023-01-17 15:02:20,927 INFO mapred.LocalJobRunner: Records R/W=2576/1\n",
            "2023-01-17 15:02:20,927 INFO mapred.Task: Task 'attempt_local1574291105_0001_m_000005_0' done.\n",
            "2023-01-17 15:02:20,928 INFO mapred.Task: Final Counters for attempt_local1574291105_0001_m_000005_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=201356516\n",
            "\t\tFILE: Number of bytes written=51876913\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657343\n",
            "\t\tMap output records=657343\n",
            "\t\tMap output bytes=7228545\n",
            "\t\tMap output materialized bytes=8543237\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657343\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=698351616\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:02:20,928 INFO mapred.LocalJobRunner: Finishing task: attempt_local1574291105_0001_m_000005_0\n",
            "2023-01-17 15:02:20,928 INFO mapred.LocalJobRunner: Starting task: attempt_local1574291105_0001_m_000006_0\n",
            "2023-01-17 15:02:20,930 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:02:20,931 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:02:20,931 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:02:20,934 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:201326592+9986332\n",
            "2023-01-17 15:02:20,941 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:02:20,962 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:02:20,963 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:02:20,963 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:02:20,963 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:02:20,963 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:02:20,964 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:02:20,971 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:02:20,983 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:20,983 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:20,983 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:20,983 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:21,073 INFO streaming.PipeMapRed: Records R/W=2569/1\n",
            "2023-01-17 15:02:21,088 INFO streaming.PipeMapRed: R/W/S=10000/5962/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:21,343 INFO streaming.PipeMapRed: R/W/S=100000/96066/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:21,633 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:02:21,633 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:02:21,634 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:02:21,634 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:02:21,634 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:02:21,634 INFO mapred.MapTask: bufstart = 0; bufend = 2153557; bufvoid = 104857600\n",
            "2023-01-17 15:02:21,634 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25432028(101728112); length = 782369/6553600\n",
            "2023-01-17 15:02:21,725 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:02:21,728 INFO mapred.Task: Task:attempt_local1574291105_0001_m_000006_0 is done. And is in the process of committing\n",
            "2023-01-17 15:02:21,731 INFO mapred.LocalJobRunner: Records R/W=2569/1\n",
            "2023-01-17 15:02:21,732 INFO mapred.Task: Task 'attempt_local1574291105_0001_m_000006_0' done.\n",
            "2023-01-17 15:02:21,732 INFO mapred.Task: Final Counters for attempt_local1574291105_0001_m_000006_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=211343459\n",
            "\t\tFILE: Number of bytes written=54421694\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=195593\n",
            "\t\tMap output records=195593\n",
            "\t\tMap output bytes=2153557\n",
            "\t\tMap output materialized bytes=2544749\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=195593\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=2\n",
            "\t\tTotal committed heap usage (bytes)=698351616\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=9986332\n",
            "2023-01-17 15:02:21,733 INFO mapred.LocalJobRunner: Finishing task: attempt_local1574291105_0001_m_000006_0\n",
            "2023-01-17 15:02:21,733 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2023-01-17 15:02:21,737 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2023-01-17 15:02:21,737 INFO mapred.LocalJobRunner: Starting task: attempt_local1574291105_0001_r_000000_0\n",
            "2023-01-17 15:02:21,745 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:02:21,745 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:02:21,745 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:02:21,748 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@61f2012e\n",
            "2023-01-17 15:02:21,750 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2023-01-17 15:02:21,774 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2119434240, maxSingleShuffleLimit=529858560, mergeThreshold=1398826624, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2023-01-17 15:02:21,778 INFO reduce.EventFetcher: attempt_local1574291105_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2023-01-17 15:02:21,833 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1574291105_0001_m_000003_0 decomp: 8545208 len: 8545212 to MEMORY\n",
            "2023-01-17 15:02:21,849 INFO reduce.InMemoryMapOutput: Read 8545208 bytes from map-output for attempt_local1574291105_0001_m_000003_0\n",
            "2023-01-17 15:02:21,850 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8545208, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->8545208\n",
            "2023-01-17 15:02:21,854 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1574291105_0001_m_000006_0 decomp: 2544745 len: 2544749 to MEMORY\n",
            "2023-01-17 15:02:21,858 INFO reduce.InMemoryMapOutput: Read 2544745 bytes from map-output for attempt_local1574291105_0001_m_000006_0\n",
            "2023-01-17 15:02:21,858 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2544745, inMemoryMapOutputs.size() -> 2, commitMemory -> 8545208, usedMemory ->11089953\n",
            "2023-01-17 15:02:21,861 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1574291105_0001_m_000002_0 decomp: 8541955 len: 8541959 to MEMORY\n",
            "2023-01-17 15:02:21,870 INFO reduce.InMemoryMapOutput: Read 8541955 bytes from map-output for attempt_local1574291105_0001_m_000002_0\n",
            "2023-01-17 15:02:21,870 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8541955, inMemoryMapOutputs.size() -> 3, commitMemory -> 11089953, usedMemory ->19631908\n",
            "2023-01-17 15:02:21,873 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1574291105_0001_m_000005_0 decomp: 8543233 len: 8543237 to MEMORY\n",
            "2023-01-17 15:02:21,882 INFO reduce.InMemoryMapOutput: Read 8543233 bytes from map-output for attempt_local1574291105_0001_m_000005_0\n",
            "2023-01-17 15:02:21,882 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8543233, inMemoryMapOutputs.size() -> 4, commitMemory -> 19631908, usedMemory ->28175141\n",
            "2023-01-17 15:02:21,885 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1574291105_0001_m_000001_0 decomp: 8542943 len: 8542947 to MEMORY\n",
            "2023-01-17 15:02:21,894 INFO reduce.InMemoryMapOutput: Read 8542943 bytes from map-output for attempt_local1574291105_0001_m_000001_0\n",
            "2023-01-17 15:02:21,894 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8542943, inMemoryMapOutputs.size() -> 5, commitMemory -> 28175141, usedMemory ->36718084\n",
            "2023-01-17 15:02:21,897 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1574291105_0001_m_000004_0 decomp: 8546261 len: 8546265 to MEMORY\n",
            "2023-01-17 15:02:21,905 INFO reduce.InMemoryMapOutput: Read 8546261 bytes from map-output for attempt_local1574291105_0001_m_000004_0\n",
            "2023-01-17 15:02:21,905 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8546261, inMemoryMapOutputs.size() -> 6, commitMemory -> 36718084, usedMemory ->45264345\n",
            "2023-01-17 15:02:21,909 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1574291105_0001_m_000000_0 decomp: 8539753 len: 8539757 to MEMORY\n",
            "2023-01-17 15:02:21,918 INFO reduce.InMemoryMapOutput: Read 8539753 bytes from map-output for attempt_local1574291105_0001_m_000000_0\n",
            "2023-01-17 15:02:21,918 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8539753, inMemoryMapOutputs.size() -> 7, commitMemory -> 45264345, usedMemory ->53804098\n",
            "2023-01-17 15:02:21,918 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2023-01-17 15:02:21,920 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 15:02:21,920 INFO reduce.MergeManagerImpl: finalMerge called with 7 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2023-01-17 15:02:21,930 INFO mapred.Merger: Merging 7 sorted segments\n",
            "2023-01-17 15:02:21,930 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 53804042 bytes\n",
            "2023-01-17 15:02:23,617 INFO reduce.MergeManagerImpl: Merged 7 segments, 53804098 bytes to disk to satisfy reduce memory limit\n",
            "2023-01-17 15:02:23,618 INFO reduce.MergeManagerImpl: Merging 1 files, 53804090 bytes from disk\n",
            "2023-01-17 15:02:23,619 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2023-01-17 15:02:23,619 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2023-01-17 15:02:23,619 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 53804078 bytes\n",
            "2023-01-17 15:02:23,620 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 15:02:23,627 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, reducer.py]\n",
            "2023-01-17 15:02:23,630 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2023-01-17 15:02:23,630 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2023-01-17 15:02:23,648 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:23,648 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:23,650 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:23,673 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:23,718 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:24,161 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:24,463 INFO streaming.PipeMapRed: R/W/S=200000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:24,613 INFO streaming.PipeMapRed: R/W/S=300000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:02:24,762 INFO streaming.PipeMapRed: R/W/S=400000/0/0 in:400000=400000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:02:24,897 INFO streaming.PipeMapRed: R/W/S=500000/0/0 in:500000=500000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:02:25,029 INFO streaming.PipeMapRed: R/W/S=600000/0/0 in:600000=600000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:02:25,161 INFO streaming.PipeMapRed: R/W/S=700000/0/0 in:700000=700000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:02:25,294 INFO streaming.PipeMapRed: R/W/S=800000/0/0 in:800000=800000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:02:25,458 INFO streaming.PipeMapRed: R/W/S=900000/0/0 in:900000=900000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:02:25,605 INFO streaming.PipeMapRed: R/W/S=1000000/0/0 in:1000000=1000000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:02:25,735 INFO streaming.PipeMapRed: R/W/S=1100000/0/0 in:550000=1100000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:02:25,884 INFO streaming.PipeMapRed: R/W/S=1200000/0/0 in:600000=1200000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:02:26,015 INFO streaming.PipeMapRed: R/W/S=1300000/0/0 in:650000=1300000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:02:26,145 INFO streaming.PipeMapRed: R/W/S=1400000/0/0 in:700000=1400000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:02:26,272 INFO streaming.PipeMapRed: R/W/S=1500000/0/0 in:750000=1500000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:02:26,411 INFO streaming.PipeMapRed: R/W/S=1600000/0/0 in:800000=1600000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:02:26,579 INFO streaming.PipeMapRed: R/W/S=1700000/0/0 in:850000=1700000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:02:26,715 INFO streaming.PipeMapRed: R/W/S=1800000/0/0 in:600000=1800000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:02:26,845 INFO streaming.PipeMapRed: R/W/S=1900000/0/0 in:633333=1900000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:02:26,979 INFO streaming.PipeMapRed: R/W/S=2000000/0/0 in:666666=2000000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:02:27,110 INFO streaming.PipeMapRed: R/W/S=2100000/0/0 in:700000=2100000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:02:27,239 INFO streaming.PipeMapRed: R/W/S=2200000/0/0 in:733333=2200000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:02:27,385 INFO streaming.PipeMapRed: R/W/S=2300000/0/0 in:766666=2300000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:02:27,515 INFO streaming.PipeMapRed: R/W/S=2400000/0/0 in:800000=2400000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:02:27,643 INFO streaming.PipeMapRed: R/W/S=2500000/0/0 in:625000=2500000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:02:27,779 INFO streaming.PipeMapRed: R/W/S=2600000/0/0 in:650000=2600000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:02:27,911 INFO streaming.PipeMapRed: R/W/S=2700000/0/0 in:675000=2700000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:02:28,042 INFO streaming.PipeMapRed: R/W/S=2800000/0/0 in:700000=2800000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:02:28,175 INFO streaming.PipeMapRed: R/W/S=2900000/0/0 in:725000=2900000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:02:28,303 INFO streaming.PipeMapRed: R/W/S=3000000/0/0 in:750000=3000000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:02:28,453 INFO streaming.PipeMapRed: R/W/S=3100000/0/0 in:775000=3100000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:02:28,585 INFO streaming.PipeMapRed: R/W/S=3200000/0/0 in:800000=3200000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:02:28,727 INFO streaming.PipeMapRed: R/W/S=3300000/0/0 in:660000=3300000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:02:28,852 INFO streaming.PipeMapRed: R/W/S=3400000/0/0 in:680000=3400000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:02:28,989 INFO streaming.PipeMapRed: R/W/S=3500000/0/0 in:700000=3500000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:02:29,118 INFO streaming.PipeMapRed: R/W/S=3600000/0/0 in:720000=3600000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:02:29,252 INFO streaming.PipeMapRed: R/W/S=3700000/0/0 in:740000=3700000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:02:29,394 INFO streaming.PipeMapRed: R/W/S=3800000/0/0 in:760000=3800000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:02:29,520 INFO streaming.PipeMapRed: R/W/S=3900000/0/0 in:780000=3900000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:02:29,652 INFO streaming.PipeMapRed: R/W/S=4000000/0/0 in:666666=4000000/6 [rec/s] out:0=0/6 [rec/s]\n",
            "2023-01-17 15:02:29,785 INFO streaming.PipeMapRed: R/W/S=4100000/0/0 in:683333=4100000/6 [rec/s] out:0=0/6 [rec/s]\n",
            "2023-01-17 15:02:29,859 INFO streaming.PipeMapRed: Records R/W=4138476/1\n",
            "2023-01-17 15:02:29,868 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:02:29,869 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:02:29,870 INFO mapred.Task: Task:attempt_local1574291105_0001_r_000000_0 is done. And is in the process of committing\n",
            "2023-01-17 15:02:29,871 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 15:02:29,871 INFO mapred.Task: Task attempt_local1574291105_0001_r_000000_0 is allowed to commit now\n",
            "2023-01-17 15:02:29,875 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1574291105_0001_r_000000_0' to file:/root/myoutput\n",
            "2023-01-17 15:02:29,876 INFO mapred.LocalJobRunner: Records R/W=4138476/1 > reduce\n",
            "2023-01-17 15:02:29,876 INFO mapred.Task: Task 'attempt_local1574291105_0001_r_000000_0' done.\n",
            "2023-01-17 15:02:29,876 INFO mapred.Task: Final Counters for attempt_local1574291105_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=318951899\n",
            "\t\tFILE: Number of bytes written=108225881\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=5\n",
            "\t\tReduce shuffle bytes=53804126\n",
            "\t\tReduce input records=4138476\n",
            "\t\tReduce output records=5\n",
            "\t\tSpilled Records=4138476\n",
            "\t\tShuffled Maps =7\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=7\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=698351616\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=97\n",
            "2023-01-17 15:02:29,877 INFO mapred.LocalJobRunner: Finishing task: attempt_local1574291105_0001_r_000000_0\n",
            "2023-01-17 15:02:29,877 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2023-01-17 15:02:30,266 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2023-01-17 15:02:30,267 INFO mapreduce.Job: Job job_local1574291105_0001 completed successfully\n",
            "2023-01-17 15:02:30,286 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1235047369\n",
            "\t\tFILE: Number of bytes written=345744827\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=4138476\n",
            "\t\tMap output records=4138476\n",
            "\t\tMap output bytes=45527132\n",
            "\t\tMap output materialized bytes=53804126\n",
            "\t\tInput split bytes=588\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=5\n",
            "\t\tReduce shuffle bytes=53804126\n",
            "\t\tReduce input records=4138476\n",
            "\t\tReduce output records=5\n",
            "\t\tSpilled Records=8276952\n",
            "\t\tShuffled Maps =7\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=7\n",
            "\t\tGC time elapsed (ms)=442\n",
            "\t\tTotal committed heap usage (bytes)=4575985664\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=211337500\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=97\n",
            "2023-01-17 15:02:30,286 INFO streaming.StreamJob: Output directory: /root/myoutput\n"
          ]
        }
      ],
      "source": [
        "!rm -r ~/myoutput\n",
        "!/usr/local/hadoop-3.3.0/bin/hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input ~/myinput -output ~/myoutput -file /content/mapper.py  -file /content/reducer.py  -mapper 'python mapper.py'  -reducer 'python reducer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibmZnXUGBU6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd40b55-88f2-489a-950e-1e7e543076fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000  _SUCCESS\n"
          ]
        }
      ],
      "source": [
        "!ls ~/myoutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5VWZ3hZBYbr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8cc7dd-79d0-48c2-9827-bc1468412681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amex  \t 826535\n",
            "Cash  \t 828770\n",
            "Discover  \t 827426\n",
            "MasterCard  \t 828524\n",
            "Visa  \t 827221\n"
          ]
        }
      ],
      "source": [
        "!tail -n 30 ~/myoutput/part-00000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2FtrkngK8W3"
      },
      "source": [
        "# **Correction** \n",
        "\n",
        "**2 - Quel est le chiffre d'affaire réalisé selon les jours de la semaine ?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxFIwpR5LiAc"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "import sys\n",
        "from datetime import datetime\n",
        "# Mettez vos instructions ...\n",
        "for line in sys.stdin:\n",
        "  data = line.strip().split(\"\\t\")\n",
        "  if len(data) == 6:\n",
        "    date, time, store, item, amount, payment = data\n",
        "    day = datetime.fromisoformat(date)\n",
        "    print(day.strftime(\"%A\"), \"\\t\", float(amount))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mUQAXkrLiAe"
      },
      "outputs": [],
      "source": [
        "# All cell codes are stored in a List variable \"In\"\n",
        "with open('/content/mapper.py', 'w') as f:\n",
        "  f.write(In[116]) \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojVINWXPLiAe"
      },
      "outputs": [],
      "source": [
        "!chmod u+rwx /content/mapper.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dgx6NR6kLiAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba200a7-4818-4c43-c6b0-f6d97fa60697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sunday \t 214.05\n",
            "Sunday \t 153.57\n",
            "Sunday \t 66.08\n",
            "Sunday \t 493.51\n",
            "Sunday \t 235.63\n",
            "Sunday \t 247.18\n",
            "Sunday \t 379.6\n",
            "Sunday \t 296.8\n",
            "Sunday \t 25.38\n",
            "Sunday \t 213.88\n"
          ]
        }
      ],
      "source": [
        "!head -10 ~/myinput/purchases.txt | python3 /content/mapper.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4F58ovYLiAe"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "from operator import itemgetter\n",
        "import sys\n",
        "# Mettez vos instructions ...\n",
        "current_turnover = 0\n",
        "oldKey = None\n",
        "\n",
        "for line in sys.stdin:\n",
        "  data = line.strip().split(\"\\t\")\n",
        "  if len(data) != 2:\n",
        "    continue\n",
        "  \n",
        "  thisKey, count = data\n",
        "\n",
        "  if oldKey and oldKey != thisKey:\n",
        "    print(oldKey, \"\\t\", str(current_turnover))\n",
        "    current_turnover = 0\n",
        "    \n",
        "  oldKey = thisKey\n",
        "  current_turnover += float(count)\n",
        "\n",
        "if oldKey != None:\n",
        "  print(oldKey, \"\\t\", str(current_turnover))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4QwQxNnLiAe"
      },
      "outputs": [],
      "source": [
        "# All cell codes are stored in a List variable \"In\"\n",
        "with open('/content/reducer.py', 'w') as f:\n",
        "  f.write(In[126]) \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y1jl3_-LiAf"
      },
      "outputs": [],
      "source": [
        "!chmod u+rwx /content/reducer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG5Bg7V9LiAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acbc9020-9317-4278-df22-38bd27061be9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sunday  \t 11259.819999999998\n"
          ]
        }
      ],
      "source": [
        "!head -50 ~/myinput/purchases.txt | python3 /content/mapper.py | sort | python3 /content/reducer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j92WDODwLiAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d999d46-ac27-45ed-d7da-d9e10233cad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-17 15:17:36,548 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
            "packageJobJar: [/content/mapper.py, /content/reducer.py] [] /tmp/streamjob6140463737155378217.jar tmpDir=null\n",
            "2023-01-17 15:17:37,300 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2023-01-17 15:17:37,439 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2023-01-17 15:17:37,439 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2023-01-17 15:17:37,463 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2023-01-17 15:17:37,687 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2023-01-17 15:17:37,707 INFO mapreduce.JobSubmitter: number of splits:7\n",
            "2023-01-17 15:17:37,932 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1950166958_0001\n",
            "2023-01-17 15:17:37,932 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2023-01-17 15:17:38,306 INFO mapred.LocalDistributedCacheManager: Localized file:/content/mapper.py as file:/tmp/hadoop-root/mapred/local/job_local1950166958_0001_4472b822-714b-4e3d-9bf8-391e6522cb1a/mapper.py\n",
            "2023-01-17 15:17:38,336 INFO mapred.LocalDistributedCacheManager: Localized file:/content/reducer.py as file:/tmp/hadoop-root/mapred/local/job_local1950166958_0001_e3cc2a9d-dbd1-42a9-842e-7c6447e8e675/reducer.py\n",
            "2023-01-17 15:17:38,506 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2023-01-17 15:17:38,508 INFO mapreduce.Job: Running job: job_local1950166958_0001\n",
            "2023-01-17 15:17:38,517 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2023-01-17 15:17:38,519 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "2023-01-17 15:17:38,530 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:17:38,530 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:17:38,593 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2023-01-17 15:17:38,598 INFO mapred.LocalJobRunner: Starting task: attempt_local1950166958_0001_m_000000_0\n",
            "2023-01-17 15:17:38,644 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:17:38,644 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:17:38,675 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:17:38,688 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:0+33554432\n",
            "2023-01-17 15:17:38,814 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:17:38,862 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:17:38,862 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:17:38,862 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:17:38,862 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:17:38,862 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:17:38,866 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:17:39,081 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:17:39,088 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "2023-01-17 15:17:39,089 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "2023-01-17 15:17:39,090 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "2023-01-17 15:17:39,090 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2023-01-17 15:17:39,091 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "2023-01-17 15:17:39,091 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "2023-01-17 15:17:39,091 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "2023-01-17 15:17:39,092 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2023-01-17 15:17:39,092 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "2023-01-17 15:17:39,093 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "2023-01-17 15:17:39,093 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2023-01-17 15:17:39,094 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "2023-01-17 15:17:39,129 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:39,129 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:39,131 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:39,147 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:39,252 INFO streaming.PipeMapRed: Records R/W=2565/1\n",
            "2023-01-17 15:17:39,331 INFO streaming.PipeMapRed: R/W/S=10000/5694/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:39,515 INFO mapreduce.Job: Job job_local1950166958_0001 running in uber mode : false\n",
            "2023-01-17 15:17:39,516 INFO mapreduce.Job:  map 0% reduce 0%\n",
            "2023-01-17 15:17:40,053 INFO streaming.PipeMapRed: R/W/S=100000/96054/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:40,671 INFO streaming.PipeMapRed: R/W/S=200000/196478/0 in:200000=200000/1 [rec/s] out:196478=196478/1 [rec/s]\n",
            "2023-01-17 15:17:41,346 INFO streaming.PipeMapRed: R/W/S=300000/295872/0 in:150000=300000/2 [rec/s] out:147936=295872/2 [rec/s]\n",
            "2023-01-17 15:17:42,010 INFO streaming.PipeMapRed: R/W/S=400000/396276/0 in:200000=400000/2 [rec/s] out:198138=396276/2 [rec/s]\n",
            "2023-01-17 15:17:42,610 INFO streaming.PipeMapRed: R/W/S=500000/496461/0 in:166666=500000/3 [rec/s] out:165487=496461/3 [rec/s]\n",
            "2023-01-17 15:17:43,237 INFO streaming.PipeMapRed: R/W/S=600000/596229/0 in:150000=600000/4 [rec/s] out:149057=596229/4 [rec/s]\n",
            "2023-01-17 15:17:43,602 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:17:43,603 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:17:43,607 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:17:43,608 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:17:43,608 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:17:43,608 INFO mapred.MapTask: bufstart = 0; bufend = 11027663; bufvoid = 104857600\n",
            "2023-01-17 15:17:43,608 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586356(94345424); length = 2628041/6553600\n",
            "2023-01-17 15:17:44,156 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:17:44,175 INFO mapred.Task: Task:attempt_local1950166958_0001_m_000000_0 is done. And is in the process of committing\n",
            "2023-01-17 15:17:44,183 INFO mapred.LocalJobRunner: Records R/W=2565/1\n",
            "2023-01-17 15:17:44,184 INFO mapred.Task: Task 'attempt_local1950166958_0001_m_000000_0' done.\n",
            "2023-01-17 15:17:44,196 INFO mapred.Task: Final Counters for attempt_local1950166958_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=33560776\n",
            "\t\tFILE: Number of bytes written=12959018\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657011\n",
            "\t\tMap output records=657011\n",
            "\t\tMap output bytes=11027663\n",
            "\t\tMap output materialized bytes=12341691\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657011\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=306\n",
            "\t\tTotal committed heap usage (bytes)=603979776\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:17:44,196 INFO mapred.LocalJobRunner: Finishing task: attempt_local1950166958_0001_m_000000_0\n",
            "2023-01-17 15:17:44,197 INFO mapred.LocalJobRunner: Starting task: attempt_local1950166958_0001_m_000001_0\n",
            "2023-01-17 15:17:44,198 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:17:44,198 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:17:44,199 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:17:44,201 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:33554432+33554432\n",
            "2023-01-17 15:17:44,205 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:17:44,266 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:17:44,266 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:17:44,266 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:17:44,266 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:17:44,266 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:17:44,267 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:17:44,278 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:17:44,317 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:44,317 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:44,318 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:44,322 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:44,431 INFO streaming.PipeMapRed: Records R/W=2572/1\n",
            "2023-01-17 15:17:44,500 INFO streaming.PipeMapRed: R/W/S=10000/5892/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:44,522 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 15:17:45,297 INFO streaming.PipeMapRed: R/W/S=100000/96238/0 in:100000=100000/1 [rec/s] out:96238=96238/1 [rec/s]\n",
            "2023-01-17 15:17:45,908 INFO streaming.PipeMapRed: R/W/S=200000/196322/0 in:200000=200000/1 [rec/s] out:196322=196322/1 [rec/s]\n",
            "2023-01-17 15:17:46,577 INFO streaming.PipeMapRed: R/W/S=300000/296126/0 in:150000=300000/2 [rec/s] out:148063=296126/2 [rec/s]\n",
            "2023-01-17 15:17:47,188 INFO streaming.PipeMapRed: R/W/S=400000/396218/0 in:200000=400000/2 [rec/s] out:198109=396218/2 [rec/s]\n",
            "2023-01-17 15:17:47,830 INFO streaming.PipeMapRed: R/W/S=500000/496308/0 in:166666=500000/3 [rec/s] out:165436=496308/3 [rec/s]\n",
            "2023-01-17 15:17:48,455 INFO streaming.PipeMapRed: R/W/S=600000/596874/0 in:150000=600000/4 [rec/s] out:149218=596874/4 [rec/s]\n",
            "2023-01-17 15:17:48,833 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:17:48,834 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:17:48,834 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:17:48,834 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:17:48,834 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:17:48,834 INFO mapred.MapTask: bufstart = 0; bufend = 11063183; bufvoid = 104857600\n",
            "2023-01-17 15:17:48,834 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585260(94341040); length = 2629137/6553600\n",
            "2023-01-17 15:17:49,249 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:17:49,252 INFO mapred.Task: Task:attempt_local1950166958_0001_m_000001_0 is done. And is in the process of committing\n",
            "2023-01-17 15:17:49,255 INFO mapred.LocalJobRunner: Records R/W=2572/1\n",
            "2023-01-17 15:17:49,255 INFO mapred.Task: Task 'attempt_local1950166958_0001_m_000001_0' done.\n",
            "2023-01-17 15:17:49,257 INFO mapred.Task: Final Counters for attempt_local1950166958_0001_m_000001_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=67119915\n",
            "\t\tFILE: Number of bytes written=25336809\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657285\n",
            "\t\tMap output records=657285\n",
            "\t\tMap output bytes=11063183\n",
            "\t\tMap output materialized bytes=12377759\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657285\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=192\n",
            "\t\tTotal committed heap usage (bytes)=736100352\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:17:49,258 INFO mapred.LocalJobRunner: Finishing task: attempt_local1950166958_0001_m_000001_0\n",
            "2023-01-17 15:17:49,258 INFO mapred.LocalJobRunner: Starting task: attempt_local1950166958_0001_m_000002_0\n",
            "2023-01-17 15:17:49,260 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:17:49,260 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:17:49,261 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:17:49,262 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:67108864+33554432\n",
            "2023-01-17 15:17:49,266 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:17:49,289 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:17:49,289 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:17:49,289 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:17:49,289 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:17:49,289 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:17:49,290 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:17:49,298 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:17:49,323 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:49,323 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:49,323 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:49,324 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:49,431 INFO streaming.PipeMapRed: Records R/W=2566/1\n",
            "2023-01-17 15:17:49,471 INFO streaming.PipeMapRed: R/W/S=10000/6188/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:50,051 INFO streaming.PipeMapRed: R/W/S=100000/95911/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:50,656 INFO streaming.PipeMapRed: R/W/S=200000/195838/0 in:200000=200000/1 [rec/s] out:195838=195838/1 [rec/s]\n",
            "2023-01-17 15:17:51,406 INFO streaming.PipeMapRed: R/W/S=300000/295860/0 in:150000=300000/2 [rec/s] out:147930=295860/2 [rec/s]\n",
            "2023-01-17 15:17:52,013 INFO streaming.PipeMapRed: R/W/S=400000/396318/0 in:200000=400000/2 [rec/s] out:198159=396318/2 [rec/s]\n",
            "2023-01-17 15:17:52,636 INFO streaming.PipeMapRed: R/W/S=500000/496412/0 in:166666=500000/3 [rec/s] out:165470=496412/3 [rec/s]\n",
            "2023-01-17 15:17:53,239 INFO streaming.PipeMapRed: R/W/S=600000/596212/0 in:200000=600000/3 [rec/s] out:198737=596212/3 [rec/s]\n",
            "2023-01-17 15:17:53,634 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:17:53,635 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:17:53,635 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:17:53,635 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:17:53,636 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:17:53,636 INFO mapred.MapTask: bufstart = 0; bufend = 11049566; bufvoid = 104857600\n",
            "2023-01-17 15:17:53,636 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586148(94344592); length = 2628249/6553600\n",
            "2023-01-17 15:17:53,937 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:17:53,940 INFO mapred.Task: Task:attempt_local1950166958_0001_m_000002_0 is done. And is in the process of committing\n",
            "2023-01-17 15:17:53,941 INFO mapred.LocalJobRunner: Records R/W=2566/1\n",
            "2023-01-17 15:17:53,942 INFO mapred.Task: Task 'attempt_local1950166958_0001_m_000002_0' done.\n",
            "2023-01-17 15:17:53,942 INFO mapred.Task: Final Counters for attempt_local1950166958_0001_m_000002_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=100679054\n",
            "\t\tFILE: Number of bytes written=37700539\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657063\n",
            "\t\tMap output records=657063\n",
            "\t\tMap output bytes=11049566\n",
            "\t\tMap output materialized bytes=12363698\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657063\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=102\n",
            "\t\tTotal committed heap usage (bytes)=911212544\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:17:53,942 INFO mapred.LocalJobRunner: Finishing task: attempt_local1950166958_0001_m_000002_0\n",
            "2023-01-17 15:17:53,942 INFO mapred.LocalJobRunner: Starting task: attempt_local1950166958_0001_m_000003_0\n",
            "2023-01-17 15:17:53,946 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:17:53,946 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:17:53,948 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:17:53,949 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:100663296+33554432\n",
            "2023-01-17 15:17:53,954 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:17:53,974 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:17:53,974 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:17:53,974 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:17:53,974 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:17:53,974 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:17:53,977 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:17:53,987 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:17:54,018 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:54,018 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:54,018 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:54,018 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:54,131 INFO streaming.PipeMapRed: Records R/W=2570/1\n",
            "2023-01-17 15:17:54,166 INFO streaming.PipeMapRed: R/W/S=10000/6073/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:54,719 INFO streaming.PipeMapRed: R/W/S=100000/95852/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:55,308 INFO streaming.PipeMapRed: R/W/S=200000/196099/0 in:200000=200000/1 [rec/s] out:196099=196099/1 [rec/s]\n",
            "2023-01-17 15:17:55,917 INFO streaming.PipeMapRed: R/W/S=300000/296192/0 in:300000=300000/1 [rec/s] out:296192=296192/1 [rec/s]\n",
            "2023-01-17 15:17:56,524 INFO streaming.PipeMapRed: R/W/S=400000/396281/0 in:200000=400000/2 [rec/s] out:198140=396281/2 [rec/s]\n",
            "2023-01-17 15:17:57,128 INFO streaming.PipeMapRed: R/W/S=500000/496203/0 in:166666=500000/3 [rec/s] out:165401=496203/3 [rec/s]\n",
            "2023-01-17 15:17:57,749 INFO streaming.PipeMapRed: R/W/S=600000/596341/0 in:200000=600000/3 [rec/s] out:198780=596341/3 [rec/s]\n",
            "2023-01-17 15:17:58,112 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:17:58,114 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:17:58,114 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:17:58,114 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:17:58,114 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:17:58,114 INFO mapred.MapTask: bufstart = 0; bufend = 11032681; bufvoid = 104857600\n",
            "2023-01-17 15:17:58,114 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586104(94344416); length = 2628293/6553600\n",
            "2023-01-17 15:17:58,415 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:17:58,418 INFO mapred.Task: Task:attempt_local1950166958_0001_m_000003_0 is done. And is in the process of committing\n",
            "2023-01-17 15:17:58,421 INFO mapred.LocalJobRunner: Records R/W=2570/1\n",
            "2023-01-17 15:17:58,422 INFO mapred.Task: Task 'attempt_local1950166958_0001_m_000003_0' done.\n",
            "2023-01-17 15:17:58,422 INFO mapred.Task: Final Counters for attempt_local1950166958_0001_m_000003_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=134238193\n",
            "\t\tFILE: Number of bytes written=50047406\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657074\n",
            "\t\tMap output records=657074\n",
            "\t\tMap output bytes=11032681\n",
            "\t\tMap output materialized bytes=12346835\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657074\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=911212544\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:17:58,422 INFO mapred.LocalJobRunner: Finishing task: attempt_local1950166958_0001_m_000003_0\n",
            "2023-01-17 15:17:58,422 INFO mapred.LocalJobRunner: Starting task: attempt_local1950166958_0001_m_000004_0\n",
            "2023-01-17 15:17:58,434 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:17:58,434 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:17:58,435 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:17:58,436 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:134217728+33554432\n",
            "2023-01-17 15:17:58,439 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:17:58,462 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:17:58,462 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:17:58,462 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:17:58,462 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:17:58,462 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:17:58,463 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:17:58,471 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:17:58,498 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:58,498 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:58,498 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:58,498 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:58,621 INFO streaming.PipeMapRed: Records R/W=2562/1\n",
            "2023-01-17 15:17:58,662 INFO streaming.PipeMapRed: R/W/S=10000/6017/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:59,216 INFO streaming.PipeMapRed: R/W/S=100000/95813/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:17:59,817 INFO streaming.PipeMapRed: R/W/S=200000/196129/0 in:200000=200000/1 [rec/s] out:196129=196129/1 [rec/s]\n",
            "2023-01-17 15:18:00,436 INFO streaming.PipeMapRed: R/W/S=300000/296076/0 in:300000=300000/1 [rec/s] out:296076=296076/1 [rec/s]\n",
            "2023-01-17 15:18:01,039 INFO streaming.PipeMapRed: R/W/S=400000/396219/0 in:200000=400000/2 [rec/s] out:198109=396219/2 [rec/s]\n",
            "2023-01-17 15:18:01,654 INFO streaming.PipeMapRed: R/W/S=500000/496476/0 in:166666=500000/3 [rec/s] out:165492=496476/3 [rec/s]\n",
            "2023-01-17 15:18:02,288 INFO streaming.PipeMapRed: R/W/S=600000/596518/0 in:200000=600000/3 [rec/s] out:198839=596518/3 [rec/s]\n",
            "2023-01-17 15:18:02,677 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:18:02,678 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:18:02,678 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:18:02,678 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:18:02,678 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:18:02,678 INFO mapred.MapTask: bufstart = 0; bufend = 11066663; bufvoid = 104857600\n",
            "2023-01-17 15:18:02,678 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585972(94343888); length = 2628425/6553600\n",
            "2023-01-17 15:18:02,994 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:18:02,997 INFO mapred.Task: Task:attempt_local1950166958_0001_m_000004_0 is done. And is in the process of committing\n",
            "2023-01-17 15:18:03,000 INFO mapred.LocalJobRunner: Records R/W=2562/1\n",
            "2023-01-17 15:18:03,001 INFO mapred.Task: Task 'attempt_local1950166958_0001_m_000004_0' done.\n",
            "2023-01-17 15:18:03,001 INFO mapred.Task: Final Counters for attempt_local1950166958_0001_m_000004_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=167797332\n",
            "\t\tFILE: Number of bytes written=62428321\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657107\n",
            "\t\tMap output records=657107\n",
            "\t\tMap output bytes=11066663\n",
            "\t\tMap output materialized bytes=12380883\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657107\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=3\n",
            "\t\tTotal committed heap usage (bytes)=911212544\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:18:03,002 INFO mapred.LocalJobRunner: Finishing task: attempt_local1950166958_0001_m_000004_0\n",
            "2023-01-17 15:18:03,002 INFO mapred.LocalJobRunner: Starting task: attempt_local1950166958_0001_m_000005_0\n",
            "2023-01-17 15:18:03,004 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:18:03,005 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:18:03,005 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:18:03,008 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:167772160+33554432\n",
            "2023-01-17 15:18:03,012 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:18:03,065 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:18:03,065 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:18:03,065 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:18:03,065 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:18:03,065 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:18:03,066 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:18:03,073 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:18:03,192 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:03,192 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:03,192 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:03,192 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:03,297 INFO streaming.PipeMapRed: Records R/W=2576/1\n",
            "2023-01-17 15:18:03,335 INFO streaming.PipeMapRed: R/W/S=10000/5847/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:04,030 INFO streaming.PipeMapRed: R/W/S=100000/96124/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:04,656 INFO streaming.PipeMapRed: R/W/S=200000/195969/0 in:200000=200000/1 [rec/s] out:195969=195969/1 [rec/s]\n",
            "2023-01-17 15:18:05,249 INFO streaming.PipeMapRed: R/W/S=300000/296207/0 in:150000=300000/2 [rec/s] out:148103=296207/2 [rec/s]\n",
            "2023-01-17 15:18:05,840 INFO streaming.PipeMapRed: R/W/S=400000/396336/0 in:200000=400000/2 [rec/s] out:198168=396336/2 [rec/s]\n",
            "2023-01-17 15:18:06,432 INFO streaming.PipeMapRed: R/W/S=500000/496576/0 in:166666=500000/3 [rec/s] out:165525=496576/3 [rec/s]\n",
            "2023-01-17 15:18:07,022 INFO streaming.PipeMapRed: R/W/S=600000/596457/0 in:200000=600000/3 [rec/s] out:198819=596457/3 [rec/s]\n",
            "2023-01-17 15:18:07,375 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:18:07,376 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:18:07,378 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:18:07,378 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:18:07,378 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:18:07,378 INFO mapred.MapTask: bufstart = 0; bufend = 11063009; bufvoid = 104857600\n",
            "2023-01-17 15:18:07,378 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585028(94340112); length = 2629369/6553600\n",
            "2023-01-17 15:18:07,540 INFO mapreduce.Job:  map 71% reduce 0%\n",
            "2023-01-17 15:18:07,699 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:18:07,701 INFO mapred.Task: Task:attempt_local1950166958_0001_m_000005_0 is done. And is in the process of committing\n",
            "2023-01-17 15:18:07,707 INFO mapred.LocalJobRunner: Records R/W=2576/1\n",
            "2023-01-17 15:18:07,707 INFO mapred.Task: Task 'attempt_local1950166958_0001_m_000005_0' done.\n",
            "2023-01-17 15:18:07,713 INFO mapred.Task: Final Counters for attempt_local1950166958_0001_m_000005_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=201356471\n",
            "\t\tFILE: Number of bytes written=74806054\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657343\n",
            "\t\tMap output records=657343\n",
            "\t\tMap output bytes=11063009\n",
            "\t\tMap output materialized bytes=12377701\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657343\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=100\n",
            "\t\tTotal committed heap usage (bytes)=1070071808\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:18:07,713 INFO mapred.LocalJobRunner: Finishing task: attempt_local1950166958_0001_m_000005_0\n",
            "2023-01-17 15:18:07,714 INFO mapred.LocalJobRunner: Starting task: attempt_local1950166958_0001_m_000006_0\n",
            "2023-01-17 15:18:07,716 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:18:07,716 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:18:07,717 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:18:07,718 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:201326592+9986332\n",
            "2023-01-17 15:18:07,725 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:18:07,748 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:18:07,748 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:18:07,748 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:18:07,748 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:18:07,748 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:18:07,749 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:18:07,756 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:18:07,784 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:07,784 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:07,784 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:07,784 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:07,868 INFO streaming.PipeMapRed: Records R/W=2569/1\n",
            "2023-01-17 15:18:07,903 INFO streaming.PipeMapRed: R/W/S=10000/5865/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:08,437 INFO streaming.PipeMapRed: R/W/S=100000/96184/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:08,540 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 15:18:09,037 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:18:09,037 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:18:09,038 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:18:09,038 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:18:09,038 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:18:09,038 INFO mapred.MapTask: bufstart = 0; bufend = 3270977; bufvoid = 104857600\n",
            "2023-01-17 15:18:09,038 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25432028(101728112); length = 782369/6553600\n",
            "2023-01-17 15:18:09,128 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:18:09,130 INFO mapred.Task: Task:attempt_local1950166958_0001_m_000006_0 is done. And is in the process of committing\n",
            "2023-01-17 15:18:09,131 INFO mapred.LocalJobRunner: Records R/W=2569/1\n",
            "2023-01-17 15:18:09,131 INFO mapred.Task: Task 'attempt_local1950166958_0001_m_000006_0' done.\n",
            "2023-01-17 15:18:09,131 INFO mapred.Task: Final Counters for attempt_local1950166958_0001_m_000006_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=211343414\n",
            "\t\tFILE: Number of bytes written=78468255\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=195593\n",
            "\t\tMap output records=195593\n",
            "\t\tMap output bytes=3270977\n",
            "\t\tMap output materialized bytes=3662169\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=195593\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1070071808\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=9986332\n",
            "2023-01-17 15:18:09,132 INFO mapred.LocalJobRunner: Finishing task: attempt_local1950166958_0001_m_000006_0\n",
            "2023-01-17 15:18:09,132 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2023-01-17 15:18:09,135 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2023-01-17 15:18:09,136 INFO mapred.LocalJobRunner: Starting task: attempt_local1950166958_0001_r_000000_0\n",
            "2023-01-17 15:18:09,143 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:18:09,143 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:18:09,143 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:18:09,146 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5f4f26fd\n",
            "2023-01-17 15:18:09,148 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2023-01-17 15:18:09,174 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2119434240, maxSingleShuffleLimit=529858560, mergeThreshold=1398826624, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2023-01-17 15:18:09,178 INFO reduce.EventFetcher: attempt_local1950166958_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2023-01-17 15:18:09,229 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1950166958_0001_m_000005_0 decomp: 12377697 len: 12377701 to MEMORY\n",
            "2023-01-17 15:18:09,251 INFO reduce.InMemoryMapOutput: Read 12377697 bytes from map-output for attempt_local1950166958_0001_m_000005_0\n",
            "2023-01-17 15:18:09,253 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12377697, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12377697\n",
            "2023-01-17 15:18:09,262 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1950166958_0001_m_000002_0 decomp: 12363694 len: 12363698 to MEMORY\n",
            "2023-01-17 15:18:09,275 INFO reduce.InMemoryMapOutput: Read 12363694 bytes from map-output for attempt_local1950166958_0001_m_000002_0\n",
            "2023-01-17 15:18:09,275 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12363694, inMemoryMapOutputs.size() -> 2, commitMemory -> 12377697, usedMemory ->24741391\n",
            "2023-01-17 15:18:09,297 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1950166958_0001_m_000001_0 decomp: 12377755 len: 12377759 to MEMORY\n",
            "2023-01-17 15:18:09,314 INFO reduce.InMemoryMapOutput: Read 12377755 bytes from map-output for attempt_local1950166958_0001_m_000001_0\n",
            "2023-01-17 15:18:09,314 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12377755, inMemoryMapOutputs.size() -> 3, commitMemory -> 24741391, usedMemory ->37119146\n",
            "2023-01-17 15:18:09,317 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1950166958_0001_m_000004_0 decomp: 12380879 len: 12380883 to MEMORY\n",
            "2023-01-17 15:18:09,328 INFO reduce.InMemoryMapOutput: Read 12380879 bytes from map-output for attempt_local1950166958_0001_m_000004_0\n",
            "2023-01-17 15:18:09,329 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12380879, inMemoryMapOutputs.size() -> 4, commitMemory -> 37119146, usedMemory ->49500025\n",
            "2023-01-17 15:18:09,337 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1950166958_0001_m_000003_0 decomp: 12346831 len: 12346835 to MEMORY\n",
            "2023-01-17 15:18:09,349 INFO reduce.InMemoryMapOutput: Read 12346831 bytes from map-output for attempt_local1950166958_0001_m_000003_0\n",
            "2023-01-17 15:18:09,349 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12346831, inMemoryMapOutputs.size() -> 5, commitMemory -> 49500025, usedMemory ->61846856\n",
            "2023-01-17 15:18:09,358 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1950166958_0001_m_000000_0 decomp: 12341687 len: 12341691 to MEMORY\n",
            "2023-01-17 15:18:09,370 INFO reduce.InMemoryMapOutput: Read 12341687 bytes from map-output for attempt_local1950166958_0001_m_000000_0\n",
            "2023-01-17 15:18:09,370 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12341687, inMemoryMapOutputs.size() -> 6, commitMemory -> 61846856, usedMemory ->74188543\n",
            "2023-01-17 15:18:09,374 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1950166958_0001_m_000006_0 decomp: 3662165 len: 3662169 to MEMORY\n",
            "2023-01-17 15:18:09,378 INFO reduce.InMemoryMapOutput: Read 3662165 bytes from map-output for attempt_local1950166958_0001_m_000006_0\n",
            "2023-01-17 15:18:09,378 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3662165, inMemoryMapOutputs.size() -> 7, commitMemory -> 74188543, usedMemory ->77850708\n",
            "2023-01-17 15:18:09,379 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2023-01-17 15:18:09,380 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 15:18:09,380 INFO reduce.MergeManagerImpl: finalMerge called with 7 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2023-01-17 15:18:09,390 INFO mapred.Merger: Merging 7 sorted segments\n",
            "2023-01-17 15:18:09,390 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 77850638 bytes\n",
            "2023-01-17 15:18:11,099 INFO reduce.MergeManagerImpl: Merged 7 segments, 77850708 bytes to disk to satisfy reduce memory limit\n",
            "2023-01-17 15:18:11,100 INFO reduce.MergeManagerImpl: Merging 1 files, 77850700 bytes from disk\n",
            "2023-01-17 15:18:11,101 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2023-01-17 15:18:11,101 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2023-01-17 15:18:11,101 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 77850686 bytes\n",
            "2023-01-17 15:18:11,102 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 15:18:11,111 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, reducer.py]\n",
            "2023-01-17 15:18:11,114 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2023-01-17 15:18:11,115 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2023-01-17 15:18:11,129 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:11,129 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:11,131 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:11,147 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:11,287 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:11,604 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:11,809 INFO streaming.PipeMapRed: R/W/S=200000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:11,944 INFO streaming.PipeMapRed: R/W/S=300000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:12,081 INFO streaming.PipeMapRed: R/W/S=400000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:18:12,226 INFO streaming.PipeMapRed: R/W/S=500000/0/0 in:500000=500000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:18:12,364 INFO streaming.PipeMapRed: R/W/S=600000/0/0 in:600000=600000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:18:12,525 INFO streaming.PipeMapRed: R/W/S=700000/0/0 in:700000=700000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:18:12,653 INFO streaming.PipeMapRed: R/W/S=800000/0/0 in:800000=800000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:18:12,782 INFO streaming.PipeMapRed: R/W/S=900000/0/0 in:900000=900000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:18:12,927 INFO streaming.PipeMapRed: R/W/S=1000000/0/0 in:1000000=1000000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:18:13,063 INFO streaming.PipeMapRed: R/W/S=1100000/0/0 in:1100000=1100000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:18:13,195 INFO streaming.PipeMapRed: R/W/S=1200000/0/0 in:600000=1200000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:18:13,331 INFO streaming.PipeMapRed: R/W/S=1300000/0/0 in:650000=1300000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:18:13,459 INFO streaming.PipeMapRed: R/W/S=1400000/0/0 in:700000=1400000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:18:13,592 INFO streaming.PipeMapRed: R/W/S=1500000/0/0 in:750000=1500000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:18:13,722 INFO streaming.PipeMapRed: R/W/S=1600000/0/0 in:800000=1600000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:18:13,863 INFO streaming.PipeMapRed: R/W/S=1700000/0/0 in:850000=1700000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:18:13,991 INFO streaming.PipeMapRed: R/W/S=1800000/0/0 in:900000=1800000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:18:14,133 INFO streaming.PipeMapRed: R/W/S=1900000/0/0 in:633333=1900000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:18:14,286 INFO streaming.PipeMapRed: R/W/S=2000000/0/0 in:666666=2000000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:18:14,431 INFO streaming.PipeMapRed: R/W/S=2100000/0/0 in:700000=2100000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:18:14,574 INFO streaming.PipeMapRed: R/W/S=2200000/0/0 in:733333=2200000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:18:14,707 INFO streaming.PipeMapRed: R/W/S=2300000/0/0 in:766666=2300000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:18:14,844 INFO streaming.PipeMapRed: R/W/S=2400000/0/0 in:800000=2400000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:18:14,984 INFO streaming.PipeMapRed: R/W/S=2500000/0/0 in:833333=2500000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:18:15,127 INFO streaming.PipeMapRed: R/W/S=2600000/0/0 in:650000=2600000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:18:15,260 INFO streaming.PipeMapRed: R/W/S=2700000/0/0 in:675000=2700000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:18:15,399 INFO streaming.PipeMapRed: R/W/S=2800000/0/0 in:700000=2800000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:18:15,532 INFO streaming.PipeMapRed: R/W/S=2900000/0/0 in:725000=2900000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:18:15,665 INFO streaming.PipeMapRed: R/W/S=3000000/0/0 in:750000=3000000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:18:15,794 INFO streaming.PipeMapRed: R/W/S=3100000/0/0 in:775000=3100000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:18:15,945 INFO streaming.PipeMapRed: R/W/S=3200000/0/0 in:800000=3200000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:18:16,087 INFO streaming.PipeMapRed: R/W/S=3300000/0/0 in:825000=3300000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:18:16,229 INFO streaming.PipeMapRed: R/W/S=3400000/0/0 in:680000=3400000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:18:16,358 INFO streaming.PipeMapRed: R/W/S=3500000/0/0 in:700000=3500000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:18:16,492 INFO streaming.PipeMapRed: R/W/S=3600000/0/0 in:720000=3600000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:18:16,627 INFO streaming.PipeMapRed: R/W/S=3700000/0/0 in:740000=3700000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:18:16,758 INFO streaming.PipeMapRed: R/W/S=3800000/0/0 in:760000=3800000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:18:16,893 INFO streaming.PipeMapRed: R/W/S=3900000/0/0 in:780000=3900000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:18:17,042 INFO streaming.PipeMapRed: R/W/S=4000000/0/0 in:800000=4000000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:18:17,194 INFO streaming.PipeMapRed: R/W/S=4100000/0/0 in:683333=4100000/6 [rec/s] out:0=0/6 [rec/s]\n",
            "2023-01-17 15:18:17,281 INFO streaming.PipeMapRed: Records R/W=4138476/1\n",
            "2023-01-17 15:18:17,286 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:18:17,288 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:18:17,289 INFO mapred.Task: Task:attempt_local1950166958_0001_r_000000_0 is done. And is in the process of committing\n",
            "2023-01-17 15:18:17,293 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 15:18:17,293 INFO mapred.Task: Task attempt_local1950166958_0001_r_000000_0 is allowed to commit now\n",
            "2023-01-17 15:18:17,295 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1950166958_0001_r_000000_0' to file:/root/myoutput\n",
            "2023-01-17 15:18:17,297 INFO mapred.LocalJobRunner: Records R/W=4138476/1 > reduce\n",
            "2023-01-17 15:18:17,298 INFO mapred.Task: Task 'attempt_local1950166958_0001_r_000000_0' done.\n",
            "2023-01-17 15:18:17,299 INFO mapred.Task: Final Counters for attempt_local1950166958_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=367045074\n",
            "\t\tFILE: Number of bytes written=156319177\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=7\n",
            "\t\tReduce shuffle bytes=77850736\n",
            "\t\tReduce input records=4138476\n",
            "\t\tReduce output records=7\n",
            "\t\tSpilled Records=4138476\n",
            "\t\tShuffled Maps =7\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=7\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1070071808\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=222\n",
            "2023-01-17 15:18:17,300 INFO mapred.LocalJobRunner: Finishing task: attempt_local1950166958_0001_r_000000_0\n",
            "2023-01-17 15:18:17,300 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2023-01-17 15:18:17,546 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2023-01-17 15:18:17,546 INFO mapreduce.Job: Job job_local1950166958_0001 completed successfully\n",
            "2023-01-17 15:18:17,568 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1283140229\n",
            "\t\tFILE: Number of bytes written=498065579\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=4138476\n",
            "\t\tMap output records=4138476\n",
            "\t\tMap output bytes=69573742\n",
            "\t\tMap output materialized bytes=77850736\n",
            "\t\tInput split bytes=588\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=7\n",
            "\t\tReduce shuffle bytes=77850736\n",
            "\t\tReduce input records=4138476\n",
            "\t\tReduce output records=7\n",
            "\t\tSpilled Records=8276952\n",
            "\t\tShuffled Maps =7\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=7\n",
            "\t\tGC time elapsed (ms)=703\n",
            "\t\tTotal committed heap usage (bytes)=7283933184\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=211337500\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=222\n",
            "2023-01-17 15:18:17,568 INFO streaming.StreamJob: Output directory: /root/myoutput\n"
          ]
        }
      ],
      "source": [
        "!rm -r ~/myoutput\n",
        "!/usr/local/hadoop-3.3.0/bin/hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input ~/myinput -output ~/myoutput -file /content/mapper.py  -file /content/reducer.py  -mapper 'python mapper.py'  -reducer 'python reducer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwk0CDsyLiAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4fb25d5-d0c7-4819-f1a6-ca0379f29d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000  _SUCCESS\n"
          ]
        }
      ],
      "source": [
        "!ls ~/myoutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enS7aw7HLiAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278c606c-ae90-4404-b629-d4822849258f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Friday  \t 147414929.49999785\n",
            "Monday  \t 150364112.0699967\n",
            "Saturday  \t 147410177.56999636\n",
            "Sunday  \t 150296795.46999726\n",
            "Thursday  \t 147353780.56999773\n",
            "Tuesday  \t 147246658.13999906\n",
            "Wednesday  \t 144371499.93999988\n"
          ]
        }
      ],
      "source": [
        "!tail -n 30 ~/myoutput/part-00000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeD-TujcJb_p"
      },
      "source": [
        "# **Correction** \n",
        "\n",
        "**3 - Quelle est la liste des magasins ?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_2_jVnaJVzM"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "import sys\n",
        "# Mettez vos instructions ...\n",
        "for line in sys.stdin:\n",
        "  data = line.strip().split(\"\\t\")\n",
        "  if len(data) == 6:\n",
        "    date, time, store, item, amount, payment = data\n",
        "    print(store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ9jx1VXJVzN"
      },
      "outputs": [],
      "source": [
        "# All cell codes are stored in a List variable \"In\"\n",
        "with open('/content/mapper.py', 'w') as f:\n",
        "  f.write(In[132]) \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sJILQb6JVzN"
      },
      "outputs": [],
      "source": [
        "!chmod u+rwx /content/mapper.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6831da20-7af3-4ab3-f765-d4ed524874fd",
        "id": "s0fj9FzCJVzN"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "San Jose\n",
            "Fort Worth\n",
            "San Diego\n",
            "Pittsburgh\n",
            "Omaha\n",
            "Stockton\n",
            "Austin\n",
            "New York\n",
            "Corpus Christi\n",
            "Fort Worth\n",
            "Las Vegas\n",
            "Newark\n",
            "Austin\n",
            "Greensboro\n",
            "San Francisco\n",
            "Lincoln\n",
            "Buffalo\n",
            "San Jose\n",
            "Boston\n",
            "Houston\n",
            "Las Vegas\n",
            "Virginia Beach\n",
            "Riverside\n",
            "Tulsa\n",
            "Reno\n",
            "Chicago\n",
            "Fort Wayne\n",
            "San Bernardino\n",
            "Madison\n",
            "Austin\n"
          ]
        }
      ],
      "source": [
        "!head -30 ~/myinput/purchases.txt | python3 /content/mapper.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ofnxmb8BJVzO"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "from operator import itemgetter\n",
        "import sys\n",
        "# Mettez vos instructions ...\n",
        "oldKey = None\n",
        "\n",
        "for line in sys.stdin:\n",
        "  data = line.strip().split(\"\\t\")\n",
        "  if len(data) != 1:\n",
        "    continue\n",
        "  \n",
        "  thisKey = data\n",
        "  if oldKey and oldKey != thisKey:\n",
        "    print(oldKey)\n",
        "    \n",
        "  oldKey = thisKey\n",
        "\n",
        "if oldKey != None:\n",
        "  print(oldKey)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdl_dDaqJVzO"
      },
      "outputs": [],
      "source": [
        "# All cell codes are stored in a List variable \"In\"\n",
        "with open('/content/reducer.py', 'w') as f:\n",
        "  f.write(In[135]) \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8menZGTrJVzO"
      },
      "outputs": [],
      "source": [
        "!chmod u+rwx /content/reducer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff95371-9999-4f75-9d8e-2edf196a0074",
        "id": "e36gnTSsJVzP"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Anchorage']\n",
            "['Aurora']\n",
            "['Austin']\n",
            "['Boston']\n",
            "['Buffalo']\n",
            "['Chandler']\n",
            "['Chicago']\n",
            "['Corpus Christi']\n",
            "['Fort Wayne']\n",
            "['Fort Worth']\n",
            "['Fremont']\n",
            "['Fresno']\n",
            "['Greensboro']\n",
            "['Honolulu']\n",
            "['Houston']\n",
            "['Indianapolis']\n",
            "['Las Vegas']\n",
            "['Lincoln']\n",
            "['Madison']\n",
            "['Minneapolis']\n",
            "['Newark']\n",
            "['New York']\n",
            "['Norfolk']\n",
            "['Omaha']\n",
            "['Philadelphia']\n",
            "['Pittsburgh']\n",
            "['Portland']\n",
            "['Reno']\n",
            "['Riverside']\n",
            "['San Bernardino']\n",
            "['San Diego']\n",
            "['San Francisco']\n",
            "['San Jose']\n",
            "['Spokane']\n",
            "['Stockton']\n",
            "['Tulsa']\n",
            "['Virginia Beach']\n"
          ]
        }
      ],
      "source": [
        "!head -50 ~/myinput/purchases.txt | python3 /content/mapper.py | sort | python3 /content/reducer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6eb277-85a3-4b03-bc24-7deec3c53b83",
        "id": "-Dp_5J90JVzP"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-17 15:22:14,115 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
            "packageJobJar: [/content/mapper.py, /content/reducer.py] [] /tmp/streamjob4966580498203347478.jar tmpDir=null\n",
            "2023-01-17 15:22:14,958 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2023-01-17 15:22:15,084 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2023-01-17 15:22:15,084 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2023-01-17 15:22:15,113 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2023-01-17 15:22:15,324 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2023-01-17 15:22:15,348 INFO mapreduce.JobSubmitter: number of splits:7\n",
            "2023-01-17 15:22:15,605 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local884149691_0001\n",
            "2023-01-17 15:22:15,605 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2023-01-17 15:22:16,042 INFO mapred.LocalDistributedCacheManager: Localized file:/content/mapper.py as file:/tmp/hadoop-root/mapred/local/job_local884149691_0001_49db218e-3a14-4f62-ab0a-6e7294d1a6fd/mapper.py\n",
            "2023-01-17 15:22:16,077 INFO mapred.LocalDistributedCacheManager: Localized file:/content/reducer.py as file:/tmp/hadoop-root/mapred/local/job_local884149691_0001_b91928ae-bfce-4614-82a8-b233188623ac/reducer.py\n",
            "2023-01-17 15:22:16,261 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2023-01-17 15:22:16,267 INFO mapreduce.Job: Running job: job_local884149691_0001\n",
            "2023-01-17 15:22:16,276 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2023-01-17 15:22:16,278 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "2023-01-17 15:22:16,286 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:22:16,286 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:22:16,345 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2023-01-17 15:22:16,353 INFO mapred.LocalJobRunner: Starting task: attempt_local884149691_0001_m_000000_0\n",
            "2023-01-17 15:22:16,395 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:22:16,395 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:22:16,425 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:22:16,435 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:0+33554432\n",
            "2023-01-17 15:22:16,561 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:22:16,608 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:22:16,608 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:22:16,608 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:22:16,608 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:22:16,608 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:22:16,612 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:22:16,832 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:22:16,841 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "2023-01-17 15:22:16,843 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "2023-01-17 15:22:16,844 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "2023-01-17 15:22:16,844 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2023-01-17 15:22:16,845 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "2023-01-17 15:22:16,845 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "2023-01-17 15:22:16,846 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "2023-01-17 15:22:16,846 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2023-01-17 15:22:16,847 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "2023-01-17 15:22:16,848 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "2023-01-17 15:22:16,848 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2023-01-17 15:22:16,848 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "2023-01-17 15:22:16,890 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:16,890 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:16,892 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:16,901 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:17,022 INFO streaming.PipeMapRed: Records R/W=2565/1\n",
            "2023-01-17 15:22:17,075 INFO streaming.PipeMapRed: R/W/S=10000/2039/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:17,283 INFO mapreduce.Job: Job job_local884149691_0001 running in uber mode : false\n",
            "2023-01-17 15:22:17,284 INFO mapreduce.Job:  map 0% reduce 0%\n",
            "2023-01-17 15:22:17,534 INFO streaming.PipeMapRed: R/W/S=100000/96071/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:17,760 INFO streaming.PipeMapRed: R/W/S=200000/196576/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:18,022 INFO streaming.PipeMapRed: R/W/S=300000/296290/0 in:300000=300000/1 [rec/s] out:296290=296290/1 [rec/s]\n",
            "2023-01-17 15:22:18,362 INFO streaming.PipeMapRed: R/W/S=400000/395770/0 in:400000=400000/1 [rec/s] out:395770=395770/1 [rec/s]\n",
            "2023-01-17 15:22:18,593 INFO streaming.PipeMapRed: R/W/S=500000/496895/0 in:500000=500000/1 [rec/s] out:496895=496895/1 [rec/s]\n",
            "2023-01-17 15:22:18,809 INFO streaming.PipeMapRed: R/W/S=600000/597284/0 in:600000=600000/1 [rec/s] out:597284=597284/1 [rec/s]\n",
            "2023-01-17 15:22:18,953 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:22:18,954 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:22:18,958 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:22:18,959 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:22:18,959 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:22:18,959 INFO mapred.MapTask: bufstart = 0; bufend = 6980997; bufvoid = 104857600\n",
            "2023-01-17 15:22:18,959 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586356(94345424); length = 2628041/6553600\n",
            "2023-01-17 15:22:19,959 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:22:19,974 INFO mapred.Task: Task:attempt_local884149691_0001_m_000000_0 is done. And is in the process of committing\n",
            "2023-01-17 15:22:19,982 INFO mapred.LocalJobRunner: Records R/W=2565/1\n",
            "2023-01-17 15:22:19,982 INFO mapred.Task: Task 'attempt_local884149691_0001_m_000000_0' done.\n",
            "2023-01-17 15:22:19,992 INFO mapred.Task: Final Counters for attempt_local884149691_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=33560426\n",
            "\t\tFILE: Number of bytes written=8909018\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657011\n",
            "\t\tMap output records=657011\n",
            "\t\tMap output bytes=6980997\n",
            "\t\tMap output materialized bytes=8295025\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657011\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=312\n",
            "\t\tTotal committed heap usage (bytes)=612368384\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:22:19,993 INFO mapred.LocalJobRunner: Finishing task: attempt_local884149691_0001_m_000000_0\n",
            "2023-01-17 15:22:19,993 INFO mapred.LocalJobRunner: Starting task: attempt_local884149691_0001_m_000001_0\n",
            "2023-01-17 15:22:19,994 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:22:19,994 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:22:19,995 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:22:19,996 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:33554432+33554432\n",
            "2023-01-17 15:22:20,001 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:22:20,029 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:22:20,029 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:22:20,029 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:22:20,030 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:22:20,030 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:22:20,031 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:22:20,040 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:22:20,066 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:20,066 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:20,067 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:20,075 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:20,216 INFO streaming.PipeMapRed: Records R/W=2572/1\n",
            "2023-01-17 15:22:20,244 INFO streaming.PipeMapRed: R/W/S=10000/5947/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:20,299 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 15:22:20,527 INFO streaming.PipeMapRed: R/W/S=100000/96068/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:20,751 INFO streaming.PipeMapRed: R/W/S=200000/196588/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:20,973 INFO streaming.PipeMapRed: R/W/S=300000/296110/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:21,193 INFO streaming.PipeMapRed: R/W/S=400000/396697/0 in:400000=400000/1 [rec/s] out:396697=396697/1 [rec/s]\n",
            "2023-01-17 15:22:21,412 INFO streaming.PipeMapRed: R/W/S=500000/496247/0 in:500000=500000/1 [rec/s] out:496247=496247/1 [rec/s]\n",
            "2023-01-17 15:22:21,628 INFO streaming.PipeMapRed: R/W/S=600000/596797/0 in:600000=600000/1 [rec/s] out:596797=596797/1 [rec/s]\n",
            "2023-01-17 15:22:21,759 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:22:21,760 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:22:21,761 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:22:21,761 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:22:21,761 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:22:21,761 INFO mapred.MapTask: bufstart = 0; bufend = 6978865; bufvoid = 104857600\n",
            "2023-01-17 15:22:21,761 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585260(94341040); length = 2629137/6553600\n",
            "2023-01-17 15:22:22,300 INFO mapreduce.Job:  map 14% reduce 0%\n",
            "2023-01-17 15:22:22,535 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:22:22,539 INFO mapred.Task: Task:attempt_local884149691_0001_m_000001_0 is done. And is in the process of committing\n",
            "2023-01-17 15:22:22,541 INFO mapred.LocalJobRunner: Records R/W=2572/1\n",
            "2023-01-17 15:22:22,541 INFO mapred.Task: Task 'attempt_local884149691_0001_m_000001_0' done.\n",
            "2023-01-17 15:22:22,542 INFO mapred.Task: Final Counters for attempt_local884149691_0001_m_000001_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=67119565\n",
            "\t\tFILE: Number of bytes written=17202491\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657285\n",
            "\t\tMap output records=657285\n",
            "\t\tMap output bytes=6978865\n",
            "\t\tMap output materialized bytes=8293441\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657285\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=5\n",
            "\t\tTotal committed heap usage (bytes)=627572736\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:22:22,542 INFO mapred.LocalJobRunner: Finishing task: attempt_local884149691_0001_m_000001_0\n",
            "2023-01-17 15:22:22,542 INFO mapred.LocalJobRunner: Starting task: attempt_local884149691_0001_m_000002_0\n",
            "2023-01-17 15:22:22,543 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:22:22,544 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:22:22,544 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:22:22,551 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:67108864+33554432\n",
            "2023-01-17 15:22:22,554 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:22:22,624 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:22:22,624 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:22:22,624 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:22:22,624 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:22:22,624 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:22:22,625 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:22:22,633 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:22:22,662 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:22,662 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:22,662 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:22,663 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:22,762 INFO streaming.PipeMapRed: Records R/W=2566/1\n",
            "2023-01-17 15:22:22,777 INFO streaming.PipeMapRed: R/W/S=10000/5972/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:22,969 INFO streaming.PipeMapRed: R/W/S=100000/95247/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:23,193 INFO streaming.PipeMapRed: R/W/S=200000/196583/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:23,301 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 15:22:23,407 INFO streaming.PipeMapRed: R/W/S=300000/296086/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:23,714 INFO streaming.PipeMapRed: R/W/S=400000/396413/0 in:400000=400000/1 [rec/s] out:396413=396413/1 [rec/s]\n",
            "2023-01-17 15:22:23,921 INFO streaming.PipeMapRed: R/W/S=500000/495997/0 in:500000=500000/1 [rec/s] out:495997=495997/1 [rec/s]\n",
            "2023-01-17 15:22:24,136 INFO streaming.PipeMapRed: R/W/S=600000/596390/0 in:600000=600000/1 [rec/s] out:596390=596390/1 [rec/s]\n",
            "2023-01-17 15:22:24,275 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:22:24,276 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:22:24,277 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:22:24,277 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:22:24,277 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:22:24,277 INFO mapred.MapTask: bufstart = 0; bufend = 6980364; bufvoid = 104857600\n",
            "2023-01-17 15:22:24,277 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586148(94344592); length = 2628249/6553600\n",
            "2023-01-17 15:22:24,302 INFO mapreduce.Job:  map 29% reduce 0%\n",
            "2023-01-17 15:22:24,963 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:22:24,966 INFO mapred.Task: Task:attempt_local884149691_0001_m_000002_0 is done. And is in the process of committing\n",
            "2023-01-17 15:22:24,968 INFO mapred.LocalJobRunner: Records R/W=2566/1\n",
            "2023-01-17 15:22:24,969 INFO mapred.Task: Task 'attempt_local884149691_0001_m_000002_0' done.\n",
            "2023-01-17 15:22:24,969 INFO mapred.Task: Final Counters for attempt_local884149691_0001_m_000002_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=100678704\n",
            "\t\tFILE: Number of bytes written=25497019\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657063\n",
            "\t\tMap output records=657063\n",
            "\t\tMap output bytes=6980364\n",
            "\t\tMap output materialized bytes=8294496\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657063\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=102\n",
            "\t\tTotal committed heap usage (bytes)=656932864\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:22:24,969 INFO mapred.LocalJobRunner: Finishing task: attempt_local884149691_0001_m_000002_0\n",
            "2023-01-17 15:22:24,969 INFO mapred.LocalJobRunner: Starting task: attempt_local884149691_0001_m_000003_0\n",
            "2023-01-17 15:22:24,971 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:22:24,971 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:22:24,971 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:22:24,973 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:100663296+33554432\n",
            "2023-01-17 15:22:24,976 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:22:24,994 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:22:24,994 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:22:24,994 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:22:24,994 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:22:24,994 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:22:24,995 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:22:25,002 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:22:25,024 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:25,024 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:25,024 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:25,024 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:25,111 INFO streaming.PipeMapRed: Records R/W=2570/1\n",
            "2023-01-17 15:22:25,124 INFO streaming.PipeMapRed: R/W/S=10000/5924/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:25,328 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 15:22:25,433 INFO streaming.PipeMapRed: R/W/S=100000/96170/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:25,657 INFO streaming.PipeMapRed: R/W/S=200000/196588/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:25,867 INFO streaming.PipeMapRed: R/W/S=300000/296042/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:26,088 INFO streaming.PipeMapRed: R/W/S=400000/396569/0 in:400000=400000/1 [rec/s] out:396569=396569/1 [rec/s]\n",
            "2023-01-17 15:22:26,316 INFO streaming.PipeMapRed: R/W/S=500000/496087/0 in:500000=500000/1 [rec/s] out:496087=496087/1 [rec/s]\n",
            "2023-01-17 15:22:26,534 INFO streaming.PipeMapRed: R/W/S=600000/596492/0 in:600000=600000/1 [rec/s] out:596492=596492/1 [rec/s]\n",
            "2023-01-17 15:22:26,670 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:22:26,670 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:22:26,671 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:22:26,672 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:22:26,672 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:22:26,672 INFO mapred.MapTask: bufstart = 0; bufend = 6980325; bufvoid = 104857600\n",
            "2023-01-17 15:22:26,672 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586104(94344416); length = 2628293/6553600\n",
            "2023-01-17 15:22:27,329 INFO mapreduce.Job:  map 43% reduce 0%\n",
            "2023-01-17 15:22:27,377 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:22:27,381 INFO mapred.Task: Task:attempt_local884149691_0001_m_000003_0 is done. And is in the process of committing\n",
            "2023-01-17 15:22:27,383 INFO mapred.LocalJobRunner: Records R/W=2570/1\n",
            "2023-01-17 15:22:27,383 INFO mapred.Task: Task 'attempt_local884149691_0001_m_000003_0' done.\n",
            "2023-01-17 15:22:27,386 INFO mapred.Task: Final Counters for attempt_local884149691_0001_m_000003_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=134237843\n",
            "\t\tFILE: Number of bytes written=33791530\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657074\n",
            "\t\tMap output records=657074\n",
            "\t\tMap output bytes=6980325\n",
            "\t\tMap output materialized bytes=8294479\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657074\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=109\n",
            "\t\tTotal committed heap usage (bytes)=869269504\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:22:27,387 INFO mapred.LocalJobRunner: Finishing task: attempt_local884149691_0001_m_000003_0\n",
            "2023-01-17 15:22:27,387 INFO mapred.LocalJobRunner: Starting task: attempt_local884149691_0001_m_000004_0\n",
            "2023-01-17 15:22:27,388 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:22:27,388 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:22:27,389 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:22:27,390 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:134217728+33554432\n",
            "2023-01-17 15:22:27,393 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:22:27,431 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:22:27,431 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:22:27,431 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:22:27,431 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:22:27,431 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:22:27,432 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:22:27,439 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:22:27,462 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:27,462 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:27,462 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:27,462 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:27,596 INFO streaming.PipeMapRed: Records R/W=2562/1\n",
            "2023-01-17 15:22:27,610 INFO streaming.PipeMapRed: R/W/S=10000/5915/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:27,911 INFO streaming.PipeMapRed: R/W/S=100000/96838/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:28,111 INFO streaming.PipeMapRed: R/W/S=200000/196456/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:28,330 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 15:22:28,355 INFO streaming.PipeMapRed: R/W/S=300000/296087/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:28,573 INFO streaming.PipeMapRed: R/W/S=400000/396384/0 in:400000=400000/1 [rec/s] out:396384=396384/1 [rec/s]\n",
            "2023-01-17 15:22:28,773 INFO streaming.PipeMapRed: R/W/S=500000/496869/0 in:500000=500000/1 [rec/s] out:496869=496869/1 [rec/s]\n",
            "2023-01-17 15:22:28,980 INFO streaming.PipeMapRed: R/W/S=600000/596525/0 in:600000=600000/1 [rec/s] out:596525=596525/1 [rec/s]\n",
            "2023-01-17 15:22:29,113 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:22:29,114 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:22:29,114 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:22:29,115 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:22:29,115 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:22:29,115 INFO mapred.MapTask: bufstart = 0; bufend = 6979845; bufvoid = 104857600\n",
            "2023-01-17 15:22:29,115 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585972(94343888); length = 2628425/6553600\n",
            "2023-01-17 15:22:29,331 INFO mapreduce.Job:  map 57% reduce 0%\n",
            "2023-01-17 15:22:29,831 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:22:29,834 INFO mapred.Task: Task:attempt_local884149691_0001_m_000004_0 is done. And is in the process of committing\n",
            "2023-01-17 15:22:29,836 INFO mapred.LocalJobRunner: Records R/W=2562/1\n",
            "2023-01-17 15:22:29,836 INFO mapred.Task: Task 'attempt_local884149691_0001_m_000004_0' done.\n",
            "2023-01-17 15:22:29,840 INFO mapred.Task: Final Counters for attempt_local884149691_0001_m_000004_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=167796982\n",
            "\t\tFILE: Number of bytes written=42085627\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657107\n",
            "\t\tMap output records=657107\n",
            "\t\tMap output bytes=6979845\n",
            "\t\tMap output materialized bytes=8294065\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657107\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=101\n",
            "\t\tTotal committed heap usage (bytes)=969408512\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:22:29,842 INFO mapred.LocalJobRunner: Finishing task: attempt_local884149691_0001_m_000004_0\n",
            "2023-01-17 15:22:29,842 INFO mapred.LocalJobRunner: Starting task: attempt_local884149691_0001_m_000005_0\n",
            "2023-01-17 15:22:29,846 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:22:29,846 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:22:29,846 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:22:29,849 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:167772160+33554432\n",
            "2023-01-17 15:22:29,852 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:22:29,871 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:22:29,871 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:22:29,872 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:22:29,872 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:22:29,872 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:22:29,873 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:22:29,879 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:22:29,909 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:29,909 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:29,909 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:29,910 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:30,014 INFO streaming.PipeMapRed: Records R/W=2576/1\n",
            "2023-01-17 15:22:30,026 INFO streaming.PipeMapRed: R/W/S=10000/5965/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:30,220 INFO streaming.PipeMapRed: R/W/S=100000/96149/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:30,332 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 15:22:30,500 INFO streaming.PipeMapRed: R/W/S=200000/195760/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:30,710 INFO streaming.PipeMapRed: R/W/S=300000/296369/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:30,911 INFO streaming.PipeMapRed: R/W/S=400000/396828/0 in:400000=400000/1 [rec/s] out:396828=396828/1 [rec/s]\n",
            "2023-01-17 15:22:31,118 INFO streaming.PipeMapRed: R/W/S=500000/496307/0 in:500000=500000/1 [rec/s] out:496307=496307/1 [rec/s]\n",
            "2023-01-17 15:22:31,337 INFO streaming.PipeMapRed: R/W/S=600000/595891/0 in:600000=600000/1 [rec/s] out:595891=595891/1 [rec/s]\n",
            "2023-01-17 15:22:31,472 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:22:31,472 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:22:31,473 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:22:31,473 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:22:31,473 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:22:31,473 INFO mapred.MapTask: bufstart = 0; bufend = 6978534; bufvoid = 104857600\n",
            "2023-01-17 15:22:31,473 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585028(94340112); length = 2629369/6553600\n",
            "2023-01-17 15:22:32,158 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:22:32,161 INFO mapred.Task: Task:attempt_local884149691_0001_m_000005_0 is done. And is in the process of committing\n",
            "2023-01-17 15:22:32,164 INFO mapred.LocalJobRunner: Records R/W=2576/1\n",
            "2023-01-17 15:22:32,165 INFO mapred.Task: Task 'attempt_local884149691_0001_m_000005_0' done.\n",
            "2023-01-17 15:22:32,165 INFO mapred.Task: Final Counters for attempt_local884149691_0001_m_000005_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=201356121\n",
            "\t\tFILE: Number of bytes written=50378885\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657343\n",
            "\t\tMap output records=657343\n",
            "\t\tMap output bytes=6978534\n",
            "\t\tMap output materialized bytes=8293226\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657343\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=50\n",
            "\t\tTotal committed heap usage (bytes)=1081606144\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:22:32,165 INFO mapred.LocalJobRunner: Finishing task: attempt_local884149691_0001_m_000005_0\n",
            "2023-01-17 15:22:32,165 INFO mapred.LocalJobRunner: Starting task: attempt_local884149691_0001_m_000006_0\n",
            "2023-01-17 15:22:32,171 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:22:32,172 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:22:32,172 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:22:32,176 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:201326592+9986332\n",
            "2023-01-17 15:22:32,186 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:22:32,204 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:22:32,204 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:22:32,204 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:22:32,204 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:22:32,204 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:22:32,205 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:22:32,211 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:22:32,224 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:32,224 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:32,224 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:32,224 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:32,320 INFO streaming.PipeMapRed: Records R/W=2569/1\n",
            "2023-01-17 15:22:32,340 INFO streaming.PipeMapRed: R/W/S=10000/5963/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:32,538 INFO streaming.PipeMapRed: R/W/S=100000/96164/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:32,756 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:22:32,761 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:22:32,761 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:22:32,761 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:22:32,761 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:22:32,761 INFO mapred.MapTask: bufstart = 0; bufend = 2078292; bufvoid = 104857600\n",
            "2023-01-17 15:22:32,761 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25432028(101728112); length = 782369/6553600\n",
            "2023-01-17 15:22:32,982 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:22:32,985 INFO mapred.Task: Task:attempt_local884149691_0001_m_000006_0 is done. And is in the process of committing\n",
            "2023-01-17 15:22:32,988 INFO mapred.LocalJobRunner: Records R/W=2569/1\n",
            "2023-01-17 15:22:32,988 INFO mapred.Task: Task 'attempt_local884149691_0001_m_000006_0' done.\n",
            "2023-01-17 15:22:32,988 INFO mapred.Task: Final Counters for attempt_local884149691_0001_m_000006_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=211343064\n",
            "\t\tFILE: Number of bytes written=52848401\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=195593\n",
            "\t\tMap output records=195593\n",
            "\t\tMap output bytes=2078292\n",
            "\t\tMap output materialized bytes=2469484\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=195593\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1081606144\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=9986332\n",
            "2023-01-17 15:22:32,989 INFO mapred.LocalJobRunner: Finishing task: attempt_local884149691_0001_m_000006_0\n",
            "2023-01-17 15:22:32,989 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2023-01-17 15:22:32,993 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2023-01-17 15:22:32,994 INFO mapred.LocalJobRunner: Starting task: attempt_local884149691_0001_r_000000_0\n",
            "2023-01-17 15:22:33,006 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:22:33,006 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:22:33,006 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:22:33,011 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@649e533a\n",
            "2023-01-17 15:22:33,015 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2023-01-17 15:22:33,039 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2119434240, maxSingleShuffleLimit=529858560, mergeThreshold=1398826624, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2023-01-17 15:22:33,043 INFO reduce.EventFetcher: attempt_local884149691_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2023-01-17 15:22:33,097 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local884149691_0001_m_000005_0 decomp: 8293222 len: 8293226 to MEMORY\n",
            "2023-01-17 15:22:33,111 INFO reduce.InMemoryMapOutput: Read 8293222 bytes from map-output for attempt_local884149691_0001_m_000005_0\n",
            "2023-01-17 15:22:33,113 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8293222, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->8293222\n",
            "2023-01-17 15:22:33,123 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local884149691_0001_m_000002_0 decomp: 8294492 len: 8294496 to MEMORY\n",
            "2023-01-17 15:22:33,132 INFO reduce.InMemoryMapOutput: Read 8294492 bytes from map-output for attempt_local884149691_0001_m_000002_0\n",
            "2023-01-17 15:22:33,132 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8294492, inMemoryMapOutputs.size() -> 2, commitMemory -> 8293222, usedMemory ->16587714\n",
            "2023-01-17 15:22:33,136 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local884149691_0001_m_000006_0 decomp: 2469480 len: 2469484 to MEMORY\n",
            "2023-01-17 15:22:33,140 INFO reduce.InMemoryMapOutput: Read 2469480 bytes from map-output for attempt_local884149691_0001_m_000006_0\n",
            "2023-01-17 15:22:33,140 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2469480, inMemoryMapOutputs.size() -> 3, commitMemory -> 16587714, usedMemory ->19057194\n",
            "2023-01-17 15:22:33,148 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local884149691_0001_m_000003_0 decomp: 8294475 len: 8294479 to MEMORY\n",
            "2023-01-17 15:22:33,155 INFO reduce.InMemoryMapOutput: Read 8294475 bytes from map-output for attempt_local884149691_0001_m_000003_0\n",
            "2023-01-17 15:22:33,156 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8294475, inMemoryMapOutputs.size() -> 4, commitMemory -> 19057194, usedMemory ->27351669\n",
            "2023-01-17 15:22:33,164 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local884149691_0001_m_000000_0 decomp: 8295021 len: 8295025 to MEMORY\n",
            "2023-01-17 15:22:33,172 INFO reduce.InMemoryMapOutput: Read 8295021 bytes from map-output for attempt_local884149691_0001_m_000000_0\n",
            "2023-01-17 15:22:33,172 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8295021, inMemoryMapOutputs.size() -> 5, commitMemory -> 27351669, usedMemory ->35646690\n",
            "2023-01-17 15:22:33,179 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local884149691_0001_m_000001_0 decomp: 8293437 len: 8293441 to MEMORY\n",
            "2023-01-17 15:22:33,187 INFO reduce.InMemoryMapOutput: Read 8293437 bytes from map-output for attempt_local884149691_0001_m_000001_0\n",
            "2023-01-17 15:22:33,187 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8293437, inMemoryMapOutputs.size() -> 6, commitMemory -> 35646690, usedMemory ->43940127\n",
            "2023-01-17 15:22:33,196 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local884149691_0001_m_000004_0 decomp: 8294061 len: 8294065 to MEMORY\n",
            "2023-01-17 15:22:33,203 INFO reduce.InMemoryMapOutput: Read 8294061 bytes from map-output for attempt_local884149691_0001_m_000004_0\n",
            "2023-01-17 15:22:33,203 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 8294061, inMemoryMapOutputs.size() -> 7, commitMemory -> 43940127, usedMemory ->52234188\n",
            "2023-01-17 15:22:33,204 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2023-01-17 15:22:33,205 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 15:22:33,205 INFO reduce.MergeManagerImpl: finalMerge called with 7 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2023-01-17 15:22:33,215 INFO mapred.Merger: Merging 7 sorted segments\n",
            "2023-01-17 15:22:33,215 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 52234090 bytes\n",
            "2023-01-17 15:22:34,769 INFO reduce.MergeManagerImpl: Merged 7 segments, 52234188 bytes to disk to satisfy reduce memory limit\n",
            "2023-01-17 15:22:34,770 INFO reduce.MergeManagerImpl: Merging 1 files, 52234180 bytes from disk\n",
            "2023-01-17 15:22:34,771 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2023-01-17 15:22:34,771 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2023-01-17 15:22:34,772 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 52234162 bytes\n",
            "2023-01-17 15:22:34,772 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 15:22:34,785 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, reducer.py]\n",
            "2023-01-17 15:22:34,791 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2023-01-17 15:22:34,792 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2023-01-17 15:22:34,827 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:34,827 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:34,829 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:34,835 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:34,875 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:35,260 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:35,545 INFO streaming.PipeMapRed: R/W/S=200000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:35,733 INFO streaming.PipeMapRed: R/W/S=300000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:22:35,841 INFO streaming.PipeMapRed: R/W/S=400000/0/0 in:400000=400000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:22:35,933 INFO streaming.PipeMapRed: R/W/S=500000/0/0 in:500000=500000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:22:36,031 INFO streaming.PipeMapRed: R/W/S=600000/0/0 in:600000=600000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:22:36,135 INFO streaming.PipeMapRed: R/W/S=700000/0/0 in:700000=700000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:22:36,232 INFO streaming.PipeMapRed: R/W/S=800000/0/0 in:800000=800000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:22:36,340 INFO streaming.PipeMapRed: R/W/S=900000/0/0 in:900000=900000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:22:36,439 INFO streaming.PipeMapRed: R/W/S=1000000/0/0 in:1000000=1000000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:22:36,541 INFO streaming.PipeMapRed: R/W/S=1100000/0/0 in:1100000=1100000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:22:36,633 INFO streaming.PipeMapRed: R/W/S=1200000/0/0 in:1200000=1200000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:22:36,732 INFO streaming.PipeMapRed: R/W/S=1300000/0/0 in:1300000=1300000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:22:36,827 INFO streaming.PipeMapRed: R/W/S=1400000/0/0 in:700000=1400000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:22:36,923 INFO streaming.PipeMapRed: R/W/S=1500000/0/0 in:750000=1500000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:22:37,022 INFO streaming.PipeMapRed: R/W/S=1600000/0/0 in:800000=1600000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:22:37,112 INFO streaming.PipeMapRed: R/W/S=1700000/0/0 in:850000=1700000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:22:37,218 INFO streaming.PipeMapRed: R/W/S=1800000/0/0 in:900000=1800000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:22:37,314 INFO streaming.PipeMapRed: R/W/S=1900000/0/0 in:950000=1900000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:22:37,418 INFO streaming.PipeMapRed: R/W/S=2000000/0/0 in:1000000=2000000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:22:37,527 INFO streaming.PipeMapRed: R/W/S=2100000/0/0 in:1050000=2100000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:22:37,627 INFO streaming.PipeMapRed: R/W/S=2200000/0/0 in:1100000=2200000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:22:37,721 INFO streaming.PipeMapRed: R/W/S=2300000/0/0 in:1150000=2300000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:22:37,812 INFO streaming.PipeMapRed: R/W/S=2400000/0/0 in:800000=2400000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:22:37,911 INFO streaming.PipeMapRed: R/W/S=2500000/0/0 in:833333=2500000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:22:38,002 INFO streaming.PipeMapRed: R/W/S=2600000/0/0 in:866666=2600000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:22:38,102 INFO streaming.PipeMapRed: R/W/S=2700000/0/0 in:900000=2700000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:22:38,198 INFO streaming.PipeMapRed: R/W/S=2800000/0/0 in:933333=2800000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:22:38,295 INFO streaming.PipeMapRed: R/W/S=2900000/0/0 in:966666=2900000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:22:38,394 INFO streaming.PipeMapRed: R/W/S=3000000/0/0 in:1000000=3000000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:22:38,537 INFO streaming.PipeMapRed: R/W/S=3100000/0/0 in:1033333=3100000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:22:38,636 INFO streaming.PipeMapRed: R/W/S=3200000/0/0 in:1066666=3200000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:22:38,734 INFO streaming.PipeMapRed: R/W/S=3300000/0/0 in:1100000=3300000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:22:38,829 INFO streaming.PipeMapRed: R/W/S=3400000/0/0 in:850000=3400000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:22:38,928 INFO streaming.PipeMapRed: R/W/S=3500000/0/0 in:875000=3500000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:22:39,026 INFO streaming.PipeMapRed: R/W/S=3600000/0/0 in:900000=3600000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:22:39,119 INFO streaming.PipeMapRed: R/W/S=3700000/0/0 in:925000=3700000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:22:39,219 INFO streaming.PipeMapRed: R/W/S=3800000/0/0 in:950000=3800000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:22:39,309 INFO streaming.PipeMapRed: R/W/S=3900000/0/0 in:975000=3900000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:22:39,407 INFO streaming.PipeMapRed: R/W/S=4000000/0/0 in:1000000=4000000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:22:39,514 INFO streaming.PipeMapRed: R/W/S=4100000/0/0 in:1025000=4100000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:22:39,580 INFO streaming.PipeMapRed: Records R/W=4138476/1\n",
            "2023-01-17 15:22:39,587 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:22:39,589 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:22:39,590 INFO mapred.Task: Task:attempt_local884149691_0001_r_000000_0 is done. And is in the process of committing\n",
            "2023-01-17 15:22:39,592 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 15:22:39,592 INFO mapred.Task: Task attempt_local884149691_0001_r_000000_0 is allowed to commit now\n",
            "2023-01-17 15:22:39,594 INFO output.FileOutputCommitter: Saved output of task 'attempt_local884149691_0001_r_000000_0' to file:/root/myoutput\n",
            "2023-01-17 15:22:39,596 INFO mapred.LocalJobRunner: Records R/W=4138476/1 > reduce\n",
            "2023-01-17 15:22:39,596 INFO mapred.Task: Task 'attempt_local884149691_0001_r_000000_0' done.\n",
            "2023-01-17 15:22:39,596 INFO mapred.Task: Final Counters for attempt_local884149691_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=315811684\n",
            "\t\tFILE: Number of bytes written=105084107\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=103\n",
            "\t\tReduce shuffle bytes=52234216\n",
            "\t\tReduce input records=4138476\n",
            "\t\tReduce output records=103\n",
            "\t\tSpilled Records=4138476\n",
            "\t\tShuffled Maps =7\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=7\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=1081606144\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=1526\n",
            "2023-01-17 15:22:39,597 INFO mapred.LocalJobRunner: Finishing task: attempt_local884149691_0001_r_000000_0\n",
            "2023-01-17 15:22:39,597 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2023-01-17 15:22:40,337 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2023-01-17 15:22:40,338 INFO mapreduce.Job: Job job_local884149691_0001 completed successfully\n",
            "2023-01-17 15:22:40,361 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1231904389\n",
            "\t\tFILE: Number of bytes written=335797078\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=4138476\n",
            "\t\tMap output records=4138476\n",
            "\t\tMap output bytes=43957222\n",
            "\t\tMap output materialized bytes=52234216\n",
            "\t\tInput split bytes=588\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=103\n",
            "\t\tReduce shuffle bytes=52234216\n",
            "\t\tReduce input records=4138476\n",
            "\t\tReduce output records=103\n",
            "\t\tSpilled Records=8276952\n",
            "\t\tShuffled Maps =7\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=7\n",
            "\t\tGC time elapsed (ms)=679\n",
            "\t\tTotal committed heap usage (bytes)=6980370432\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=211337500\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=1526\n",
            "2023-01-17 15:22:40,361 INFO streaming.StreamJob: Output directory: /root/myoutput\n"
          ]
        }
      ],
      "source": [
        "!rm -r ~/myoutput\n",
        "!/usr/local/hadoop-3.3.0/bin/hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input ~/myinput -output ~/myoutput -file /content/mapper.py  -file /content/reducer.py  -mapper 'python mapper.py'  -reducer 'python reducer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebfebe1-ddda-4ab5-91d8-62b87ad76515",
        "id": "IwdN4RF0JVzP"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000  _SUCCESS\n"
          ]
        }
      ],
      "source": [
        "!ls ~/myoutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d13f160e-b660-4cbe-e496-b0902db0058e",
        "id": "ItNDL1kpJVzP"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pittsburgh']\t\n",
            "['Plano']\t\n",
            "['Portland']\t\n",
            "['Raleigh']\t\n",
            "['Reno']\t\n",
            "['Richmond']\t\n",
            "['Riverside']\t\n",
            "['Rochester']\t\n",
            "['Sacramento']\t\n",
            "['Saint Paul']\t\n",
            "['San Antonio']\t\n",
            "['San Bernardino']\t\n",
            "['San Diego']\t\n",
            "['San Francisco']\t\n",
            "['San Jose']\t\n",
            "['Santa Ana']\t\n",
            "['Scottsdale']\t\n",
            "['Seattle']\t\n",
            "['Spokane']\t\n",
            "['St. Louis']\t\n",
            "['St. Petersburg']\t\n",
            "['Stockton']\t\n",
            "['Tampa']\t\n",
            "['Toledo']\t\n",
            "['Tucson']\t\n",
            "['Tulsa']\t\n",
            "['Virginia Beach']\t\n",
            "['Washington']\t\n",
            "['Wichita']\t\n",
            "['Winston–Salem']\t\n"
          ]
        }
      ],
      "source": [
        "!tail -n 30 ~/myoutput/part-00000"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1rxJwGBlJLFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qOL_orW8La1T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmb4rNYwLcR1"
      },
      "source": [
        "# **Correction**\n",
        "\n",
        "**4 - Quel est le nombre total des ventes et la valeur totale des ventes de tous les magasins confondus ?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbdF_WslLcR2"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "import sys\n",
        "# Mettez vos instructions ...\n",
        "for line in sys.stdin:\n",
        "  data = line.strip().split(\"\\t\")\n",
        "  if len(data) == 6:\n",
        "    date, time, store, item, amount, payment = data\n",
        "    print(item, \"\\t\", str(amount))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SO6CFM8qLcR2"
      },
      "outputs": [],
      "source": [
        "# All cell codes are stored in a List variable \"In\"\n",
        "with open('/content/mapper.py', 'w') as f:\n",
        "  f.write(In[155]) \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqSYjcg4LcR2"
      },
      "outputs": [],
      "source": [
        "!chmod u+rwx /content/mapper.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMgZwKKrLcR3",
        "outputId": "f5e26534-5889-48d8-c2ae-48c2a5f4d049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Men's Clothing \t 214.05\n",
            "Women's Clothing \t 153.57\n",
            "Music \t 66.08\n",
            "Pet Supplies \t 493.51\n",
            "Children's Clothing \t 235.63\n",
            "Men's Clothing \t 247.18\n",
            "Cameras \t 379.6\n",
            "Consumer Electronics \t 296.8\n",
            "Toys \t 25.38\n",
            "Toys \t 213.88\n"
          ]
        }
      ],
      "source": [
        "!head -10 ~/myinput/purchases.txt | python3 /content/mapper.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAf80AphLcR3"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/python\n",
        "from operator import itemgetter\n",
        "import sys\n",
        "# Mettez vos instructions ...\n",
        "total_Sale = 0\n",
        "count = 0\n",
        "\n",
        "for line in sys.stdin:\n",
        "  data = line.strip().split(\"\\t\")\n",
        "  if len(data) != 2:\n",
        "    continue\n",
        "    \n",
        "  count += 1\n",
        "  total_Sale += float(data[1])\n",
        "\n",
        "if count != 0:\n",
        "  print(f\"Nombre total de ventes : {count} \\n Valeur totale des ventes: {total_Sale}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR4qpeUZLcR3"
      },
      "outputs": [],
      "source": [
        "# All cell codes are stored in a List variable \"In\"\n",
        "with open('/content/reducer.py', 'w') as f:\n",
        "  f.write(In[161]) \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0W_ExeaLcR4"
      },
      "outputs": [],
      "source": [
        "!chmod u+rwx /content/reducer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61XuM9i3LcR4",
        "outputId": "8067a13d-5c1f-4041-fed7-cb84daddae29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre total de ventes : 50 \n",
            " Valeur totale des ventes: 11259.819999999998\n"
          ]
        }
      ],
      "source": [
        "!head -50 ~/myinput/purchases.txt | python3 /content/mapper.py | sort | python3 /content/reducer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pcg15P2cLcR4",
        "outputId": "cda8e22f-08a3-4dab-dc19-2c1fdb5aa7e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-01-17 15:50:19,940 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
            "packageJobJar: [/content/mapper.py, /content/reducer.py] [] /tmp/streamjob5581750343310435674.jar tmpDir=null\n",
            "2023-01-17 15:50:20,699 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
            "2023-01-17 15:50:20,806 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
            "2023-01-17 15:50:20,806 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
            "2023-01-17 15:50:20,831 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2023-01-17 15:50:21,088 INFO mapred.FileInputFormat: Total input files to process : 1\n",
            "2023-01-17 15:50:21,110 INFO mapreduce.JobSubmitter: number of splits:7\n",
            "2023-01-17 15:50:21,346 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local204468955_0001\n",
            "2023-01-17 15:50:21,346 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
            "2023-01-17 15:50:21,686 INFO mapred.LocalDistributedCacheManager: Localized file:/content/mapper.py as file:/tmp/hadoop-root/mapred/local/job_local204468955_0001_d8fb6829-3df2-4b93-a13b-23612ff573a4/mapper.py\n",
            "2023-01-17 15:50:21,718 INFO mapred.LocalDistributedCacheManager: Localized file:/content/reducer.py as file:/tmp/hadoop-root/mapred/local/job_local204468955_0001_6bb3f696-0815-4ba5-94bd-d2da7aa3ba80/reducer.py\n",
            "2023-01-17 15:50:21,886 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
            "2023-01-17 15:50:21,888 INFO mapreduce.Job: Running job: job_local204468955_0001\n",
            "2023-01-17 15:50:21,896 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
            "2023-01-17 15:50:21,898 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
            "2023-01-17 15:50:21,909 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:50:21,910 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:50:21,991 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
            "2023-01-17 15:50:21,997 INFO mapred.LocalJobRunner: Starting task: attempt_local204468955_0001_m_000000_0\n",
            "2023-01-17 15:50:22,029 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:50:22,029 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:50:22,072 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:50:22,091 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:0+33554432\n",
            "2023-01-17 15:50:22,223 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:50:22,312 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:50:22,312 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:50:22,312 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:50:22,312 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:50:22,312 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:50:22,316 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:50:22,326 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:50:22,332 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
            "2023-01-17 15:50:22,333 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
            "2023-01-17 15:50:22,334 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
            "2023-01-17 15:50:22,334 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
            "2023-01-17 15:50:22,335 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
            "2023-01-17 15:50:22,335 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
            "2023-01-17 15:50:22,335 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
            "2023-01-17 15:50:22,336 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
            "2023-01-17 15:50:22,336 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
            "2023-01-17 15:50:22,338 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
            "2023-01-17 15:50:22,338 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
            "2023-01-17 15:50:22,339 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
            "2023-01-17 15:50:22,375 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:22,376 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:22,377 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:22,390 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:22,496 INFO streaming.PipeMapRed: Records R/W=2565/1\n",
            "2023-01-17 15:50:22,557 INFO streaming.PipeMapRed: R/W/S=10000/5887/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:22,895 INFO mapreduce.Job: Job job_local204468955_0001 running in uber mode : false\n",
            "2023-01-17 15:50:22,896 INFO mapreduce.Job:  map 0% reduce 0%\n",
            "2023-01-17 15:50:22,997 INFO streaming.PipeMapRed: R/W/S=100000/96098/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:23,313 INFO streaming.PipeMapRed: R/W/S=200000/196366/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:23,634 INFO streaming.PipeMapRed: R/W/S=300000/296148/0 in:300000=300000/1 [rec/s] out:296148=296148/1 [rec/s]\n",
            "2023-01-17 15:50:24,083 INFO streaming.PipeMapRed: R/W/S=400000/396254/0 in:400000=400000/1 [rec/s] out:396254=396254/1 [rec/s]\n",
            "2023-01-17 15:50:24,390 INFO streaming.PipeMapRed: R/W/S=500000/496438/0 in:250000=500000/2 [rec/s] out:248219=496438/2 [rec/s]\n",
            "2023-01-17 15:50:24,692 INFO streaming.PipeMapRed: R/W/S=600000/596639/0 in:300000=600000/2 [rec/s] out:298319=596639/2 [rec/s]\n",
            "2023-01-17 15:50:24,868 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:50:24,869 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:50:24,873 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:50:24,873 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:50:24,873 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:50:24,874 INFO mapred.MapTask: bufstart = 0; bufend = 12777601; bufvoid = 104857600\n",
            "2023-01-17 15:50:24,874 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586356(94345424); length = 2628041/6553600\n",
            "2023-01-17 15:50:25,615 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:50:25,633 INFO mapred.Task: Task:attempt_local204468955_0001_m_000000_0 is done. And is in the process of committing\n",
            "2023-01-17 15:50:25,636 INFO mapred.LocalJobRunner: Records R/W=2565/1\n",
            "2023-01-17 15:50:25,636 INFO mapred.Task: Task 'attempt_local204468955_0001_m_000000_0' done.\n",
            "2023-01-17 15:50:25,645 INFO mapred.Task: Final Counters for attempt_local204468955_0001_m_000000_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=33560516\n",
            "\t\tFILE: Number of bytes written=14705712\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657011\n",
            "\t\tMap output records=657011\n",
            "\t\tMap output bytes=12777601\n",
            "\t\tMap output materialized bytes=14091629\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657011\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=95\n",
            "\t\tTotal committed heap usage (bytes)=304087040\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:50:25,646 INFO mapred.LocalJobRunner: Finishing task: attempt_local204468955_0001_m_000000_0\n",
            "2023-01-17 15:50:25,646 INFO mapred.LocalJobRunner: Starting task: attempt_local204468955_0001_m_000001_0\n",
            "2023-01-17 15:50:25,647 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:50:25,647 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:50:25,648 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:50:25,649 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:33554432+33554432\n",
            "2023-01-17 15:50:25,659 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:50:25,730 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:50:25,731 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:50:25,731 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:50:25,731 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:50:25,731 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:50:25,731 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:50:25,739 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:50:25,772 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:25,772 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:25,773 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:25,777 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:25,900 INFO streaming.PipeMapRed: Records R/W=2572/1\n",
            "2023-01-17 15:50:25,901 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 15:50:25,945 INFO streaming.PipeMapRed: R/W/S=10000/5937/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:26,320 INFO streaming.PipeMapRed: R/W/S=100000/96146/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:26,622 INFO streaming.PipeMapRed: R/W/S=200000/196919/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:26,914 INFO streaming.PipeMapRed: R/W/S=300000/296263/0 in:300000=300000/1 [rec/s] out:296263=296263/1 [rec/s]\n",
            "2023-01-17 15:50:27,207 INFO streaming.PipeMapRed: R/W/S=400000/396091/0 in:400000=400000/1 [rec/s] out:396091=396091/1 [rec/s]\n",
            "2023-01-17 15:50:27,489 INFO streaming.PipeMapRed: R/W/S=500000/496364/0 in:500000=500000/1 [rec/s] out:496387=496387/1 [rec/s]\n",
            "2023-01-17 15:50:27,759 INFO streaming.PipeMapRed: R/W/S=600000/596622/0 in:300000=600000/2 [rec/s] out:298311=596622/2 [rec/s]\n",
            "2023-01-17 15:50:27,929 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:50:27,938 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:50:27,941 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:50:27,941 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:50:27,941 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:50:27,941 INFO mapred.MapTask: bufstart = 0; bufend = 12774344; bufvoid = 104857600\n",
            "2023-01-17 15:50:27,941 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585260(94341040); length = 2629137/6553600\n",
            "2023-01-17 15:50:28,548 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:50:28,551 INFO mapred.Task: Task:attempt_local204468955_0001_m_000001_0 is done. And is in the process of committing\n",
            "2023-01-17 15:50:28,552 INFO mapred.LocalJobRunner: Records R/W=2572/1\n",
            "2023-01-17 15:50:28,553 INFO mapred.Task: Task 'attempt_local204468955_0001_m_000001_0' done.\n",
            "2023-01-17 15:50:28,553 INFO mapred.Task: Final Counters for attempt_local204468955_0001_m_000001_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=67119655\n",
            "\t\tFILE: Number of bytes written=28794664\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657285\n",
            "\t\tMap output records=657285\n",
            "\t\tMap output bytes=12774344\n",
            "\t\tMap output materialized bytes=14088920\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657285\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=3\n",
            "\t\tTotal committed heap usage (bytes)=409468928\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:50:28,553 INFO mapred.LocalJobRunner: Finishing task: attempt_local204468955_0001_m_000001_0\n",
            "2023-01-17 15:50:28,553 INFO mapred.LocalJobRunner: Starting task: attempt_local204468955_0001_m_000002_0\n",
            "2023-01-17 15:50:28,555 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:50:28,555 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:50:28,556 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:50:28,557 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:67108864+33554432\n",
            "2023-01-17 15:50:28,564 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:50:28,636 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:50:28,636 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:50:28,636 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:50:28,636 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:50:28,636 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:50:28,637 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:50:28,643 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:50:28,666 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:28,666 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:28,666 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:28,667 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:28,779 INFO streaming.PipeMapRed: Records R/W=2566/1\n",
            "2023-01-17 15:50:28,801 INFO streaming.PipeMapRed: R/W/S=10000/6284/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:29,062 INFO streaming.PipeMapRed: R/W/S=100000/96032/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:29,358 INFO streaming.PipeMapRed: R/W/S=200000/196131/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:29,641 INFO streaming.PipeMapRed: R/W/S=300000/296326/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:29,935 INFO streaming.PipeMapRed: R/W/S=400000/396531/0 in:400000=400000/1 [rec/s] out:396531=396531/1 [rec/s]\n",
            "2023-01-17 15:50:30,222 INFO streaming.PipeMapRed: R/W/S=500000/495948/0 in:500000=500000/1 [rec/s] out:495948=495948/1 [rec/s]\n",
            "2023-01-17 15:50:30,536 INFO streaming.PipeMapRed: R/W/S=600000/596629/0 in:600000=600000/1 [rec/s] out:596629=596629/1 [rec/s]\n",
            "2023-01-17 15:50:30,712 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:50:30,713 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:50:30,713 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:50:30,713 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:50:30,713 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:50:30,713 INFO mapred.MapTask: bufstart = 0; bufend = 12775666; bufvoid = 104857600\n",
            "2023-01-17 15:50:30,713 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586148(94344592); length = 2628249/6553600\n",
            "2023-01-17 15:50:30,905 INFO mapreduce.Job:  map 29% reduce 0%\n",
            "2023-01-17 15:50:31,185 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:50:31,187 INFO mapred.Task: Task:attempt_local204468955_0001_m_000002_0 is done. And is in the process of committing\n",
            "2023-01-17 15:50:31,189 INFO mapred.LocalJobRunner: Records R/W=2566/1\n",
            "2023-01-17 15:50:31,189 INFO mapred.Task: Task 'attempt_local204468955_0001_m_000002_0' done.\n",
            "2023-01-17 15:50:31,192 INFO mapred.Task: Final Counters for attempt_local204468955_0001_m_000002_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=100678794\n",
            "\t\tFILE: Number of bytes written=42884494\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657063\n",
            "\t\tMap output records=657063\n",
            "\t\tMap output bytes=12775666\n",
            "\t\tMap output materialized bytes=14089798\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657063\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=6\n",
            "\t\tTotal committed heap usage (bytes)=563609600\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:50:31,192 INFO mapred.LocalJobRunner: Finishing task: attempt_local204468955_0001_m_000002_0\n",
            "2023-01-17 15:50:31,192 INFO mapred.LocalJobRunner: Starting task: attempt_local204468955_0001_m_000003_0\n",
            "2023-01-17 15:50:31,198 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:50:31,198 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:50:31,198 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:50:31,200 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:100663296+33554432\n",
            "2023-01-17 15:50:31,203 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:50:31,226 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:50:31,226 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:50:31,226 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:50:31,226 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:50:31,226 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:50:31,227 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:50:31,236 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:50:31,257 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:31,257 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:31,257 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:31,257 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:31,392 INFO streaming.PipeMapRed: Records R/W=2570/1\n",
            "2023-01-17 15:50:31,409 INFO streaming.PipeMapRed: R/W/S=10000/5859/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:31,678 INFO streaming.PipeMapRed: R/W/S=100000/96367/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:31,905 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 15:50:31,963 INFO streaming.PipeMapRed: R/W/S=200000/196544/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:32,276 INFO streaming.PipeMapRed: R/W/S=300000/295992/0 in:300000=300000/1 [rec/s] out:295992=295992/1 [rec/s]\n",
            "2023-01-17 15:50:32,571 INFO streaming.PipeMapRed: R/W/S=400000/396713/0 in:400000=400000/1 [rec/s] out:396713=396713/1 [rec/s]\n",
            "2023-01-17 15:50:33,064 INFO streaming.PipeMapRed: R/W/S=500000/496681/0 in:500000=500000/1 [rec/s] out:496681=496681/1 [rec/s]\n",
            "2023-01-17 15:50:33,355 INFO streaming.PipeMapRed: R/W/S=600000/596116/0 in:300000=600000/2 [rec/s] out:298058=596116/2 [rec/s]\n",
            "2023-01-17 15:50:33,526 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:50:33,527 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:50:33,528 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:50:33,529 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:50:33,529 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:50:33,529 INFO mapred.MapTask: bufstart = 0; bufend = 12772296; bufvoid = 104857600\n",
            "2023-01-17 15:50:33,529 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23586104(94344416); length = 2628293/6553600\n",
            "2023-01-17 15:50:33,907 INFO mapreduce.Job:  map 43% reduce 0%\n",
            "2023-01-17 15:50:34,008 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:50:34,010 INFO mapred.Task: Task:attempt_local204468955_0001_m_000003_0 is done. And is in the process of committing\n",
            "2023-01-17 15:50:34,012 INFO mapred.LocalJobRunner: Records R/W=2570/1\n",
            "2023-01-17 15:50:34,012 INFO mapred.Task: Task 'attempt_local204468955_0001_m_000003_0' done.\n",
            "2023-01-17 15:50:34,012 INFO mapred.Task: Final Counters for attempt_local204468955_0001_m_000003_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=134237933\n",
            "\t\tFILE: Number of bytes written=56970976\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657074\n",
            "\t\tMap output records=657074\n",
            "\t\tMap output bytes=12772296\n",
            "\t\tMap output materialized bytes=14086450\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657074\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=214\n",
            "\t\tTotal committed heap usage (bytes)=505413632\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:50:34,012 INFO mapred.LocalJobRunner: Finishing task: attempt_local204468955_0001_m_000003_0\n",
            "2023-01-17 15:50:34,013 INFO mapred.LocalJobRunner: Starting task: attempt_local204468955_0001_m_000004_0\n",
            "2023-01-17 15:50:34,014 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:50:34,014 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:50:34,014 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:50:34,015 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:134217728+33554432\n",
            "2023-01-17 15:50:34,018 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:50:34,035 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:50:34,036 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:50:34,036 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:50:34,036 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:50:34,036 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:50:34,036 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:50:34,044 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:50:34,071 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:34,071 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:34,071 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:34,071 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:34,164 INFO streaming.PipeMapRed: Records R/W=2562/1\n",
            "2023-01-17 15:50:34,186 INFO streaming.PipeMapRed: R/W/S=10000/5856/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:34,458 INFO streaming.PipeMapRed: R/W/S=100000/96029/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:34,735 INFO streaming.PipeMapRed: R/W/S=200000/195983/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:34,946 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 15:50:35,148 INFO streaming.PipeMapRed: R/W/S=300000/296288/0 in:300000=300000/1 [rec/s] out:296288=296288/1 [rec/s]\n",
            "2023-01-17 15:50:35,442 INFO streaming.PipeMapRed: R/W/S=400000/394367/0 in:400000=400000/1 [rec/s] out:394367=394367/1 [rec/s]\n",
            "2023-01-17 15:50:35,725 INFO streaming.PipeMapRed: R/W/S=500000/496778/0 in:500000=500000/1 [rec/s] out:496778=496778/1 [rec/s]\n",
            "2023-01-17 15:50:36,014 INFO streaming.PipeMapRed: R/W/S=600000/596335/0 in:600000=600000/1 [rec/s] out:596335=596335/1 [rec/s]\n",
            "2023-01-17 15:50:36,180 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:50:36,181 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:50:36,181 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:50:36,181 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:50:36,181 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:50:36,181 INFO mapred.MapTask: bufstart = 0; bufend = 12771456; bufvoid = 104857600\n",
            "2023-01-17 15:50:36,181 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585972(94343888); length = 2628425/6553600\n",
            "2023-01-17 15:50:36,685 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:50:36,689 INFO mapred.Task: Task:attempt_local204468955_0001_m_000004_0 is done. And is in the process of committing\n",
            "2023-01-17 15:50:36,690 INFO mapred.LocalJobRunner: Records R/W=2562/1\n",
            "2023-01-17 15:50:36,690 INFO mapred.Task: Task 'attempt_local204468955_0001_m_000004_0' done.\n",
            "2023-01-17 15:50:36,691 INFO mapred.Task: Final Counters for attempt_local204468955_0001_m_000004_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=167797072\n",
            "\t\tFILE: Number of bytes written=71056684\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657107\n",
            "\t\tMap output records=657107\n",
            "\t\tMap output bytes=12771456\n",
            "\t\tMap output materialized bytes=14085676\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657107\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=132\n",
            "\t\tTotal committed heap usage (bytes)=695730176\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:50:36,691 INFO mapred.LocalJobRunner: Finishing task: attempt_local204468955_0001_m_000004_0\n",
            "2023-01-17 15:50:36,691 INFO mapred.LocalJobRunner: Starting task: attempt_local204468955_0001_m_000005_0\n",
            "2023-01-17 15:50:36,692 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:50:36,692 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:50:36,693 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:50:36,695 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:167772160+33554432\n",
            "2023-01-17 15:50:36,699 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:50:36,717 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:50:36,717 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:50:36,717 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:50:36,717 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:50:36,717 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:50:36,718 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:50:36,724 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:50:36,734 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:36,734 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:36,734 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:36,734 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:36,827 INFO streaming.PipeMapRed: Records R/W=2576/1\n",
            "2023-01-17 15:50:36,843 INFO streaming.PipeMapRed: R/W/S=10000/5902/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:37,107 INFO streaming.PipeMapRed: R/W/S=100000/96167/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:37,415 INFO streaming.PipeMapRed: R/W/S=200000/196387/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:37,722 INFO streaming.PipeMapRed: R/W/S=300000/296669/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:38,021 INFO streaming.PipeMapRed: R/W/S=400000/396714/0 in:400000=400000/1 [rec/s] out:396714=396714/1 [rec/s]\n",
            "2023-01-17 15:50:38,318 INFO streaming.PipeMapRed: R/W/S=500000/496609/0 in:500000=500000/1 [rec/s] out:496609=496609/1 [rec/s]\n",
            "2023-01-17 15:50:38,664 INFO streaming.PipeMapRed: R/W/S=600000/596708/0 in:600000=600000/1 [rec/s] out:596708=596708/1 [rec/s]\n",
            "2023-01-17 15:50:38,867 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:50:38,868 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:50:38,868 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:50:38,868 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:50:38,868 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:50:38,868 INFO mapred.MapTask: bufstart = 0; bufend = 12773926; bufvoid = 104857600\n",
            "2023-01-17 15:50:38,868 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 23585028(94340112); length = 2629369/6553600\n",
            "2023-01-17 15:50:38,955 INFO mapreduce.Job:  map 71% reduce 0%\n",
            "2023-01-17 15:50:39,367 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:50:39,369 INFO mapred.Task: Task:attempt_local204468955_0001_m_000005_0 is done. And is in the process of committing\n",
            "2023-01-17 15:50:39,371 INFO mapred.LocalJobRunner: Records R/W=2576/1\n",
            "2023-01-17 15:50:39,371 INFO mapred.Task: Task 'attempt_local204468955_0001_m_000005_0' done.\n",
            "2023-01-17 15:50:39,371 INFO mapred.Task: Final Counters for attempt_local204468955_0001_m_000005_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=201356211\n",
            "\t\tFILE: Number of bytes written=85145334\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=657343\n",
            "\t\tMap output records=657343\n",
            "\t\tMap output bytes=12773926\n",
            "\t\tMap output materialized bytes=14088618\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=657343\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=695730176\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=33558528\n",
            "2023-01-17 15:50:39,372 INFO mapred.LocalJobRunner: Finishing task: attempt_local204468955_0001_m_000005_0\n",
            "2023-01-17 15:50:39,372 INFO mapred.LocalJobRunner: Starting task: attempt_local204468955_0001_m_000006_0\n",
            "2023-01-17 15:50:39,373 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:50:39,373 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:50:39,373 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:50:39,380 INFO mapred.MapTask: Processing split: file:/root/myinput/purchases.txt:201326592+9986332\n",
            "2023-01-17 15:50:39,386 INFO mapred.MapTask: numReduceTasks: 1\n",
            "2023-01-17 15:50:39,407 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
            "2023-01-17 15:50:39,408 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
            "2023-01-17 15:50:39,408 INFO mapred.MapTask: soft limit at 83886080\n",
            "2023-01-17 15:50:39,408 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
            "2023-01-17 15:50:39,408 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
            "2023-01-17 15:50:39,409 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
            "2023-01-17 15:50:39,415 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n",
            "2023-01-17 15:50:39,423 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:39,423 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:39,423 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:39,423 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:39,525 INFO streaming.PipeMapRed: Records R/W=2569/1\n",
            "2023-01-17 15:50:39,551 INFO streaming.PipeMapRed: R/W/S=10000/6337/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:39,818 INFO streaming.PipeMapRed: R/W/S=100000/96129/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:39,956 INFO mapreduce.Job:  map 100% reduce 0%\n",
            "2023-01-17 15:50:40,124 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:50:40,126 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:50:40,126 INFO mapred.LocalJobRunner: \n",
            "2023-01-17 15:50:40,126 INFO mapred.MapTask: Starting flush of map output\n",
            "2023-01-17 15:50:40,126 INFO mapred.MapTask: Spilling map output\n",
            "2023-01-17 15:50:40,127 INFO mapred.MapTask: bufstart = 0; bufend = 3798521; bufvoid = 104857600\n",
            "2023-01-17 15:50:40,127 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25432028(101728112); length = 782369/6553600\n",
            "2023-01-17 15:50:40,313 INFO mapred.MapTask: Finished spill 0\n",
            "2023-01-17 15:50:40,316 INFO mapred.Task: Task:attempt_local204468955_0001_m_000006_0 is done. And is in the process of committing\n",
            "2023-01-17 15:50:40,318 INFO mapred.LocalJobRunner: Records R/W=2569/1\n",
            "2023-01-17 15:50:40,318 INFO mapred.Task: Task 'attempt_local204468955_0001_m_000006_0' done.\n",
            "2023-01-17 15:50:40,319 INFO mapred.Task: Final Counters for attempt_local204468955_0001_m_000006_0: Counters: 17\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=211343154\n",
            "\t\tFILE: Number of bytes written=89335079\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=195593\n",
            "\t\tMap output records=195593\n",
            "\t\tMap output bytes=3798521\n",
            "\t\tMap output materialized bytes=4189713\n",
            "\t\tInput split bytes=84\n",
            "\t\tCombine input records=0\n",
            "\t\tSpilled Records=195593\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=0\n",
            "\t\tGC time elapsed (ms)=3\n",
            "\t\tTotal committed heap usage (bytes)=695730176\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=9986332\n",
            "2023-01-17 15:50:40,319 INFO mapred.LocalJobRunner: Finishing task: attempt_local204468955_0001_m_000006_0\n",
            "2023-01-17 15:50:40,319 INFO mapred.LocalJobRunner: map task executor complete.\n",
            "2023-01-17 15:50:40,326 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
            "2023-01-17 15:50:40,326 INFO mapred.LocalJobRunner: Starting task: attempt_local204468955_0001_r_000000_0\n",
            "2023-01-17 15:50:40,335 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
            "2023-01-17 15:50:40,336 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
            "2023-01-17 15:50:40,336 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
            "2023-01-17 15:50:40,342 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1db46071\n",
            "2023-01-17 15:50:40,344 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
            "2023-01-17 15:50:40,376 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2119434240, maxSingleShuffleLimit=529858560, mergeThreshold=1398826624, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
            "2023-01-17 15:50:40,385 INFO reduce.EventFetcher: attempt_local204468955_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
            "2023-01-17 15:50:40,432 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local204468955_0001_m_000000_0 decomp: 14091625 len: 14091629 to MEMORY\n",
            "2023-01-17 15:50:40,451 INFO reduce.InMemoryMapOutput: Read 14091625 bytes from map-output for attempt_local204468955_0001_m_000000_0\n",
            "2023-01-17 15:50:40,453 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14091625, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->14091625\n",
            "2023-01-17 15:50:40,459 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local204468955_0001_m_000001_0 decomp: 14088916 len: 14088920 to MEMORY\n",
            "2023-01-17 15:50:40,473 INFO reduce.InMemoryMapOutput: Read 14088916 bytes from map-output for attempt_local204468955_0001_m_000001_0\n",
            "2023-01-17 15:50:40,473 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14088916, inMemoryMapOutputs.size() -> 2, commitMemory -> 14091625, usedMemory ->28180541\n",
            "2023-01-17 15:50:40,479 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local204468955_0001_m_000004_0 decomp: 14085672 len: 14085676 to MEMORY\n",
            "2023-01-17 15:50:40,497 INFO reduce.InMemoryMapOutput: Read 14085672 bytes from map-output for attempt_local204468955_0001_m_000004_0\n",
            "2023-01-17 15:50:40,499 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14085672, inMemoryMapOutputs.size() -> 3, commitMemory -> 28180541, usedMemory ->42266213\n",
            "2023-01-17 15:50:40,503 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local204468955_0001_m_000002_0 decomp: 14089794 len: 14089798 to MEMORY\n",
            "2023-01-17 15:50:40,518 INFO reduce.InMemoryMapOutput: Read 14089794 bytes from map-output for attempt_local204468955_0001_m_000002_0\n",
            "2023-01-17 15:50:40,519 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14089794, inMemoryMapOutputs.size() -> 4, commitMemory -> 42266213, usedMemory ->56356007\n",
            "2023-01-17 15:50:40,524 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local204468955_0001_m_000005_0 decomp: 14088614 len: 14088618 to MEMORY\n",
            "2023-01-17 15:50:40,536 INFO reduce.InMemoryMapOutput: Read 14088614 bytes from map-output for attempt_local204468955_0001_m_000005_0\n",
            "2023-01-17 15:50:40,537 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14088614, inMemoryMapOutputs.size() -> 5, commitMemory -> 56356007, usedMemory ->70444621\n",
            "2023-01-17 15:50:40,547 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local204468955_0001_m_000003_0 decomp: 14086446 len: 14086450 to MEMORY\n",
            "2023-01-17 15:50:40,559 INFO reduce.InMemoryMapOutput: Read 14086446 bytes from map-output for attempt_local204468955_0001_m_000003_0\n",
            "2023-01-17 15:50:40,560 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 14086446, inMemoryMapOutputs.size() -> 6, commitMemory -> 70444621, usedMemory ->84531067\n",
            "2023-01-17 15:50:40,564 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local204468955_0001_m_000006_0 decomp: 4189709 len: 4189713 to MEMORY\n",
            "2023-01-17 15:50:40,569 INFO reduce.InMemoryMapOutput: Read 4189709 bytes from map-output for attempt_local204468955_0001_m_000006_0\n",
            "2023-01-17 15:50:40,569 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4189709, inMemoryMapOutputs.size() -> 7, commitMemory -> 84531067, usedMemory ->88720776\n",
            "2023-01-17 15:50:40,570 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
            "2023-01-17 15:50:40,571 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 15:50:40,571 INFO reduce.MergeManagerImpl: finalMerge called with 7 in-memory map-outputs and 0 on-disk map-outputs\n",
            "2023-01-17 15:50:40,585 INFO mapred.Merger: Merging 7 sorted segments\n",
            "2023-01-17 15:50:40,585 INFO mapred.Merger: Down to the last merge-pass, with 7 segments left of total size: 88720720 bytes\n",
            "2023-01-17 15:50:42,361 INFO reduce.MergeManagerImpl: Merged 7 segments, 88720776 bytes to disk to satisfy reduce memory limit\n",
            "2023-01-17 15:50:42,361 INFO reduce.MergeManagerImpl: Merging 1 files, 88720768 bytes from disk\n",
            "2023-01-17 15:50:42,362 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
            "2023-01-17 15:50:42,363 INFO mapred.Merger: Merging 1 sorted segments\n",
            "2023-01-17 15:50:42,363 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 88720756 bytes\n",
            "2023-01-17 15:50:42,364 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 15:50:42,371 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, reducer.py]\n",
            "2023-01-17 15:50:42,374 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
            "2023-01-17 15:50:42,375 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
            "2023-01-17 15:50:42,392 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:42,393 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:42,394 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:42,416 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:42,591 INFO streaming.PipeMapRed: R/W/S=10000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:42,858 INFO streaming.PipeMapRed: R/W/S=100000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:43,077 INFO streaming.PipeMapRed: R/W/S=200000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:43,221 INFO streaming.PipeMapRed: R/W/S=300000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:43,353 INFO streaming.PipeMapRed: R/W/S=400000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
            "2023-01-17 15:50:43,574 INFO streaming.PipeMapRed: R/W/S=500000/0/0 in:500000=500000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:50:43,710 INFO streaming.PipeMapRed: R/W/S=600000/0/0 in:600000=600000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:50:43,832 INFO streaming.PipeMapRed: R/W/S=700000/0/0 in:700000=700000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:50:43,949 INFO streaming.PipeMapRed: R/W/S=800000/0/0 in:800000=800000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:50:44,077 INFO streaming.PipeMapRed: R/W/S=900000/0/0 in:900000=900000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:50:44,212 INFO streaming.PipeMapRed: R/W/S=1000000/0/0 in:1000000=1000000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:50:44,346 INFO streaming.PipeMapRed: R/W/S=1100000/0/0 in:1100000=1100000/1 [rec/s] out:0=0/1 [rec/s]\n",
            "2023-01-17 15:50:44,489 INFO streaming.PipeMapRed: R/W/S=1200000/0/0 in:600000=1200000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:50:44,630 INFO streaming.PipeMapRed: R/W/S=1300000/0/0 in:650000=1300000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:50:44,761 INFO streaming.PipeMapRed: R/W/S=1400000/0/0 in:700000=1400000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:50:44,891 INFO streaming.PipeMapRed: R/W/S=1500000/0/0 in:750000=1500000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:50:45,030 INFO streaming.PipeMapRed: R/W/S=1600000/0/0 in:800000=1600000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:50:45,147 INFO streaming.PipeMapRed: R/W/S=1700000/0/0 in:850000=1700000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:50:45,268 INFO streaming.PipeMapRed: R/W/S=1800000/0/0 in:900000=1800000/2 [rec/s] out:0=0/2 [rec/s]\n",
            "2023-01-17 15:50:45,394 INFO streaming.PipeMapRed: R/W/S=1900000/0/0 in:633333=1900000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:50:45,523 INFO streaming.PipeMapRed: R/W/S=2000000/0/0 in:666666=2000000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:50:45,656 INFO streaming.PipeMapRed: R/W/S=2100000/0/0 in:700000=2100000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:50:45,777 INFO streaming.PipeMapRed: R/W/S=2200000/0/0 in:733333=2200000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:50:45,904 INFO streaming.PipeMapRed: R/W/S=2300000/0/0 in:766666=2300000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:50:46,033 INFO streaming.PipeMapRed: R/W/S=2400000/0/0 in:800000=2400000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:50:46,160 INFO streaming.PipeMapRed: R/W/S=2500000/0/0 in:833333=2500000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:50:46,286 INFO streaming.PipeMapRed: R/W/S=2600000/0/0 in:866666=2600000/3 [rec/s] out:0=0/3 [rec/s]\n",
            "2023-01-17 15:50:46,422 INFO streaming.PipeMapRed: R/W/S=2700000/0/0 in:675000=2700000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:50:46,540 INFO streaming.PipeMapRed: R/W/S=2800000/0/0 in:700000=2800000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:50:46,677 INFO streaming.PipeMapRed: R/W/S=2900000/0/0 in:725000=2900000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:50:46,803 INFO streaming.PipeMapRed: R/W/S=3000000/0/0 in:750000=3000000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:50:46,932 INFO streaming.PipeMapRed: R/W/S=3100000/0/0 in:775000=3100000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:50:47,056 INFO streaming.PipeMapRed: R/W/S=3200000/0/0 in:800000=3200000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:50:47,183 INFO streaming.PipeMapRed: R/W/S=3300000/0/0 in:825000=3300000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:50:47,319 INFO streaming.PipeMapRed: R/W/S=3400000/0/0 in:850000=3400000/4 [rec/s] out:0=0/4 [rec/s]\n",
            "2023-01-17 15:50:47,447 INFO streaming.PipeMapRed: R/W/S=3500000/0/0 in:700000=3500000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:50:47,571 INFO streaming.PipeMapRed: R/W/S=3600000/0/0 in:720000=3600000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:50:47,708 INFO streaming.PipeMapRed: R/W/S=3700000/0/0 in:740000=3700000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:50:47,833 INFO streaming.PipeMapRed: R/W/S=3800000/0/0 in:760000=3800000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:50:47,966 INFO streaming.PipeMapRed: R/W/S=3900000/0/0 in:780000=3900000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:50:48,110 INFO streaming.PipeMapRed: R/W/S=4000000/0/0 in:800000=4000000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:50:48,237 INFO streaming.PipeMapRed: R/W/S=4100000/0/0 in:820000=4100000/5 [rec/s] out:0=0/5 [rec/s]\n",
            "2023-01-17 15:50:48,309 INFO streaming.PipeMapRed: Records R/W=4138476/1\n",
            "2023-01-17 15:50:48,313 INFO streaming.PipeMapRed: MRErrorThread done\n",
            "2023-01-17 15:50:48,314 INFO streaming.PipeMapRed: mapRedFinished\n",
            "2023-01-17 15:50:48,315 INFO mapred.Task: Task:attempt_local204468955_0001_r_000000_0 is done. And is in the process of committing\n",
            "2023-01-17 15:50:48,316 INFO mapred.LocalJobRunner: 7 / 7 copied.\n",
            "2023-01-17 15:50:48,316 INFO mapred.Task: Task attempt_local204468955_0001_r_000000_0 is allowed to commit now\n",
            "2023-01-17 15:50:48,318 INFO output.FileOutputCommitter: Saved output of task 'attempt_local204468955_0001_r_000000_0' to file:/root/myoutput\n",
            "2023-01-17 15:50:48,320 INFO mapred.LocalJobRunner: Records R/W=4138476/1 > reduce\n",
            "2023-01-17 15:50:48,320 INFO mapred.Task: Task 'attempt_local204468955_0001_r_000000_0' done.\n",
            "2023-01-17 15:50:48,320 INFO mapred.Task: Final Counters for attempt_local204468955_0001_r_000000_0: Counters: 24\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=388784950\n",
            "\t\tFILE: Number of bytes written=178055941\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=18\n",
            "\t\tReduce shuffle bytes=88720804\n",
            "\t\tReduce input records=4138476\n",
            "\t\tReduce output records=2\n",
            "\t\tSpilled Records=4138476\n",
            "\t\tShuffled Maps =7\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=7\n",
            "\t\tGC time elapsed (ms)=0\n",
            "\t\tTotal committed heap usage (bytes)=695730176\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=94\n",
            "2023-01-17 15:50:48,321 INFO mapred.LocalJobRunner: Finishing task: attempt_local204468955_0001_r_000000_0\n",
            "2023-01-17 15:50:48,321 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
            "2023-01-17 15:50:48,961 INFO mapreduce.Job:  map 100% reduce 100%\n",
            "2023-01-17 15:50:48,961 INFO mapreduce.Job: Job job_local204468955_0001 completed successfully\n",
            "2023-01-17 15:50:48,979 INFO mapreduce.Job: Counters: 30\n",
            "\tFile System Counters\n",
            "\t\tFILE: Number of bytes read=1304878285\n",
            "\t\tFILE: Number of bytes written=566948884\n",
            "\t\tFILE: Number of read operations=0\n",
            "\t\tFILE: Number of large read operations=0\n",
            "\t\tFILE: Number of write operations=0\n",
            "\tMap-Reduce Framework\n",
            "\t\tMap input records=4138476\n",
            "\t\tMap output records=4138476\n",
            "\t\tMap output bytes=80443810\n",
            "\t\tMap output materialized bytes=88720804\n",
            "\t\tInput split bytes=588\n",
            "\t\tCombine input records=0\n",
            "\t\tCombine output records=0\n",
            "\t\tReduce input groups=18\n",
            "\t\tReduce shuffle bytes=88720804\n",
            "\t\tReduce input records=4138476\n",
            "\t\tReduce output records=2\n",
            "\t\tSpilled Records=8276952\n",
            "\t\tShuffled Maps =7\n",
            "\t\tFailed Shuffles=0\n",
            "\t\tMerged Map outputs=7\n",
            "\t\tGC time elapsed (ms)=453\n",
            "\t\tTotal committed heap usage (bytes)=4565499904\n",
            "\tShuffle Errors\n",
            "\t\tBAD_ID=0\n",
            "\t\tCONNECTION=0\n",
            "\t\tIO_ERROR=0\n",
            "\t\tWRONG_LENGTH=0\n",
            "\t\tWRONG_MAP=0\n",
            "\t\tWRONG_REDUCE=0\n",
            "\tFile Input Format Counters \n",
            "\t\tBytes Read=211337500\n",
            "\tFile Output Format Counters \n",
            "\t\tBytes Written=94\n",
            "2023-01-17 15:50:48,979 INFO streaming.StreamJob: Output directory: /root/myoutput\n"
          ]
        }
      ],
      "source": [
        "!rm -r ~/myoutput\n",
        "!/usr/local/hadoop-3.3.0/bin/hadoop jar /usr/local/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input ~/myinput -output ~/myoutput -file /content/mapper.py  -file /content/reducer.py  -mapper 'python mapper.py'  -reducer 'python reducer.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPzvWCalLcR4",
        "outputId": "1ed33471-0c6f-4cb2-99b0-5cfd2294ac95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "part-00000  _SUCCESS\n"
          ]
        }
      ],
      "source": [
        "!ls ~/myoutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59XJBWrVLcR4",
        "outputId": "ae036ee2-1625-4125-ead4-4c08c166ce60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre total de ventes : 4138476 \t\n",
            " Valeur totale des ventes: 1034457953.2599641\t\n"
          ]
        }
      ],
      "source": [
        "!tail -n 30 ~/myoutput/part-00000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK7rOg_rZlUt"
      },
      "source": [
        "# Références\n",
        "**Réalisez des calculs distribués sur des données massives** : \n",
        "https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308656-familiarisez-vous-avec-hadoop\n",
        "\n",
        "**Hadoop : la nouvelle infrastructure de gestion de données** : https://juvenal-chokogoue.developpez.com/tutoriels/hadoop-fonctionnement/\n",
        "\n",
        "**MapReduce : comment l’utiliser pour le Big Data ?** : https://datascientest.com/mapreduce\n",
        "\n",
        "**Calcul distribué: Hadoop et MapReduce** : http://b3d.bdpedia.fr/calculdistr.html\n",
        "\n",
        "**Language Processing and Python** : https://www.nltk.org/book/ch01.html"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}